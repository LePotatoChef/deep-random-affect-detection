{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Bidirectional\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import cohen_kappa_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers: 1, nodes: 1\n",
      "WARNING:tensorflow:From C:\\Users\\Ethan\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\Ethan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1854 samples, validate on 618 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 92s 50ms/step - loss: 0.8071 - val_loss: 0.6282\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 92s 49ms/step - loss: 0.6408 - val_loss: 0.6228\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 92s 49ms/step - loss: 0.6350 - val_loss: 0.6288\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 92s 49ms/step - loss: 0.6331 - val_loss: 0.6309\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 92s 50ms/step - loss: 0.6320 - val_loss: 0.6359\n",
      "Train on 1854 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 91s 49ms/step - loss: 0.8009 - val_loss: 0.6518\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 99s 53ms/step - loss: 0.6405 - val_loss: 0.6392\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 97s 52ms/step - loss: 0.6342 - val_loss: 0.6416\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 97s 52ms/step - loss: 0.6326 - val_loss: 0.6457\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 97s 52ms/step - loss: 0.6315 - val_loss: 0.6457\n",
      "Train on 1856 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1856/1856 [==============================] - 99s 53ms/step - loss: 0.8251 - val_loss: 0.6375\n",
      "Epoch 2/1000\n",
      "1856/1856 [==============================] - 97s 52ms/step - loss: 0.6485 - val_loss: 0.6221\n",
      "Epoch 3/1000\n",
      "1856/1856 [==============================] - 98s 53ms/step - loss: 0.6428 - val_loss: 0.6222\n",
      "Epoch 4/1000\n",
      "1856/1856 [==============================] - 98s 53ms/step - loss: 0.6413 - val_loss: 0.6218\n",
      "Epoch 5/1000\n",
      "1856/1856 [==============================] - 97s 53ms/step - loss: 0.6405 - val_loss: 0.6227\n",
      "Epoch 6/1000\n",
      "1856/1856 [==============================] - 103s 55ms/step - loss: 0.6618 - val_loss: 0.6763\n",
      "Epoch 7/1000\n",
      "1856/1856 [==============================] - 101s 54ms/step - loss: 0.6460 - val_loss: 0.6578\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 98s 53ms/step - loss: 0.8598 - val_loss: 0.6474\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 97s 52ms/step - loss: 0.6587 - val_loss: 0.5978\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 96s 52ms/step - loss: 0.6493 - val_loss: 0.5944\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 96s 52ms/step - loss: 0.6467 - val_loss: 0.5938\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 96s 52ms/step - loss: 0.6446 - val_loss: 0.5961\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 96s 52ms/step - loss: 0.6432 - val_loss: 0.5989\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 96s 52ms/step - loss: 0.6414 - val_loss: 0.6002\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 97s 52ms/step - loss: 0.8283 - val_loss: 0.6607\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 96s 51ms/step - loss: 0.6483 - val_loss: 0.6381\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 96s 52ms/step - loss: 0.6409 - val_loss: 0.6347\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 97s 52ms/step - loss: 0.6393 - val_loss: 0.6309\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 93s 50ms/step - loss: 0.6382 - val_loss: 0.6341\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 91s 49ms/step - loss: 0.6370 - val_loss: 0.6341\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 90s 49ms/step - loss: 0.6358 - val_loss: 0.6366\n",
      "auc: 0.57195321537884\n",
      "kappa: 0.0\n",
      "layers: 1, nodes: 2\n",
      "Train on 1854 samples, validate on 618 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 92s 49ms/step - loss: 0.7919 - val_loss: 0.6361\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 91s 49ms/step - loss: 0.6430 - val_loss: 0.6194\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 93s 50ms/step - loss: 0.6394 - val_loss: 0.6195\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 91s 49ms/step - loss: 0.6374 - val_loss: 0.6224\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 92s 50ms/step - loss: 0.6349 - val_loss: 0.6273\n",
      "Train on 1854 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 93s 50ms/step - loss: 0.7928 - val_loss: 0.6319\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 92s 50ms/step - loss: 0.6425 - val_loss: 0.6195\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 92s 50ms/step - loss: 0.6384 - val_loss: 0.6200\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 92s 50ms/step - loss: 0.6364 - val_loss: 0.6224\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 92s 50ms/step - loss: 0.6348 - val_loss: 0.6255\n",
      "Train on 1856 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1856/1856 [==============================] - 93s 50ms/step - loss: 0.7573 - val_loss: 0.6124\n",
      "Epoch 2/1000\n",
      "1856/1856 [==============================] - 93s 50ms/step - loss: 0.6429 - val_loss: 0.6063\n",
      "Epoch 3/1000\n",
      "1856/1856 [==============================] - 93s 50ms/step - loss: 0.6406 - val_loss: 0.6185\n",
      "Epoch 4/1000\n",
      "1856/1856 [==============================] - 93s 50ms/step - loss: 0.6383 - val_loss: 0.6208\n",
      "Epoch 5/1000\n",
      "1856/1856 [==============================] - 93s 50ms/step - loss: 0.6368 - val_loss: 0.6201\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 93s 50ms/step - loss: 0.8064 - val_loss: 0.6228\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 92s 50ms/step - loss: 0.6437 - val_loss: 0.6209\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 92s 49ms/step - loss: 0.6410 - val_loss: 0.6207\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 92s 50ms/step - loss: 0.6388 - val_loss: 0.6230\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 92s 50ms/step - loss: 0.6373 - val_loss: 0.6231\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 92s 50ms/step - loss: 0.6356 - val_loss: 0.6258\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 93s 50ms/step - loss: 0.7471 - val_loss: 0.6450\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 92s 50ms/step - loss: 0.6382 - val_loss: 0.6437\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 92s 50ms/step - loss: 0.6358 - val_loss: 0.6428\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 92s 50ms/step - loss: 0.6334 - val_loss: 0.6454\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 92s 50ms/step - loss: 0.6310 - val_loss: 0.6458\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 92s 50ms/step - loss: 0.6288 - val_loss: 0.6425\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 92s 50ms/step - loss: 0.6263 - val_loss: 0.6398\n",
      "Epoch 8/1000\n",
      "1857/1857 [==============================] - 92s 50ms/step - loss: 0.6240 - val_loss: 0.6443\n",
      "Epoch 9/1000\n",
      "1857/1857 [==============================] - 93s 50ms/step - loss: 0.6227 - val_loss: 0.6496\n",
      "Epoch 10/1000\n",
      "1857/1857 [==============================] - 97s 52ms/step - loss: 0.6205 - val_loss: 0.6582\n",
      "auc: 0.5621736292492342\n",
      "kappa: 0.0\n",
      "layers: 1, nodes: 4\n",
      "Train on 1854 samples, validate on 618 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 101s 55ms/step - loss: 0.7081 - val_loss: 0.6240\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 100s 54ms/step - loss: 0.6385 - val_loss: 0.6155\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 101s 55ms/step - loss: 0.6355 - val_loss: 0.6225\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 102s 55ms/step - loss: 0.6346 - val_loss: 0.6180\n",
      "Epoch 5/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1854/1854 [==============================] - 99s 54ms/step - loss: 0.6325 - val_loss: 0.6263\n",
      "Train on 1854 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 100s 54ms/step - loss: 0.6956 - val_loss: 0.6587\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 99s 53ms/step - loss: 0.6284 - val_loss: 0.6588\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 99s 53ms/step - loss: 0.6253 - val_loss: 0.6539\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 99s 53ms/step - loss: 0.6226 - val_loss: 0.6605\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 99s 53ms/step - loss: 0.6206 - val_loss: 0.6590\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 99s 53ms/step - loss: 0.6178 - val_loss: 0.6640\n",
      "Train on 1856 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1856/1856 [==============================] - 101s 54ms/step - loss: 0.7115 - val_loss: 0.6238\n",
      "Epoch 2/1000\n",
      "1856/1856 [==============================] - 100s 54ms/step - loss: 0.6413 - val_loss: 0.6192\n",
      "Epoch 3/1000\n",
      "1856/1856 [==============================] - 100s 54ms/step - loss: 0.6382 - val_loss: 0.6304\n",
      "Epoch 4/1000\n",
      "1856/1856 [==============================] - 100s 54ms/step - loss: 0.6345 - val_loss: 0.6222\n",
      "Epoch 5/1000\n",
      "1856/1856 [==============================] - 100s 54ms/step - loss: 0.6317 - val_loss: 0.6336\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 101s 55ms/step - loss: 0.7084 - val_loss: 0.6103\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 98s 53ms/step - loss: 0.6455 - val_loss: 0.6108\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 96s 52ms/step - loss: 0.6416 - val_loss: 0.6175\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 96s 52ms/step - loss: 0.6401 - val_loss: 0.6094\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 99s 53ms/step - loss: 0.6371 - val_loss: 0.6097\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 103s 56ms/step - loss: 0.6352 - val_loss: 0.6213\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 103s 55ms/step - loss: 0.6316 - val_loss: 0.6106\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 104s 56ms/step - loss: 0.7186 - val_loss: 0.6108\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 103s 55ms/step - loss: 0.6446 - val_loss: 0.6059\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 103s 56ms/step - loss: 0.6411 - val_loss: 0.6166\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 103s 55ms/step - loss: 0.6381 - val_loss: 0.6100\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 103s 56ms/step - loss: 0.6366 - val_loss: 0.6174\n",
      "auc: 0.5795106380771202\n",
      "kappa: 0.0\n",
      "layers: 1, nodes: 8\n",
      "Train on 1854 samples, validate on 618 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 104s 56ms/step - loss: 0.6813 - val_loss: 0.6472\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 102s 55ms/step - loss: 0.6347 - val_loss: 0.6297\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 102s 55ms/step - loss: 0.6309 - val_loss: 0.6532\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 103s 56ms/step - loss: 0.6287 - val_loss: 0.6423\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 100s 54ms/step - loss: 0.6259 - val_loss: 0.6382\n",
      "Train on 1854 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 102s 55ms/step - loss: 0.6796 - val_loss: 0.6229\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 101s 54ms/step - loss: 0.6402 - val_loss: 0.6058\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 101s 54ms/step - loss: 0.6355 - val_loss: 0.6193\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 104s 56ms/step - loss: 0.6328 - val_loss: 0.6123\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 100s 54ms/step - loss: 0.6322 - val_loss: 0.6224\n",
      "Train on 1856 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1856/1856 [==============================] - 103s 55ms/step - loss: 0.6863 - val_loss: 0.5864\n",
      "Epoch 2/1000\n",
      "1856/1856 [==============================] - 101s 54ms/step - loss: 0.6471 - val_loss: 0.5845\n",
      "Epoch 3/1000\n",
      "1856/1856 [==============================] - 101s 54ms/step - loss: 0.6430 - val_loss: 0.5934\n",
      "Epoch 4/1000\n",
      "1856/1856 [==============================] - 101s 54ms/step - loss: 0.6398 - val_loss: 0.5971\n",
      "Epoch 5/1000\n",
      "1856/1856 [==============================] - 102s 55ms/step - loss: 0.6384 - val_loss: 0.5935\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 106s 57ms/step - loss: 0.6724 - val_loss: 0.6412\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 105s 57ms/step - loss: 0.6300 - val_loss: 0.6475\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 105s 57ms/step - loss: 0.6279 - val_loss: 0.6473\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 104s 56ms/step - loss: 0.6233 - val_loss: 0.6473\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 109s 59ms/step - loss: 0.6778 - val_loss: 0.6404\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 105s 56ms/step - loss: 0.6365 - val_loss: 0.6318\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 105s 57ms/step - loss: 0.6311 - val_loss: 0.6431\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 105s 56ms/step - loss: 0.6261 - val_loss: 0.6333\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 99s 53ms/step - loss: 0.6248 - val_loss: 0.6488\n",
      "auc: 0.5831797952724518\n",
      "kappa: 0.0\n",
      "layers: 1, nodes: 16\n",
      "Train on 1854 samples, validate on 618 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 97s 52ms/step - loss: 0.6696 - val_loss: 0.6185\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 96s 52ms/step - loss: 0.6431 - val_loss: 0.6285\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 96s 52ms/step - loss: 0.6375 - val_loss: 0.6146\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 98s 53ms/step - loss: 0.6350 - val_loss: 0.6201\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 96s 52ms/step - loss: 0.6325 - val_loss: 0.6342\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 95s 51ms/step - loss: 0.6286 - val_loss: 0.6531\n",
      "Train on 1854 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 99s 53ms/step - loss: 0.6702 - val_loss: 0.6063\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 97s 52ms/step - loss: 0.6405 - val_loss: 0.6291\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 97s 52ms/step - loss: 0.6342 - val_loss: 0.6521\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 99s 53ms/step - loss: 0.6319 - val_loss: 0.6404\n",
      "Train on 1856 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1856/1856 [==============================] - 97s 52ms/step - loss: 0.6739 - val_loss: 0.6160\n",
      "Epoch 2/1000\n",
      "1856/1856 [==============================] - 97s 52ms/step - loss: 0.6412 - val_loss: 0.6138\n",
      "Epoch 3/1000\n",
      "1856/1856 [==============================] - 95s 51ms/step - loss: 0.6355 - val_loss: 0.6055\n",
      "Epoch 4/1000\n",
      "1856/1856 [==============================] - 95s 51ms/step - loss: 0.6320 - val_loss: 0.6261\n",
      "Epoch 5/1000\n",
      "1856/1856 [==============================] - 96s 51ms/step - loss: 0.6284 - val_loss: 0.6219\n",
      "Epoch 6/1000\n",
      "1856/1856 [==============================] - 97s 52ms/step - loss: 0.6271 - val_loss: 0.6400\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 102s 55ms/step - loss: 0.6609 - val_loss: 0.6290\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 102s 55ms/step - loss: 0.6313 - val_loss: 0.6326\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 97s 52ms/step - loss: 0.6253 - val_loss: 0.6444\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 96s 52ms/step - loss: 0.6196 - val_loss: 0.6658\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 96s 52ms/step - loss: 0.6638 - val_loss: 0.6411\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1857/1857 [==============================] - 94s 50ms/step - loss: 0.6351 - val_loss: 0.6327\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 94s 51ms/step - loss: 0.6307 - val_loss: 0.6391\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 94s 50ms/step - loss: 0.6273 - val_loss: 0.6550\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 94s 50ms/step - loss: 0.6256 - val_loss: 0.6476\n",
      "auc: 0.5834080193242608\n",
      "kappa: 0.0\n",
      "layers: 1, nodes: 32\n",
      "Train on 1854 samples, validate on 618 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 95s 51ms/step - loss: 0.6588 - val_loss: 0.6260\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 94s 50ms/step - loss: 0.6373 - val_loss: 0.6401\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 94s 50ms/step - loss: 0.6282 - val_loss: 0.6649\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 94s 51ms/step - loss: 0.6219 - val_loss: 0.6398\n",
      "Train on 1854 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 98s 53ms/step - loss: 0.6596 - val_loss: 0.6156\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 95s 51ms/step - loss: 0.6364 - val_loss: 0.6363\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 95s 51ms/step - loss: 0.6276 - val_loss: 0.6461\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 95s 51ms/step - loss: 0.6248 - val_loss: 0.6481\n",
      "Train on 1856 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1856/1856 [==============================] - 96s 52ms/step - loss: 0.6628 - val_loss: 0.6220\n",
      "Epoch 2/1000\n",
      "1856/1856 [==============================] - 94s 51ms/step - loss: 0.6368 - val_loss: 0.6399\n",
      "Epoch 3/1000\n",
      "1856/1856 [==============================] - 94s 51ms/step - loss: 0.6324 - val_loss: 0.6292\n",
      "Epoch 4/1000\n",
      "1856/1856 [==============================] - 94s 51ms/step - loss: 0.6289 - val_loss: 0.6388\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 95s 51ms/step - loss: 0.6759 - val_loss: 0.6090\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 94s 51ms/step - loss: 0.6513 - val_loss: 0.5769\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 94s 50ms/step - loss: 0.6435 - val_loss: 0.6148\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 93s 50ms/step - loss: 0.6406 - val_loss: 0.5893\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 94s 50ms/step - loss: 0.6375 - val_loss: 0.6162\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 96s 52ms/step - loss: 0.6586 - val_loss: 0.6337\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 94s 51ms/step - loss: 0.6352 - val_loss: 0.6330\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 94s 51ms/step - loss: 0.6340 - val_loss: 0.6177\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 94s 51ms/step - loss: 0.6277 - val_loss: 0.6310\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 94s 51ms/step - loss: 0.6259 - val_loss: 0.6675\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 94s 51ms/step - loss: 0.6220 - val_loss: 0.6504\n",
      "auc: 0.5807568744865292\n",
      "kappa: 0.0\n",
      "layers: 1, nodes: 64\n",
      "Train on 1854 samples, validate on 618 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 96s 52ms/step - loss: 0.6571 - val_loss: 0.6426\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 94s 51ms/step - loss: 0.6381 - val_loss: 0.6431\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 94s 51ms/step - loss: 0.6324 - val_loss: 0.6299\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 94s 51ms/step - loss: 0.6276 - val_loss: 0.6579\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 94s 51ms/step - loss: 0.6287 - val_loss: 0.6552\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 94s 51ms/step - loss: 0.6246 - val_loss: 0.6597\n",
      "Train on 1854 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 97s 52ms/step - loss: 0.6696 - val_loss: 0.6435\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 94s 51ms/step - loss: 0.6336 - val_loss: 0.6454\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 95s 51ms/step - loss: 0.6329 - val_loss: 0.6324\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 94s 51ms/step - loss: 0.6261 - val_loss: 0.6453\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 94s 51ms/step - loss: 0.6230 - val_loss: 0.6415\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 95s 51ms/step - loss: 0.6194 - val_loss: 0.6333\n",
      "Train on 1856 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1856/1856 [==============================] - 96s 52ms/step - loss: 0.6598 - val_loss: 0.6191\n",
      "Epoch 2/1000\n",
      "1856/1856 [==============================] - 94s 50ms/step - loss: 0.6370 - val_loss: 0.6629\n",
      "Epoch 3/1000\n",
      "1856/1856 [==============================] - 94s 51ms/step - loss: 0.6295 - val_loss: 0.6337\n",
      "Epoch 4/1000\n",
      "1856/1856 [==============================] - 94s 50ms/step - loss: 0.6242 - val_loss: 0.6369\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 97s 52ms/step - loss: 0.6714 - val_loss: 0.6324\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 95s 51ms/step - loss: 0.6422 - val_loss: 0.6036\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 95s 51ms/step - loss: 0.6342 - val_loss: 0.6099\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 95s 51ms/step - loss: 0.6323 - val_loss: 0.6528\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 95s 51ms/step - loss: 0.6253 - val_loss: 0.6331\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 97s 52ms/step - loss: 0.6694 - val_loss: 0.6407\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 95s 51ms/step - loss: 0.6468 - val_loss: 0.6114\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 95s 51ms/step - loss: 0.6439 - val_loss: 0.6282\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 95s 51ms/step - loss: 0.6387 - val_loss: 0.6387\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 95s 51ms/step - loss: 0.6358 - val_loss: 0.6387\n",
      "auc: 0.5922779015134424\n",
      "kappa: 0.0\n",
      "layers: 1, nodes: 128\n",
      "Train on 1854 samples, validate on 618 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 97s 52ms/step - loss: 0.6712 - val_loss: 0.6979\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 95s 51ms/step - loss: 0.6391 - val_loss: 0.6208\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 95s 51ms/step - loss: 0.6350 - val_loss: 0.6351\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 95s 51ms/step - loss: 0.6309 - val_loss: 0.6467\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 95s 51ms/step - loss: 0.6266 - val_loss: 0.6362\n",
      "Train on 1854 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 97s 52ms/step - loss: 0.6764 - val_loss: 0.6773\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 95s 51ms/step - loss: 0.6495 - val_loss: 0.6159\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 94s 51ms/step - loss: 0.6374 - val_loss: 0.6041\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 94s 51ms/step - loss: 0.6365 - val_loss: 0.6351\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 95s 51ms/step - loss: 0.6327 - val_loss: 0.6624\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 94s 51ms/step - loss: 0.6288 - val_loss: 0.5927\n",
      "Epoch 7/1000\n",
      "1854/1854 [==============================] - 94s 51ms/step - loss: 0.6235 - val_loss: 0.6458\n",
      "Epoch 8/1000\n",
      "1854/1854 [==============================] - 94s 51ms/step - loss: 0.6255 - val_loss: 0.6290\n",
      "Epoch 9/1000\n",
      "1854/1854 [==============================] - 94s 51ms/step - loss: 0.6238 - val_loss: 0.6284\n",
      "Train on 1856 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1856/1856 [==============================] - 97s 52ms/step - loss: 0.6932 - val_loss: 0.5748\n",
      "Epoch 2/1000\n",
      "1856/1856 [==============================] - 95s 51ms/step - loss: 0.6557 - val_loss: 0.6200\n",
      "Epoch 3/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1856/1856 [==============================] - 95s 51ms/step - loss: 0.6426 - val_loss: 0.6287\n",
      "Epoch 4/1000\n",
      "1856/1856 [==============================] - 95s 51ms/step - loss: 0.6407 - val_loss: 0.6220\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 99s 53ms/step - loss: 0.6660 - val_loss: 0.6456\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 96s 52ms/step - loss: 0.6433 - val_loss: 0.6241\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 96s 52ms/step - loss: 0.6310 - val_loss: 0.6426\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 96s 52ms/step - loss: 0.6295 - val_loss: 0.6701\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 96s 52ms/step - loss: 0.6235 - val_loss: 0.6574\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 98s 53ms/step - loss: 0.6578 - val_loss: 0.6581\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 95s 51ms/step - loss: 0.6383 - val_loss: 0.6440\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 96s 52ms/step - loss: 0.6361 - val_loss: 0.7309\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 96s 52ms/step - loss: 0.6276 - val_loss: 0.6439\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 96s 52ms/step - loss: 0.6216 - val_loss: 0.6570\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 96s 52ms/step - loss: 0.6277 - val_loss: 0.6624\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 96s 52ms/step - loss: 0.6186 - val_loss: 0.6923\n",
      "auc: 0.5917467830156218\n",
      "kappa: 0.0\n",
      "layers: 1, nodes: 256\n",
      "Train on 1854 samples, validate on 618 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 100s 54ms/step - loss: 0.6929 - val_loss: 0.6202\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 97s 52ms/step - loss: 0.6525 - val_loss: 0.7358\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 97s 52ms/step - loss: 0.6615 - val_loss: 0.6291\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 97s 52ms/step - loss: 0.6432 - val_loss: 0.6465\n",
      "Train on 1854 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 100s 54ms/step - loss: 0.6903 - val_loss: 0.6512\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 97s 53ms/step - loss: 0.6508 - val_loss: 0.6907\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 97s 53ms/step - loss: 0.6466 - val_loss: 0.6137\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 98s 53ms/step - loss: 0.6393 - val_loss: 0.6394\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 97s 53ms/step - loss: 0.6329 - val_loss: 0.6543\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 97s 53ms/step - loss: 0.6287 - val_loss: 0.6580\n",
      "Train on 1856 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1856/1856 [==============================] - 99s 53ms/step - loss: 0.6957 - val_loss: 0.6081\n",
      "Epoch 2/1000\n",
      "1856/1856 [==============================] - 97s 52ms/step - loss: 0.6498 - val_loss: 0.6735\n",
      "Epoch 3/1000\n",
      "1856/1856 [==============================] - 97s 52ms/step - loss: 0.6453 - val_loss: 0.6647\n",
      "Epoch 4/1000\n",
      "1856/1856 [==============================] - 97s 52ms/step - loss: 0.6359 - val_loss: 0.6250\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 100s 54ms/step - loss: 0.6862 - val_loss: 0.6476\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 98s 53ms/step - loss: 0.6432 - val_loss: 0.6915\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 98s 53ms/step - loss: 0.6391 - val_loss: 0.6622\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 98s 53ms/step - loss: 0.6368 - val_loss: 0.6448\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 98s 53ms/step - loss: 0.6279 - val_loss: 0.6422\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 98s 53ms/step - loss: 0.6252 - val_loss: 0.6838\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 98s 53ms/step - loss: 0.6326 - val_loss: 0.6888\n",
      "Epoch 8/1000\n",
      "1857/1857 [==============================] - 98s 53ms/step - loss: 0.6201 - val_loss: 0.6636\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 100s 54ms/step - loss: 0.6941 - val_loss: 0.6387\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 97s 52ms/step - loss: 0.6587 - val_loss: 0.5993\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 97s 52ms/step - loss: 0.6518 - val_loss: 0.6154\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 97s 52ms/step - loss: 0.6429 - val_loss: 0.6433\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 96s 52ms/step - loss: 0.6436 - val_loss: 0.6696\n",
      "auc: 0.5972731664557893\n",
      "kappa: 0.002452099672391539\n",
      "layers: 1, nodes: 512\n",
      "Train on 1854 samples, validate on 618 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 111s 60ms/step - loss: 0.7540 - val_loss: 0.6689\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 108s 58ms/step - loss: 0.6659 - val_loss: 0.6467\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 108s 58ms/step - loss: 0.6498 - val_loss: 0.6792\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 108s 58ms/step - loss: 0.6476 - val_loss: 0.6600\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 108s 58ms/step - loss: 0.6361 - val_loss: 0.6618\n",
      "Train on 1854 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 112s 60ms/step - loss: 0.7636 - val_loss: 0.5925\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 108s 58ms/step - loss: 0.6607 - val_loss: 0.6441\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 108s 58ms/step - loss: 0.6428 - val_loss: 0.6422\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 108s 58ms/step - loss: 0.6437 - val_loss: 0.6540\n",
      "Train on 1856 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1856/1856 [==============================] - 111s 60ms/step - loss: 0.6819 - val_loss: 0.6159\n",
      "Epoch 2/1000\n",
      "1856/1856 [==============================] - 108s 58ms/step - loss: 0.6671 - val_loss: 0.6090\n",
      "Epoch 3/1000\n",
      "1856/1856 [==============================] - 108s 58ms/step - loss: 0.6424 - val_loss: 0.6121\n",
      "Epoch 4/1000\n",
      "1856/1856 [==============================] - 108s 58ms/step - loss: 0.6406 - val_loss: 0.6192\n",
      "Epoch 5/1000\n",
      "1856/1856 [==============================] - 108s 58ms/step - loss: 0.6441 - val_loss: 0.6480\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 112s 60ms/step - loss: 0.7031 - val_loss: 0.8007\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 108s 58ms/step - loss: 0.7189 - val_loss: 0.5926\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 108s 58ms/step - loss: 0.7107 - val_loss: 0.7676\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 108s 58ms/step - loss: 0.6991 - val_loss: 0.7721\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 108s 58ms/step - loss: 0.7127 - val_loss: 0.6236\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 113s 61ms/step - loss: 0.7122 - val_loss: 0.6917\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 109s 59ms/step - loss: 0.6537 - val_loss: 0.6856\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 109s 59ms/step - loss: 0.6409 - val_loss: 0.6527\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 109s 59ms/step - loss: 0.6312 - val_loss: 0.6999\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 110s 59ms/step - loss: 0.6359 - val_loss: 0.6437\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 110s 59ms/step - loss: 0.6266 - val_loss: 0.6615\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 110s 59ms/step - loss: 0.6229 - val_loss: 0.6553\n",
      "Epoch 8/1000\n",
      "1857/1857 [==============================] - 109s 59ms/step - loss: 0.6250 - val_loss: 0.6588\n",
      "auc: 0.5889627891741401\n",
      "kappa: 0.0\n",
      "layers: 1, nodes: 1024\n",
      "Train on 1854 samples, validate on 618 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 185s 100ms/step - loss: 1.2269 - val_loss: 1.0314\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1854/1854 [==============================] - 181s 98ms/step - loss: 1.0906 - val_loss: 1.0909\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 181s 98ms/step - loss: 1.0845 - val_loss: 1.2750\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 181s 98ms/step - loss: 1.1486 - val_loss: 1.3570\n",
      "Train on 1854 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 186s 100ms/step - loss: 1.0365 - val_loss: 1.2958\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 182s 98ms/step - loss: 1.0381 - val_loss: 1.1101\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 182s 98ms/step - loss: 1.0418 - val_loss: 1.1151\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 182s 98ms/step - loss: 1.0608 - val_loss: 1.0262\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 182s 98ms/step - loss: 1.0315 - val_loss: 1.0245\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 182s 98ms/step - loss: 1.0304 - val_loss: 1.1149\n",
      "Epoch 7/1000\n",
      "1854/1854 [==============================] - 182s 98ms/step - loss: 1.0171 - val_loss: 1.0164\n",
      "Epoch 8/1000\n",
      "1854/1854 [==============================] - 182s 98ms/step - loss: 1.0410 - val_loss: 1.2070\n",
      "Epoch 9/1000\n",
      "1854/1854 [==============================] - 182s 98ms/step - loss: 1.0337 - val_loss: 1.0635\n",
      "Epoch 10/1000\n",
      "1854/1854 [==============================] - 182s 98ms/step - loss: 1.0095 - val_loss: 1.1743\n",
      "Train on 1856 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1856/1856 [==============================] - 186s 100ms/step - loss: 1.0741 - val_loss: 0.6290\n",
      "Epoch 2/1000\n",
      "1856/1856 [==============================] - 182s 98ms/step - loss: 0.6833 - val_loss: 0.6858\n",
      "Epoch 3/1000\n",
      "1856/1856 [==============================] - 182s 98ms/step - loss: 0.6609 - val_loss: 0.6063\n",
      "Epoch 4/1000\n",
      "1856/1856 [==============================] - 182s 98ms/step - loss: 0.6423 - val_loss: 0.6659\n",
      "Epoch 5/1000\n",
      "1856/1856 [==============================] - 182s 98ms/step - loss: 0.6416 - val_loss: 0.6031\n",
      "Epoch 6/1000\n",
      "1856/1856 [==============================] - 182s 98ms/step - loss: 0.6364 - val_loss: 0.6597\n",
      "Epoch 7/1000\n",
      "1856/1856 [==============================] - 182s 98ms/step - loss: 0.6325 - val_loss: 0.6238\n",
      "Epoch 8/1000\n",
      "1856/1856 [==============================] - 182s 98ms/step - loss: 0.6257 - val_loss: 0.6350\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 186s 100ms/step - loss: 0.9257 - val_loss: 0.6947\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 182s 98ms/step - loss: 0.6801 - val_loss: 0.6930\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 182s 98ms/step - loss: 0.7035 - val_loss: 0.6654\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 182s 98ms/step - loss: 0.8048 - val_loss: 0.6009\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 182s 98ms/step - loss: 0.7398 - val_loss: 0.6129\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 182s 98ms/step - loss: 0.7255 - val_loss: 0.8401\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 182s 98ms/step - loss: 0.7049 - val_loss: 0.7006\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 186s 100ms/step - loss: 1.1100 - val_loss: 0.7311\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 181s 98ms/step - loss: 0.7136 - val_loss: 0.7339\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 181s 98ms/step - loss: 0.7083 - val_loss: 0.6968\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 181s 98ms/step - loss: 0.6482 - val_loss: 0.6585\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 182s 98ms/step - loss: 0.6405 - val_loss: 0.6820\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 181s 98ms/step - loss: 0.6415 - val_loss: 0.6475\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 182s 98ms/step - loss: 0.6327 - val_loss: 0.6474\n",
      "Epoch 8/1000\n",
      "1857/1857 [==============================] - 181s 98ms/step - loss: 0.6406 - val_loss: 0.6957\n",
      "Epoch 9/1000\n",
      "1857/1857 [==============================] - 181s 98ms/step - loss: 0.6368 - val_loss: 0.6335\n",
      "Epoch 10/1000\n",
      "1857/1857 [==============================] - 181s 98ms/step - loss: 0.6329 - val_loss: 0.6604\n",
      "Epoch 11/1000\n",
      "1857/1857 [==============================] - 181s 98ms/step - loss: 0.6276 - val_loss: 0.6719\n",
      "Epoch 12/1000\n",
      "1857/1857 [==============================] - 182s 98ms/step - loss: 0.6274 - val_loss: 0.6824\n",
      "auc: 0.5784458589513\n",
      "kappa: 0.007435860355459162\n",
      "layers: 1, nodes: 2048\n",
      "Train on 1854 samples, validate on 618 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 505s 272ms/step - loss: 1.3928 - val_loss: 1.3862\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 499s 269ms/step - loss: 1.4952 - val_loss: 1.7373\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 499s 269ms/step - loss: 1.5625 - val_loss: 2.0221\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 500s 270ms/step - loss: 1.5685 - val_loss: 2.0221\n",
      "Train on 1854 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 505s 272ms/step - loss: 1.7141 - val_loss: 2.0692\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 496s 267ms/step - loss: 1.5604 - val_loss: 2.0692\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 496s 267ms/step - loss: 1.5604 - val_loss: 2.0692\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 496s 267ms/step - loss: 1.7016 - val_loss: 2.0623\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 496s 267ms/step - loss: 1.7379 - val_loss: 2.0623\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 496s 267ms/step - loss: 1.7379 - val_loss: 2.0623\n",
      "Epoch 7/1000\n",
      "1854/1854 [==============================] - 495s 267ms/step - loss: 1.7379 - val_loss: 2.0623\n",
      "Epoch 8/1000\n",
      "1854/1854 [==============================] - 495s 267ms/step - loss: 1.7379 - val_loss: 2.0623\n",
      "Train on 1856 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1856/1856 [==============================] - 502s 270ms/step - loss: 1.1245 - val_loss: 1.7611\n",
      "Epoch 2/1000\n",
      "1856/1856 [==============================] - 495s 267ms/step - loss: 1.4679 - val_loss: 1.7628\n",
      "Epoch 3/1000\n",
      "1856/1856 [==============================] - 495s 267ms/step - loss: 1.4737 - val_loss: 1.7786\n",
      "Epoch 4/1000\n",
      "1856/1856 [==============================] - 495s 267ms/step - loss: 1.4748 - val_loss: 1.7786\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 503s 271ms/step - loss: 1.6407 - val_loss: 1.3863\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 496s 267ms/step - loss: 1.3863 - val_loss: 1.3863\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 496s 267ms/step - loss: 1.3863 - val_loss: 1.3863\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 496s 267ms/step - loss: 1.3863 - val_loss: 1.3863\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 496s 267ms/step - loss: 1.3863 - val_loss: 1.3863\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 496s 267ms/step - loss: 1.3863 - val_loss: 1.3863\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 539s 290ms/step - loss: 1.4507 - val_loss: 2.0261\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 531s 286ms/step - loss: 1.5189 - val_loss: 2.0261\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 532s 286ms/step - loss: 1.5189 - val_loss: 2.0261\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 532s 286ms/step - loss: 1.5189 - val_loss: 2.0261\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 532s 286ms/step - loss: 1.5189 - val_loss: 2.0261\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 532s 286ms/step - loss: 1.5189 - val_loss: 2.0261\n",
      "auc: 0.5018879367201282\n",
      "kappa: 0.00022331926763872746\n",
      "layers: 1, nodes: 4096\n",
      "Train on 1854 samples, validate on 618 samples\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "2 root error(s) found.\n  (0) Resource exhausted: OOM when allocating tensor with shape[4096,16384] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training_60/Adam/mul_23}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Mean_60/_11747]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: OOM when allocating tensor with shape[4096,16384] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training_60/Adam/mul_23}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-766400945718>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mbilstm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[0mes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[0mbilstm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# Get the average auc and kappa for all affects and folds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted: OOM when allocating tensor with shape[4096,16384] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training_60/Adam/mul_23}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Mean_60/_11747]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: OOM when allocating tensor with shape[4096,16384] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training_60/Adam/mul_23}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored."
     ]
    }
   ],
   "source": [
    "# RBLSTM\n",
    "\n",
    "LAYERS = 3\n",
    "MAX_POWER = 12\n",
    "FOLDS = 5\n",
    "PADDING = 50\n",
    "\n",
    "\n",
    "input_data = pk.load(open('input_data.pkl', 'rb'))\n",
    "target_data = pk.load(open('target_data.pkl', 'rb'))\n",
    "\n",
    "layers = []\n",
    "dimention = []\n",
    "auc = []\n",
    "kappa = []\n",
    "\n",
    "for lay in range(1,LAYERS+1):\n",
    "    for dim in np.power(2, np.arange(MAX_POWER+1)):\n",
    "        print(f'layers: {lay}, nodes: {dim}')\n",
    "        aucs = []\n",
    "        kappas = []\n",
    "        \n",
    "        # Prepare training batches\n",
    "        bilstm_input = []\n",
    "        bilstm_target = []\n",
    "        for i, t in zip(input_data, target_data):\n",
    "            bilstm_input.append(np.concatenate([np.zeros((PADDING-1, i.shape[1])), i])[:PADDING,:])\n",
    "            bilstm_target.append(np.argmax(t))\n",
    "        bilstm_input = np.array(bilstm_input)\n",
    "        bilstm_target = np.array(bilstm_target)\n",
    "        \n",
    "        # Prepare k-fold training and test sets\n",
    "        skf = StratifiedKFold(n_splits=FOLDS, shuffle=True)\n",
    "        for train_index, test_index in skf.split(bilstm_input, bilstm_target):\n",
    "            bilstm_target[train_index.astype(int)]\n",
    "            X_train_raw, X_test_raw = bilstm_input[train_index], bilstm_input[test_index]\n",
    "            y_train_raw, y_test_raw = bilstm_target[train_index], bilstm_target[test_index]\n",
    "            \n",
    "            X_train = np.stack(X_train_raw)\n",
    "            X_test = np.stack(X_test_raw)\n",
    "            \n",
    "            y_train = np.zeros((y_train_raw.size, y_train_raw.max()+1))\n",
    "            y_train[np.arange(y_train_raw.size),y_train_raw] = 1\n",
    "            y_test = np.zeros((y_test_raw.size, y_test_raw.max()+1))\n",
    "            y_test[np.arange(y_test_raw.size),y_test_raw] = 1\n",
    "            \n",
    "            # Make the LSTM\n",
    "            bilstm = Sequential()\n",
    "            if lay == 1:\n",
    "                bilstm.add(Bidirectional(LSTM(dim, activation='tanh'), input_shape=(PADDING, input_data[0].shape[1])))\n",
    "            elif lay == 2:\n",
    "                bilstm.add(Bidirectional(LSTM(dim, activation='tanh', return_sequences=True), input_shape=(PADDING, input_data[0].shape[1])))\n",
    "                bilstm.add(Bidirectional(LSTM(dim, activation='tanh')))\n",
    "            elif lay == 3:\n",
    "                bilstm.add(Bidirectional(LSTM(dim, activation='tanh', return_sequences=True), input_shape=(PADDING, input_data[0].shape[1])))\n",
    "                bilstm.add(Bidirectional(LSTM(dim, activation='tanh', return_sequences=True)))\n",
    "                bilstm.add(Bidirectional(LSTM(dim, activation='tanh')))\n",
    "            bilstm.add(Dense(4, activation='sigmoid'))\n",
    "        \n",
    "            # Train the model\n",
    "            bilstm.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "            es = [EarlyStopping(monitor='val_loss', patience=3, min_delta=0, restore_best_weights=True)]\n",
    "            bilstm.fit(X_train, y_train, epochs=1000, batch_size=1, validation_split=0.25, callbacks=es, verbose=True)\n",
    "            \n",
    "            # Get the average auc and kappa for all affects and folds\n",
    "            y_pred = bilstm.predict(X_test, batch_size=1)\n",
    "            for y_t, y_p in zip(y_test.T, y_pred.T):\n",
    "                aucs.append(roc_auc_score(y_t, y_p))\n",
    "                kappas.append(cohen_kappa_score(y_t, np.around(y_p)))\n",
    "        layers.append(lay)\n",
    "        dimention.append(dim)\n",
    "        auc.append(np.mean(aucs))\n",
    "        kappa.append(np.mean(kappas))\n",
    "        print(f'auc: {auc[-1]}')\n",
    "        print(f'kappa: {kappa[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "for i in range(3):\n",
    "    plt.plot(dimention[i*(MAX_POWER+1):i*(MAX_POWER+1)+MAX_POWER+1], auc[i*(MAX_POWER+1):i*(MAX_POWER+1)+MAX_POWER+1], marker='.', label=f'{i+1} Layer LSTM')\n",
    "plt.xlabel('Projected Dimensions')\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.title('BiLSTM Results')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "for i in range(3):\n",
    "    plt.plot(dimention[i*(MAX_POWER+1):i*(MAX_POWER+1)+MAX_POWER+1], kappa[i*(MAX_POWER+1):i*(MAX_POWER+1)+MAX_POWER+1], marker='.', label=f'{i+1} Layer LSTM')\n",
    "plt.xlabel('Projected Dimensions')\n",
    "plt.ylabel('Cohen\\'s Kappa')\n",
    "plt.title('BiLSTM Results')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
