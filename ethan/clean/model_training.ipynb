{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Masking, Dense, LSTM, Bidirectional, TimeDistributed\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import evaluationutility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "WARNING:tensorflow:From C:\\Users\\Ethan\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\Ethan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "auc: 0.5534188576995415, kappa: 0.06843059645027565\n",
      "0 2\n"
     ]
    }
   ],
   "source": [
    "#Trained LSTM\n",
    "\n",
    "FOLDS = 5\n",
    "MAX_POWER = 9\n",
    "MAX_LAYER = 5\n",
    "TRIALS = 5\n",
    "\n",
    "gkf = GroupKFold(n_splits=FOLDS)\n",
    "mms = MinMaxScaler()\n",
    "ss = StandardScaler()\n",
    "\n",
    "for source in ['raw', 'expert']:\n",
    "    \n",
    "    input_data = pk.load(open(f'data/padded_{source}_input.pkl', 'rb'))\n",
    "    input_data = np.stack(input_data)\n",
    "    target_data = pk.load(open(f'data/padded_{source}_target.pkl', 'rb'))\n",
    "    target_data = np.stack(target_data)\n",
    "    weight_data = pk.load(open(f'data/padded_{source}_weight.pkl', 'rb'))\n",
    "    weight_data = np.equal(np.stack(weight_data), 1)\n",
    "    group_data = np.array(pk.load(open(f'data/padded_{source}_sid.pkl', 'rb')))\n",
    "    \n",
    "    layers = []\n",
    "    dimention = []\n",
    "    auc = []\n",
    "    kappa = []\n",
    "    \n",
    "    for lay in range(MAX_LAYER):\n",
    "        for dim in np.power(2, np.arange(MAX_POWER+1)):\n",
    "            print(lay, dim)\n",
    "            \n",
    "            aucs = []\n",
    "            kappas = []\n",
    "            \n",
    "            for trials in range(TRIALS):\n",
    "                for train_index, test_index in gkf.split(input_data, target_data, group_data):\n",
    "                    \n",
    "                    X_train, X_test = input_data[train_index,:,:], input_data[test_index,:,:]\n",
    "                    y_train, y_test = target_data[train_index,:,:], target_data[test_index,:,:]\n",
    "                    w_train, w_test = weight_data[train_index,:], weight_data[test_index,:]\n",
    "\n",
    "                    keras.backend.clear_session()\n",
    "                    lstm = Sequential()\n",
    "                    lstm.add(Masking(mask_value=0.0, input_shape=(input_data[0].shape)))\n",
    "                    for i in range(lay):\n",
    "                        lstm.add(LSTM(dim, activation='tanh', return_sequences=True))\n",
    "                    lstm.add(TimeDistributed(Dense(target_data.shape[2], activation='softmax')))\n",
    "                    lstm.compile(optimizer='adam', loss='categorical_crossentropy', sample_weight_mode='temporal')\n",
    "\n",
    "                    es = [EarlyStopping(monitor='val_loss', patience=3, min_delta=0, restore_best_weights=True)]\n",
    "                    lstm.fit(X_train, y_train, epochs=1000, validation_split=0.25, callbacks=es, verbose=False)\n",
    "\n",
    "                    y_pred = lstm.predict(X_test)\n",
    "                    test_p = []\n",
    "                    test_t = []\n",
    "                    for p, t, w in zip(y_pred, y_test, w_test):\n",
    "                        test_p.append(p[w.flatten(), :])\n",
    "                        test_t.append(t[w.flatten(), :])\n",
    "                    test_p = np.concatenate(test_p)\n",
    "                    test_t = np.concatenate(test_t)\n",
    "                    test_p = mms.fit_transform(test_p)\n",
    "                    aucs.append(evaluationutility.auc(test_t, test_p))\n",
    "                    kappas.append(evaluationutility.cohen_kappa_multiclass(test_t, test_p))\n",
    "                    \n",
    "            layers.append(lay)\n",
    "            dimention.append(dim)\n",
    "            auc.append(np.mean(aucs))\n",
    "            kappa.append(np.mean(kappas))\n",
    "            print(f'auc: {auc[-1]}, kappa: {kappa[-1]}')\n",
    "            \n",
    "    for i in range(MAX_LAYER):\n",
    "        plt.plot(dimention[i*(MAX_POWER+1):i*(MAX_POWER+1)+MAX_POWER+1], auc[i*(MAX_POWER+1):i*(MAX_POWER+1)+MAX_POWER+1], marker='.', label=f'{i} Hidden Layer LSTM')\n",
    "    plt.xlabel('Hidden Layer Nodes')\n",
    "    plt.ylabel('ROC AUC')\n",
    "    plt.title('Trained LSTM Results on ' + ('Raw' if source == 'raw' else 'Expert') + ' Features')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.figure()\n",
    "    for i in range(MAX_LAYER):\n",
    "        plt.plot(dimention[i*(MAX_POWER+1):i*(MAX_POWER+1)+MAX_POWER+1], kappa[i*(MAX_POWER+1):i*(MAX_POWER+1)+MAX_POWER+1], marker='.', label=f'{i} Hidden Layer LSTM')\n",
    "    plt.xlabel('Hidden Layer Nodes')\n",
    "    plt.ylabel('Cohen\\'s Kappa')\n",
    "    plt.title('Trained LSTM Results on ' + ('Raw' if source == 'raw' else 'Expert') + ' Features')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trained BiLSTM\n",
    "\n",
    "FOLDS = 5\n",
    "MAX_POWER = 9\n",
    "MAX_LAYER = 5\n",
    "TRIALS = 5\n",
    "\n",
    "gkf = GroupKFold(n_splits=FOLDS)\n",
    "mms = MinMaxScaler()\n",
    "ss = StandardScaler()\n",
    "\n",
    "for source in ['raw', 'expert']:\n",
    "    \n",
    "    input_data = pk.load(open(f'data/padded_{source}_input.pkl', 'rb'))\n",
    "    input_data = np.stack(input_data)\n",
    "    target_data = pk.load(open(f'data/padded_{source}_target.pkl', 'rb'))\n",
    "    target_data = np.stack(target_data)\n",
    "    weight_data = pk.load(open(f'data/padded_{source}_weight.pkl', 'rb'))\n",
    "    weight_data = np.equal(np.stack(weight_data), 1)\n",
    "    group_data = np.array(pk.load(open(f'data/padded_{source}_sid.pkl', 'rb')))\n",
    "    \n",
    "    layers = []\n",
    "    dimention = []\n",
    "    auc = []\n",
    "    kappa = []\n",
    "    \n",
    "    for lay in range(MAX_LAYER):\n",
    "        for dim in np.power(2, np.arange(MAX_POWER+1)):\n",
    "            print(lay, dim)\n",
    "            \n",
    "            aucs = []\n",
    "            kappas = []\n",
    "            \n",
    "            for trials in range(TRIALS):\n",
    "                for train_index, test_index in gkf.split(input_data, target_data, group_data):\n",
    "                    \n",
    "                    X_train, X_test = input_data[train_index,:,:], input_data[test_index,:,:]\n",
    "                    y_train, y_test = target_data[train_index,:,:], target_data[test_index,:,:]\n",
    "                    w_train, w_test = weight_data[train_index,:], weight_data[test_index,:]\n",
    "\n",
    "                    keras.backend.clear_session()\n",
    "                    lstm = Sequential()\n",
    "                    lstm.add(Masking(mask_value=0.0, input_shape=(input_data[0].shape)))\n",
    "                    for i in range(lay):\n",
    "                        lstm.add(LSTM(dim, activation='tanh', return_sequences=True))\n",
    "                    lstm.add(LSTM(target_data.shape[2], activation='softmax', return_sequences=True))\n",
    "                    lstm.compile(optimizer='adagrad', loss='categorical_crossentropy', sample_weight_mode='temporal')\n",
    "\n",
    "                    es = [EarlyStopping(monitor='val_loss', patience=3, min_delta=0, restore_best_weights=True)]\n",
    "                    lstm.fit(X_train, y_train, epochs=1000, validation_split=0.25, callbacks=es, verbose=True)\n",
    "\n",
    "                    y_pred = lstm.predict(X_test)\n",
    "                    test_p = []\n",
    "                    test_t = []\n",
    "                    for p, t, w in zip(y_pred, y_test, w_test):\n",
    "                        test_p.append(p[w, :])\n",
    "                        test_t.append(t[w, :])\n",
    "                    test_p = np.concatenate(test_p)\n",
    "                    test_t = np.concatenate(test_t)\n",
    "                    test_p = mms.fit_transform(test_p)\n",
    "                    aucs.append(evaluationutility.auc(test_t, test_p))\n",
    "                    kappas.append(evaluationutility.cohen_kappa_multiclass(test_t, test_p))\n",
    "                    print(f'auc: {aucs[-1]}, kappa: {kappas[-1]}')\n",
    "                    \n",
    "            layers.append(lay)\n",
    "            dimention.append(dim)\n",
    "            auc.append(np.mean(aucs))\n",
    "            kappa.append(np.mean(kappas))\n",
    "            \n",
    "    for i in range(MAX_LAYER):\n",
    "        plt.plot(dimention[i*(MAX_POWER+1):i*(MAX_POWER+1)+MAX_POWER+1], auc[i*(MAX_POWER+1):i*(MAX_POWER+1)+MAX_POWER+1], marker='.', label=f'{i} Hidden Layer LSTM')\n",
    "    plt.xlabel('Hidden Layer Nodes')\n",
    "    plt.ylabel('ROC AUC')\n",
    "    plt.title('Trained BiLSTM Results on ' + ('Raw' if source == 'raw' else 'Expert') + ' Features')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.figure()\n",
    "    for i in range(MAX_LAYER):\n",
    "        plt.plot(dimention[i*(MAX_POWER+1):i*(MAX_POWER+1)+MAX_POWER+1], kappa[i*(MAX_POWER+1):i*(MAX_POWER+1)+MAX_POWER+1], marker='.', label=f'{i} Hidden Layer LSTM')\n",
    "    plt.xlabel('Hidden Layer Nodes')\n",
    "    plt.ylabel('Cohen\\'s Kappa')\n",
    "    plt.title('Trained BiLSTM Results on ' + ('Raw' if source == 'raw' else 'Expert') + ' Features')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trained BiLSTM\n",
    "\n",
    "FOLDS = 5\n",
    "MAX_POWER = 9\n",
    "MAX_LAYER = 4\n",
    "TRIALS = 5\n",
    "\n",
    "kf = KFold(n_splits=FOLDS, shuffle=True)\n",
    "mms = MinMaxScaler()\n",
    "ss = StandardScaler()\n",
    "\n",
    "for source in ['raw', 'expert']:\n",
    "    \n",
    "    input_data = pk.load(open(f'data/padded_{source}_input.pkl', 'rb'))\n",
    "    input_data = np.stack(input_data)\n",
    "    target_data = pk.load(open(f'data/padded_{source}_target.pkl', 'rb'))\n",
    "    target_data = np.stack(target_data)\n",
    "    weight_data = pk.load(open(f'data/padded_{source}_weight.pkl', 'rb'))\n",
    "    weight_data = np.equal(np.stack(weight_data), 1)\n",
    "    \n",
    "    layers = []\n",
    "    dimention = []\n",
    "    auc = []\n",
    "    kappa = []\n",
    "    \n",
    "    for lay in range(1, MAX_LAYER+1):\n",
    "        for dim in np.power(2, np.arange(MAX_POWER+1)):\n",
    "            print(lay, dim)\n",
    "            \n",
    "            aucs = []\n",
    "            kappas = []\n",
    "            \n",
    "            for trials in range(TRIALS):\n",
    "                for train_index, test_index in kf.split(weight_data):\n",
    "                    \n",
    "                    X_train, X_test = input_data[train_index,:,:], input_data[test_index,:,:]\n",
    "                    y_train, y_test = target_data[train_index,:,:], target_data[test_index,:,:]\n",
    "                    w_train, w_test = weight_data[train_index,:], weight_data[test_index,:]\n",
    "\n",
    "                    keras.backend.clear_session()\n",
    "                    bilstm = Sequential()\n",
    "                    bilstm.add(Bidirectional(LSTM(dim, activation='tanh', return_sequences=True), input_shape=(input_data[0].shape)))\n",
    "                    for i in range(lay-1):\n",
    "                        bilstm.add(Bidirectional(LSTM(dim, activation='tanh', return_sequences=True)))\n",
    "                    bilstm.add(TimeDistributed(Dense(target_data.shape[2], activation='softmax')))\n",
    "                    bilstm.compile(optimizer='adam', loss='categorical_crossentropy', sample_weight_mode='temporal')\n",
    "\n",
    "                    es = [EarlyStopping(monitor='val_loss', patience=3, min_delta=0, restore_best_weights=True)]\n",
    "                    bilstm.fit(X_train, y_train, sample_weight=w_train, epochs=1000, validation_split=0.25, callbacks=es, verbose=True)\n",
    "\n",
    "                    y_pred = bilstm.predict(X_test)\n",
    "                    test_p = []\n",
    "                    test_t = []\n",
    "                    for p, t, w in zip(y_pred, y_test, weight_data):\n",
    "                        test_p.append(p[w, :])\n",
    "                        test_t.append(t[w, :])\n",
    "                    test_p = np.concatenate(test_p)\n",
    "                    test_t = np.concatenate(test_t)\n",
    "                    aucs.append(evaluationutility.auc(test_t, test_p))\n",
    "                    kappas.append(evaluationutility.cohen_kappa_multiclass(test_t, test_p))\n",
    "                    print(f'auc: {aucs[-1]}, kappa: {kappas[-1]}')\n",
    "                    \n",
    "            layers.append(lay)\n",
    "            dimention.append(dim)\n",
    "            auc.append(np.mean(aucs))\n",
    "            kappa.append(np.mean(kappas))\n",
    "            \n",
    "    plt.figure()\n",
    "    for i in range(MAX_LAYER):\n",
    "        plt.plot(dimention[i*(MAX_POWER+1):i*(MAX_POWER+1)+MAX_POWER+1], auc[i*(MAX_POWER+1):i*(MAX_POWER+1)+MAX_POWER+1], marker='.', label=f'{i+1} Layer BiLSTM')\n",
    "    plt.xlabel('Hidden Layer Nodes')\n",
    "    plt.ylabel('ROC AUC')\n",
    "    plt.title('Trained BiLSTM Results on ' + ('Raw' if source == 'raw' else 'Expert') + ' Features')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.figure()\n",
    "    for i in range(MAX_LAYER):\n",
    "        plt.plot(dimention[i*(MAX_POWER+1):i*(MAX_POWER+1)+MAX_POWER+1], kappa[i*(MAX_POWER+1):i*(MAX_POWER+1)+MAX_POWER+1], marker='.', label=f'{i+1} Layer BiLSTM')\n",
    "    plt.xlabel('Hidden Layer Nodes')\n",
    "    plt.ylabel('Cohen\\'s Kappa')\n",
    "    plt.title('Trained BiLSTM Results on ' + ('Raw' if source == 'raw' else 'Expert') + ' Features')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
