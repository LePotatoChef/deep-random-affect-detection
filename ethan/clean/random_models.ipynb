{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Bidirectional\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import cohen_kappa_score, roc_auc_score\n",
    "import evaluationutility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Function\n",
    "\n",
    "def lrcv(k, X, y):\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True)\n",
    "    mms = MinMaxScaler()\n",
    "    # Train a logistic regression for each fold\n",
    "    aucs = []\n",
    "    kappas = []\n",
    "    # Calculate metrics for each affect\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train_raw, y_test_raw = y[train_index], y[test_index]\n",
    "        \n",
    "        y_train = np.zeros((y_train_raw.size, y_train_raw.max()+1))\n",
    "        y_train[np.arange(y_train_raw.size),y_train_raw] = 1\n",
    "        y_test = np.zeros((y_test_raw.size, y_test_raw.max()+1))\n",
    "        y_test[np.arange(y_test_raw.size),y_test_raw] = 1\n",
    "        \n",
    "        log_reg = Sequential()\n",
    "        log_reg.add(Dense(4, activation='sigmoid', input_shape=(X_train.shape[1],)))\n",
    "        log_reg.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "        es = [EarlyStopping(monitor='loss', patience=5, min_delta=0.0001)]\n",
    "        log_reg.fit(X_train, y_train, callbacks=es, verbose=False)\n",
    "        \n",
    "        y_pred = log_reg.predict(X_test)\n",
    "        aucs.append(evaluationutility.auc(y_test, y_pred))\n",
    "        kappas.append(evaluationutility.cohen_kappa_multiclass(y_test, y_pred))\n",
    "    return np.mean(aucs), np.mean(kappas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Pooling 1\n",
      "Max Pooling 2\n",
      "Max Pooling 4\n",
      "Max Pooling 8\n",
      "Max Pooling 16\n",
      "Max Pooling 32\n"
     ]
    }
   ],
   "source": [
    "# BOREP\n",
    "\n",
    "TRIALS = 5\n",
    "FOLDS = 5\n",
    "MAX_POWER = 12\n",
    "\n",
    "for source in ['raw', 'expert']:\n",
    "    input_data = pk.load(open(f'data/bagged_{source}_input.pkl', 'rb'))\n",
    "    target_data = pk.load(open(f'data/bagged_{source}_target.pkl', 'rb'))\n",
    "    pooling = []\n",
    "    dimention = []\n",
    "    auc = []\n",
    "    kappa = []\n",
    "    for pooling_name, pooling_function in zip(['Max Pooling', 'Mean Pooling'], [np.max, np.mean]):\n",
    "        for dim in np.power(2, np.arange(MAX_POWER+1)):\n",
    "            print(pooling_name, dim)\n",
    "            aucs = []\n",
    "            kappas = []\n",
    "            for i in range(TRIALS):\n",
    "                random_embedding = (np.random.rand(input_data[0].shape[1], dim) * 2 - 1) / np.sqrt(input_data[0].shape[1])\n",
    "                log_input = []\n",
    "                log_target = []\n",
    "                for input_batch in input_data:\n",
    "                    embedded_input = np.dot(input_batch, random_embedding)\n",
    "                    embedded_input = pooling_function(embedded_input, axis=0)\n",
    "                    log_input.append(embedded_input)\n",
    "                log_input = np.stack(log_input)\n",
    "                # Get the average auc and kappa for all affects and folds\n",
    "                mean_auc, mean_kappa = lrcv(FOLDS, log_input, np.argmax(target_data, axis=1).astype(int))\n",
    "                aucs.append(mean_auc)\n",
    "                kappas.append(mean_kappa)\n",
    "            pooling.append(pooling_name)\n",
    "            dimention.append(log_input.shape[1])\n",
    "            auc.append(np.mean(aucs))\n",
    "            kappa.append(np.mean(kappas))\n",
    "    plt.figure()\n",
    "    plt.plot(dimention[MAX_POWER+1:], auc[MAX_POWER+1:], marker='.', label='Max Pooling')\n",
    "    plt.plot(dimention[:MAX_POWER+1], auc[:MAX_POWER+1], marker='.', label='Mean Pooling')\n",
    "    plt.xlabel('Projected Dimensions')\n",
    "    plt.ylabel('ROC AUC')\n",
    "    plt.title('Bag of Random Embeddings Results on ' + 'Raw' if source == 'raw' else 'Expert' + ' Features')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.figure()\n",
    "    plt.plot(dimention[MAX_POWER+1:], kappa[MAX_POWER+1:], marker='.', label='Max Pooling')\n",
    "    plt.plot(dimention[:MAX_POWER+1], kappa[:MAX_POWER+1], marker='.', label='Mean Pooling')\n",
    "    plt.xlabel('Projected Dimensions')\n",
    "    plt.ylabel('Cohen\\'s Kappa')\n",
    "    plt.title('Bag of Random Embeddings Results on ' + 'Raw' if source == 'raw' else 'Expert' + ' Features')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLSTM\n",
    "\n",
    "TRIALS = 5\n",
    "FOLDS = 5\n",
    "MAX_POWER = 12\n",
    "LAYERS = 2\n",
    "\n",
    "for source in ['raw', 'expert']:\n",
    "    input_data = pk.load(open(f'data/bagged_{source}_input.pkl', 'rb'))\n",
    "    target_data = pk.load(open(f'data/bagged_{source}_target.pkl', 'rb'))\n",
    "    pooling = []\n",
    "    dimention = []\n",
    "    auc = []\n",
    "    kappa = []\n",
    "    for lay in range(1,LAYERS+1):\n",
    "        for dim in np.power(2, np.arange(MAX_POWER+1)):\n",
    "            print(lay, dim)\n",
    "            aucs = []\n",
    "            kappas = []\n",
    "            for i in range(TRIALS):\n",
    "                # Make the LSTM\n",
    "                rand_lstm = Sequential()\n",
    "                rand_lstm.add(LSTM(dim, activation='tanh', return_sequences=True, input_shape=(1, input_data[0].shape[1])))\n",
    "                for l in range(lay-1):\n",
    "                    rand_lstm.add(LSTM(dim, activation='tanh', return_sequences=True))\n",
    "                rand_lstm.compile(optimizer='adam', loss='mse')\n",
    "                # Project each input into higher dimensions\n",
    "                log_input = []\n",
    "                for input_batch in input_data:\n",
    "                    input_batch = input_batch.reshape(input_batch.shape[0], 1, input_batch.shape[1])\n",
    "                    batch_out = rand_lstm.predict(input_batch)\n",
    "                    log_input.append(batch_out[-1,:,:].flatten())\n",
    "                    rand_lstm.reset_states()\n",
    "                log_input = np.stack(log_input)\n",
    "                # Get the average auc and kappa for all affects and folds\n",
    "                mean_auc, mean_kappa = lrcv(FOLDS, log_input, np.argmax(target_data, axis=1).astype(int))\n",
    "                aucs.append(mean_auc)\n",
    "                kappas.append(mean_kappa)\n",
    "            layers.append(lay)\n",
    "            dimention.append(log_input.shape[1])\n",
    "            auc.append(np.mean(aucs))\n",
    "            kappa.append(np.mean(kappas))\n",
    "    plt.figure()\n",
    "    plt.plot(dimention[MAX_POWER+1:], auc[MAX_POWER+1:], marker='.', label='Max Pooling')\n",
    "    plt.plot(dimention[:MAX_POWER+1], auc[:MAX_POWER+1], marker='.', label='Mean Pooling')\n",
    "    plt.xlabel('Projected Dimensions')\n",
    "    plt.ylabel('ROC AUC')\n",
    "    plt.title('Bag of Random Embeddings Results on ' + 'Raw' if source == 'raw' else 'Expert' + ' Features')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.figure()\n",
    "    plt.plot(dimention[MAX_POWER+1:], kappa[MAX_POWER+1:], marker='.', label='Max Pooling')\n",
    "    plt.plot(dimention[:MAX_POWER+1], kappa[:MAX_POWER+1], marker='.', label='Mean Pooling')\n",
    "    plt.xlabel('Projected Dimensions')\n",
    "    plt.ylabel('Cohen\\'s Kappa')\n",
    "    plt.title('Bag of Random Embeddings Results on ' + 'Raw' if source == 'raw' else 'Expert' + ' Features')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for i in range(3):\n",
    "    plt.plot(dimention[i*(MAX_POWER+1):i*(MAX_POWER+1)+MAX_POWER+1], auc[i*(MAX_POWER+1):i*(MAX_POWER+1)+MAX_POWER+1], marker='.', label=f'{i+1} Layer LSTM')\n",
    "plt.xlabel('Projected Dimensions')\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.title('Random LSTM Results')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "for i in range(3):\n",
    "    plt.plot(dimention[i*(MAX_POWER+1):i*(MAX_POWER+1)+MAX_POWER+1], kappa[i*(MAX_POWER+1):i*(MAX_POWER+1)+MAX_POWER+1], marker='.', label=f'{i+1} Layer LSTM')\n",
    "plt.xlabel('Projected Dimensions')\n",
    "plt.ylabel('Cohen\\'s Kappa')\n",
    "plt.title('Random LSTM Results')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBLSTM\n",
    "\n",
    "TRIALS = 1\n",
    "FOLDS = 5\n",
    "MAX_POWER = 11\n",
    "LAYERS = 2\n",
    "\n",
    "input_data = pk.load(open('input_data.pkl', 'rb'))\n",
    "target_data = pk.load(open('target_data.pkl', 'rb'))\n",
    "\n",
    "layers = []\n",
    "dimention = []\n",
    "auc = []\n",
    "kappa = []\n",
    "\n",
    "for lay in range(1,LAYERS+1):\n",
    "    for dim in np.power(2, np.arange(MAX_POWER+1)):\n",
    "        print(lay, dim)\n",
    "        aucs = []\n",
    "        kappas = []\n",
    "        for i in range(TRIALS):\n",
    "            # Make the LSTM\n",
    "            rand_lstm = Sequential()\n",
    "            rand_lstm.add(Bidirectional(LSTM(dim, activation='tanh', return_sequences=True), input_shape=(1, input_data[0].shape[1])))\n",
    "            for l in range(lay-1):\n",
    "                rand_lstm.add(Bidirectional(LSTM(dim, activation='tanh', return_sequences=True)))\n",
    "            rand_lstm.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "            # Project each input into higher dimensions\n",
    "            log_input = []\n",
    "            for input_batch in input_data:\n",
    "                input_batch = input_batch.reshape(input_batch.shape[0], 1, input_batch.shape[1])\n",
    "                batch_out = rand_lstm.predict(input_batch)\n",
    "                log_input.append(batch_out[-1,:,:].flatten())\n",
    "                rand_lstm.reset_states()\n",
    "            log_input = np.stack(log_input)\n",
    "            # Get the average auc and kappa for all affects and folds\n",
    "            mean_auc, mean_kappa = lrcv(FOLDS, log_input, np.argmax(target_data, axis=1).astype(int))\n",
    "            aucs.append(mean_auc)\n",
    "            kappas.append(mean_kappa)\n",
    "        layers.append(lay)\n",
    "        dimention.append(log_input.shape[1])\n",
    "        auc.append(np.mean(aucs))\n",
    "        kappa.append(np.mean(kappas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for i in range(3):\n",
    "    plt.plot(dimention[i*(MAX_POWER+1):i*(MAX_POWER+1)+MAX_POWER+1], auc[i*(MAX_POWER+1):i*(MAX_POWER+1)+MAX_POWER+1], marker='.', label=f'{i+1} Layer LSTM')\n",
    "plt.xlabel('Projected Dimensions')\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.title('Random BiLSTM Results')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "for i in range(3):\n",
    "    plt.plot(dimention[i*(MAX_POWER+1):i*(MAX_POWER+1)+MAX_POWER+1], kappa[i*(MAX_POWER+1):i*(MAX_POWER+1)+MAX_POWER+1], marker='.', label=f'{i+1} Layer LSTM')\n",
    "plt.xlabel('Projected Dimensions')\n",
    "plt.ylabel('Cohen\\'s Kappa')\n",
    "plt.title('Random BiLSTM Results')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLRBLSTM\n",
    "\n",
    "TRIALS = 5\n",
    "FOLDS = 5\n",
    "MAX_POWER = 11\n",
    "LAYERS = 2\n",
    "\n",
    "input_data = pk.load(open('input_data.pkl', 'rb'))\n",
    "target_data = pk.load(open('target_data.pkl', 'rb'))\n",
    "\n",
    "layers = []\n",
    "dimention = []\n",
    "auc = []\n",
    "kappa = []\n",
    "\n",
    "for lay in range(1,4):\n",
    "    for dim in np.power(2, np.arange(MAX_POWER+1)):\n",
    "        print(lay, dim)\n",
    "        aucs = []\n",
    "        kappas = []\n",
    "        for i in range(TRIALS):\n",
    "            # Make the LSTM\n",
    "            rand_lstm = Sequential()\n",
    "            rand_lstm.add(Bidirectional(LSTM(max(dim-lay+1, 1), activation='tanh', return_sequences=True), input_shape=(1, input_data[0].shape[1])))\n",
    "            for l in range(lay-1):\n",
    "                rand_lstm.add(Bidirectional(LSTM(max(dim-lay+1, 1), activation='tanh', return_sequences=True)))\n",
    "            rand_lstm.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "            outputs =[l.output for l in rand_lstm.layers]\n",
    "            inter_model = keras.Model(inputs=rand_lstm.inputs, outputs=outputs)\n",
    "            # Project each input into higher dimensions\n",
    "            log_input = []\n",
    "            for input_batch in input_data:\n",
    "                input_batch = input_batch.reshape(input_batch.shape[0], 1, input_batch.shape[1])\n",
    "                batch_out = np.stack(inter_model.predict(input_batch))\n",
    "                batch_out = batch_out[-1,:,:].flatten() if lay == 1 else batch_out[:,-1,:,:].flatten()\n",
    "                log_input.append(batch_out)\n",
    "                rand_lstm.reset_states()\n",
    "            log_input = np.stack(log_input)\n",
    "            # Get the average auc and kappa for all affects and folds\n",
    "            mean_auc, mean_kappa = lrcv(FOLDS, log_input, np.array(target_data).astype(int))\n",
    "            aucs.append(mean_auc)\n",
    "            kappas.append(mean_kappa)\n",
    "        layers.append(lay)\n",
    "        dimention.append(log_input.shape[1])\n",
    "        auc.append(np.mean(aucs))\n",
    "        kappa.append(np.mean(kappas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for i in range(3):\n",
    "    plt.plot(dimention[i*MAX_POWER+1:i*MAX_POWER+1+MAX_POWER+1], auc[i*MAX_POWER+1:i*MAX_POWER+1+MAX_POWER+1], marker='.', label=f'{i+1} Layer LSTM')\n",
    "plt.xlabel('Projected Dimensions')\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.title('Interlayer Random Bidirectional LSTM Results')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "for i in range(3):\n",
    "    plt.plot(dimention[i*MAX_POWER+1:i*MAX_POWER+1+MAX_POWER+1], kappa[i*MAX_POWER+1:i*MAX_POWER+1+MAX_POWER+1], marker='.', label=f'{i+1} Layer LSTM')\n",
    "plt.xlabel('Projected Dimensions')\n",
    "plt.ylabel('Cohen\\'s Kappa')\n",
    "plt.title('Interlayer Random Bidirectional LSTM Results')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
