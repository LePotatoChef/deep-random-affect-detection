{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, BatchNormalization, Dense, Conv1D, Activation, Add, GlobalAveragePooling1D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import cohen_kappa_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet(input_shape, n_feature_maps, nb_classes):\n",
    "    x = Input(shape=(input_shape))\n",
    "    conv_x = BatchNormalization()(x)\n",
    "    conv_x = Conv1D(n_feature_maps, kernel_size=8, strides=1, padding='same')(conv_x)\n",
    "    conv_x = BatchNormalization()(conv_x)\n",
    "    conv_x = Activation('relu')(conv_x)\n",
    "    conv_y = Conv1D(n_feature_maps, kernel_size=5, strides=1, padding='same')(conv_x)\n",
    "    conv_y = BatchNormalization()(conv_y)\n",
    "    conv_y = Activation('relu')(conv_y)\n",
    "    conv_z = Conv1D(n_feature_maps, kernel_size=3, strides=1, padding='same')(conv_y)\n",
    "    conv_z = BatchNormalization()(conv_z)\n",
    "    is_expand_channels = not (input_shape[-1] == n_feature_maps)\n",
    "    if is_expand_channels:\n",
    "        shortcut_y = Conv1D(n_feature_maps, 1, strides=1, padding='same')(x)\n",
    "        shortcut_y = BatchNormalization()(shortcut_y)\n",
    "    else:\n",
    "        shortcut_y = BatchNormalization()(x)\n",
    "    y = Add()([shortcut_y, conv_z])\n",
    "    y = Activation('relu')(y)\n",
    "    x1 = y\n",
    "    conv_x = Conv1D(n_feature_maps*2, kernel_size=8, strides=1, padding='same')(x1)\n",
    "    conv_x = BatchNormalization()(conv_x)\n",
    "    conv_x = Activation('relu')(conv_x)\n",
    "    conv_y = Conv1D(n_feature_maps*2, kernel_size=5, strides=1, padding='same')(conv_x)\n",
    "    conv_y = BatchNormalization()(conv_y)\n",
    "    conv_y = Activation('relu')(conv_y)\n",
    "    conv_z = Conv1D(n_feature_maps*2, kernel_size=3, strides=1, padding='same')(conv_y)\n",
    "    conv_z = BatchNormalization()(conv_z)\n",
    "    is_expand_channels = not (input_shape[-1] == n_feature_maps*2)\n",
    "    if is_expand_channels:\n",
    "        shortcut_y = Conv1D(n_feature_maps*2, kernel_size=1, strides=1, padding='same')(x1)\n",
    "        shortcut_y = BatchNormalization()(shortcut_y)\n",
    "    else:\n",
    "        shortcut_y = BatchNormalization()(x1)\n",
    "    y = Add()([shortcut_y, conv_z])\n",
    "    y = Activation('relu')(y)\n",
    "    x1 = y\n",
    "    conv_x = Conv1D(n_feature_maps*2, kernel_size=8, strides=1, padding='same')(x1)\n",
    "    conv_x = BatchNormalization()(conv_x)\n",
    "    conv_x = Activation('relu')(conv_x)\n",
    "    conv_y = Conv1D(n_feature_maps*2, kernel_size=5, strides=1, padding='same')(conv_x)\n",
    "    conv_y = BatchNormalization()(conv_y)\n",
    "    conv_y = Activation('relu')(conv_y)\n",
    "    conv_z = Conv1D(n_feature_maps*2, kernel_size=3, strides=1, padding='same')(conv_y)\n",
    "    conv_z = BatchNormalization()(conv_z)\n",
    "    is_expand_channels = not (input_shape[-1] == n_feature_maps*2)\n",
    "    if is_expand_channels:\n",
    "        shortcut_y = Conv1D(n_feature_maps*2, kernel_size=1, strides=1, padding='same')(x1)\n",
    "        shortcut_y = BatchNormalization()(shortcut_y)\n",
    "    else:\n",
    "        shortcut_y = BatchNormalization()(x1)\n",
    "    y = Add()([shortcut_y, conv_z])\n",
    "    y = Activation('relu')(y)\n",
    "    full = GlobalAveragePooling1D()(y)\n",
    "    out = Dense(nb_classes, activation='softmax')(full)\n",
    "    return x, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes: 8\n",
      "WARNING:tensorflow:From C:\\Users\\Ethan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1854 samples, validate on 618 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 3s 2ms/step - loss: 0.9828 - accuracy: 0.7071 - val_loss: 1.2115 - val_accuracy: 0.8366\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 1s 496us/step - loss: 0.6668 - accuracy: 0.8220 - val_loss: 1.0145 - val_accuracy: 0.8366\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 1s 495us/step - loss: 0.6213 - accuracy: 0.8220 - val_loss: 0.8943 - val_accuracy: 0.8366\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 1s 502us/step - loss: 0.6124 - accuracy: 0.8220 - val_loss: 0.8098 - val_accuracy: 0.8366\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 1s 500us/step - loss: 0.6099 - accuracy: 0.8220 - val_loss: 0.7813 - val_accuracy: 0.8366\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 1s 506us/step - loss: 0.6046 - accuracy: 0.8220 - val_loss: 0.7372 - val_accuracy: 0.8366\n",
      "Epoch 7/1000\n",
      "1854/1854 [==============================] - 1s 500us/step - loss: 0.6041 - accuracy: 0.8220 - val_loss: 0.7222 - val_accuracy: 0.8366\n",
      "Epoch 8/1000\n",
      "1854/1854 [==============================] - 1s 505us/step - loss: 0.6045 - accuracy: 0.8220 - val_loss: 0.6815 - val_accuracy: 0.8366\n",
      "Epoch 9/1000\n",
      "1854/1854 [==============================] - 1s 503us/step - loss: 0.6002 - accuracy: 0.8220 - val_loss: 0.6661 - val_accuracy: 0.8366\n",
      "Epoch 10/1000\n",
      "1854/1854 [==============================] - 1s 502us/step - loss: 0.5990 - accuracy: 0.8220 - val_loss: 0.6676 - val_accuracy: 0.8366\n",
      "Epoch 11/1000\n",
      "1854/1854 [==============================] - 1s 498us/step - loss: 0.5997 - accuracy: 0.8220 - val_loss: 0.6663 - val_accuracy: 0.8366\n",
      "Epoch 12/1000\n",
      "1854/1854 [==============================] - 1s 494us/step - loss: 0.5984 - accuracy: 0.8220 - val_loss: 0.6600 - val_accuracy: 0.8366\n",
      "Epoch 13/1000\n",
      "1854/1854 [==============================] - 1s 508us/step - loss: 0.5956 - accuracy: 0.8220 - val_loss: 0.6630 - val_accuracy: 0.8366\n",
      "Epoch 14/1000\n",
      "1854/1854 [==============================] - 1s 495us/step - loss: 0.5972 - accuracy: 0.8220 - val_loss: 0.6808 - val_accuracy: 0.8366\n",
      "Epoch 15/1000\n",
      "1854/1854 [==============================] - 1s 508us/step - loss: 0.5960 - accuracy: 0.8220 - val_loss: 0.6760 - val_accuracy: 0.8366\n",
      "Epoch 16/1000\n",
      "1854/1854 [==============================] - 1s 504us/step - loss: 0.5959 - accuracy: 0.8220 - val_loss: 0.6583 - val_accuracy: 0.8366\n",
      "Epoch 17/1000\n",
      "1854/1854 [==============================] - 1s 508us/step - loss: 0.5971 - accuracy: 0.8220 - val_loss: 0.6603 - val_accuracy: 0.8366\n",
      "Epoch 18/1000\n",
      "1854/1854 [==============================] - 1s 508us/step - loss: 0.5910 - accuracy: 0.8225 - val_loss: 0.6733 - val_accuracy: 0.8366\n",
      "Epoch 19/1000\n",
      "1854/1854 [==============================] - 1s 509us/step - loss: 0.5928 - accuracy: 0.8220 - val_loss: 0.6924 - val_accuracy: 0.8366\n",
      "Epoch 20/1000\n",
      "1854/1854 [==============================] - 1s 498us/step - loss: 0.5916 - accuracy: 0.8220 - val_loss: 0.7109 - val_accuracy: 0.8236\n",
      "Epoch 21/1000\n",
      "1854/1854 [==============================] - 1s 509us/step - loss: 0.5909 - accuracy: 0.8225 - val_loss: 0.6829 - val_accuracy: 0.8366\n",
      "Train on 1854 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 3s 1ms/step - loss: 1.0541 - accuracy: 0.6839 - val_loss: 0.9679 - val_accuracy: 0.8481\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 1s 513us/step - loss: 0.6876 - accuracy: 0.8177 - val_loss: 0.7530 - val_accuracy: 0.8481\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 1s 530us/step - loss: 0.6358 - accuracy: 0.8177 - val_loss: 0.6928 - val_accuracy: 0.8481\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 1s 528us/step - loss: 0.6263 - accuracy: 0.8177 - val_loss: 0.6712 - val_accuracy: 0.8481\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 1s 515us/step - loss: 0.6197 - accuracy: 0.8177 - val_loss: 0.6596 - val_accuracy: 0.8481\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 1s 517us/step - loss: 0.6167 - accuracy: 0.8177 - val_loss: 0.6476 - val_accuracy: 0.8481\n",
      "Epoch 7/1000\n",
      "1854/1854 [==============================] - 1s 511us/step - loss: 0.6150 - accuracy: 0.8177 - val_loss: 0.6327 - val_accuracy: 0.8481\n",
      "Epoch 8/1000\n",
      "1854/1854 [==============================] - 1s 511us/step - loss: 0.6141 - accuracy: 0.8177 - val_loss: 0.6416 - val_accuracy: 0.8481\n",
      "Epoch 9/1000\n",
      "1854/1854 [==============================] - 1s 502us/step - loss: 0.6104 - accuracy: 0.8177 - val_loss: 0.6473 - val_accuracy: 0.8481\n",
      "Epoch 10/1000\n",
      "1854/1854 [==============================] - 1s 512us/step - loss: 0.6126 - accuracy: 0.8177 - val_loss: 0.6297 - val_accuracy: 0.8481\n",
      "Epoch 11/1000\n",
      "1854/1854 [==============================] - 1s 515us/step - loss: 0.6113 - accuracy: 0.8177 - val_loss: 0.6403 - val_accuracy: 0.8481\n",
      "Epoch 12/1000\n",
      "1854/1854 [==============================] - 1s 513us/step - loss: 0.6100 - accuracy: 0.8177 - val_loss: 0.6529 - val_accuracy: 0.8481\n",
      "Epoch 13/1000\n",
      "1854/1854 [==============================] - 1s 515us/step - loss: 0.6060 - accuracy: 0.8177 - val_loss: 0.6270 - val_accuracy: 0.8481\n",
      "Epoch 14/1000\n",
      "1854/1854 [==============================] - 1s 510us/step - loss: 0.6048 - accuracy: 0.8177 - val_loss: 0.6367 - val_accuracy: 0.8481\n",
      "Epoch 15/1000\n",
      "1854/1854 [==============================] - 1s 520us/step - loss: 0.6059 - accuracy: 0.8177 - val_loss: 0.6348 - val_accuracy: 0.8481\n",
      "Epoch 16/1000\n",
      "1854/1854 [==============================] - 1s 510us/step - loss: 0.6046 - accuracy: 0.8177 - val_loss: 0.6350 - val_accuracy: 0.8481\n",
      "Epoch 17/1000\n",
      "1854/1854 [==============================] - 1s 510us/step - loss: 0.6016 - accuracy: 0.8172 - val_loss: 0.6471 - val_accuracy: 0.8481\n",
      "Epoch 18/1000\n",
      "1854/1854 [==============================] - 1s 524us/step - loss: 0.6014 - accuracy: 0.8161 - val_loss: 0.6337 - val_accuracy: 0.8481\n",
      "Train on 1856 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1856/1856 [==============================] - 3s 2ms/step - loss: 0.9166 - accuracy: 0.7748 - val_loss: 1.0556 - val_accuracy: 0.8352\n",
      "Epoch 2/1000\n",
      "1856/1856 [==============================] - 1s 525us/step - loss: 0.6550 - accuracy: 0.8217 - val_loss: 0.8643 - val_accuracy: 0.8352\n",
      "Epoch 3/1000\n",
      "1856/1856 [==============================] - 1s 523us/step - loss: 0.6225 - accuracy: 0.8217 - val_loss: 0.7753 - val_accuracy: 0.8352\n",
      "Epoch 4/1000\n",
      "1856/1856 [==============================] - 1s 530us/step - loss: 0.6167 - accuracy: 0.8217 - val_loss: 0.7241 - val_accuracy: 0.8352\n",
      "Epoch 5/1000\n",
      "1856/1856 [==============================] - 1s 523us/step - loss: 0.6148 - accuracy: 0.8217 - val_loss: 0.6844 - val_accuracy: 0.8352\n",
      "Epoch 6/1000\n",
      "1856/1856 [==============================] - 1s 531us/step - loss: 0.6094 - accuracy: 0.8217 - val_loss: 0.6823 - val_accuracy: 0.8352\n",
      "Epoch 7/1000\n",
      "1856/1856 [==============================] - 1s 522us/step - loss: 0.6043 - accuracy: 0.8217 - val_loss: 0.6652 - val_accuracy: 0.8352\n",
      "Epoch 8/1000\n",
      "1856/1856 [==============================] - 1s 527us/step - loss: 0.6039 - accuracy: 0.8217 - val_loss: 0.6854 - val_accuracy: 0.8352\n",
      "Epoch 9/1000\n",
      "1856/1856 [==============================] - 1s 541us/step - loss: 0.6034 - accuracy: 0.8217 - val_loss: 0.6547 - val_accuracy: 0.8352\n",
      "Epoch 10/1000\n",
      "1856/1856 [==============================] - 1s 552us/step - loss: 0.6008 - accuracy: 0.8217 - val_loss: 0.6556 - val_accuracy: 0.8352\n",
      "Epoch 11/1000\n",
      "1856/1856 [==============================] - 1s 585us/step - loss: 0.5996 - accuracy: 0.8217 - val_loss: 0.6772 - val_accuracy: 0.8158\n",
      "Epoch 12/1000\n",
      "1856/1856 [==============================] - 1s 530us/step - loss: 0.5997 - accuracy: 0.8211 - val_loss: 0.6870 - val_accuracy: 0.8174\n",
      "Epoch 13/1000\n",
      "1856/1856 [==============================] - 1s 562us/step - loss: 0.5946 - accuracy: 0.8211 - val_loss: 0.6889 - val_accuracy: 0.8158\n",
      "Epoch 14/1000\n",
      "1856/1856 [==============================] - 1s 568us/step - loss: 0.5937 - accuracy: 0.8211 - val_loss: 0.6770 - val_accuracy: 0.8158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 3s 2ms/step - loss: 0.8695 - accuracy: 0.7878 - val_loss: 0.8815 - val_accuracy: 0.8498\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 1s 552us/step - loss: 0.6700 - accuracy: 0.8164 - val_loss: 0.6913 - val_accuracy: 0.8498\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 1s 562us/step - loss: 0.6454 - accuracy: 0.8164 - val_loss: 0.6447 - val_accuracy: 0.8498\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 1s 535us/step - loss: 0.6319 - accuracy: 0.8164 - val_loss: 0.6210 - val_accuracy: 0.8498\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 1s 557us/step - loss: 0.6289 - accuracy: 0.8164 - val_loss: 0.6307 - val_accuracy: 0.8498\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 1s 530us/step - loss: 0.6250 - accuracy: 0.8164 - val_loss: 0.6268 - val_accuracy: 0.8498\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 1s 538us/step - loss: 0.6230 - accuracy: 0.8164 - val_loss: 0.6050 - val_accuracy: 0.8498\n",
      "Epoch 8/1000\n",
      "1857/1857 [==============================] - 1s 533us/step - loss: 0.6188 - accuracy: 0.8164 - val_loss: 0.6035 - val_accuracy: 0.8498\n",
      "Epoch 9/1000\n",
      "1857/1857 [==============================] - 1s 535us/step - loss: 0.6195 - accuracy: 0.8164 - val_loss: 0.6142 - val_accuracy: 0.8498\n",
      "Epoch 10/1000\n",
      "1857/1857 [==============================] - 1s 538us/step - loss: 0.6164 - accuracy: 0.8164 - val_loss: 0.6251 - val_accuracy: 0.8498\n",
      "Epoch 11/1000\n",
      "1857/1857 [==============================] - 1s 538us/step - loss: 0.6237 - accuracy: 0.8164 - val_loss: 0.6344 - val_accuracy: 0.8498\n",
      "Epoch 12/1000\n",
      "1857/1857 [==============================] - 1s 533us/step - loss: 0.6195 - accuracy: 0.8164 - val_loss: 0.6119 - val_accuracy: 0.8498\n",
      "Epoch 13/1000\n",
      "1857/1857 [==============================] - 1s 541us/step - loss: 0.6149 - accuracy: 0.8164 - val_loss: 0.6227 - val_accuracy: 0.8498\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 3s 2ms/step - loss: 1.0171 - accuracy: 0.7157 - val_loss: 1.2396 - val_accuracy: 0.8481\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 1s 558us/step - loss: 0.6996 - accuracy: 0.8169 - val_loss: 1.0749 - val_accuracy: 0.8481\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 1s 552us/step - loss: 0.6489 - accuracy: 0.8169 - val_loss: 0.9560 - val_accuracy: 0.8481\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 1s 550us/step - loss: 0.6337 - accuracy: 0.8169 - val_loss: 0.8421 - val_accuracy: 0.8481\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 1s 563us/step - loss: 0.6293 - accuracy: 0.8169 - val_loss: 0.7760 - val_accuracy: 0.8481\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 1s 542us/step - loss: 0.6258 - accuracy: 0.8169 - val_loss: 0.7162 - val_accuracy: 0.8481\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 1s 565us/step - loss: 0.6223 - accuracy: 0.8169 - val_loss: 0.6658 - val_accuracy: 0.8481\n",
      "Epoch 8/1000\n",
      "1857/1857 [==============================] - 1s 553us/step - loss: 0.6217 - accuracy: 0.8169 - val_loss: 0.6616 - val_accuracy: 0.8481\n",
      "Epoch 9/1000\n",
      "1857/1857 [==============================] - 1s 562us/step - loss: 0.6213 - accuracy: 0.8169 - val_loss: 0.6369 - val_accuracy: 0.8481\n",
      "Epoch 10/1000\n",
      "1857/1857 [==============================] - 1s 551us/step - loss: 0.6194 - accuracy: 0.8169 - val_loss: 0.6662 - val_accuracy: 0.8481\n",
      "Epoch 11/1000\n",
      "1857/1857 [==============================] - 1s 557us/step - loss: 0.6142 - accuracy: 0.8169 - val_loss: 0.6163 - val_accuracy: 0.8481\n",
      "Epoch 12/1000\n",
      "1857/1857 [==============================] - 1s 546us/step - loss: 0.6139 - accuracy: 0.8169 - val_loss: 0.6524 - val_accuracy: 0.8481\n",
      "Epoch 13/1000\n",
      "1857/1857 [==============================] - 1s 551us/step - loss: 0.6139 - accuracy: 0.8169 - val_loss: 0.6318 - val_accuracy: 0.8481\n",
      "Epoch 14/1000\n",
      "1857/1857 [==============================] - 1s 552us/step - loss: 0.6122 - accuracy: 0.8169 - val_loss: 0.6416 - val_accuracy: 0.8481\n",
      "Epoch 15/1000\n",
      "1857/1857 [==============================] - 1s 556us/step - loss: 0.6129 - accuracy: 0.8169 - val_loss: 0.6330 - val_accuracy: 0.8481\n",
      "Epoch 16/1000\n",
      "1857/1857 [==============================] - 1s 551us/step - loss: 0.6101 - accuracy: 0.8169 - val_loss: 0.6231 - val_accuracy: 0.8481\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'layers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-cb30c4f56236>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[0mkappas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcohen_kappa_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m     \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlay\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m     \u001b[0mdimention\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[0mauc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maucs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'layers' is not defined"
     ]
    }
   ],
   "source": [
    "FOLDS = 5\n",
    "PADDING = 100\n",
    "MAX_POWER = 10\n",
    "\n",
    "input_data = pk.load(open('input_data.pkl', 'rb'))\n",
    "target_data = pk.load(open('target_data.pkl', 'rb'))\n",
    "\n",
    "dimention = []\n",
    "auc = []\n",
    "kappa = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=FOLDS, shuffle=True)\n",
    "mms = MinMaxScaler()\n",
    "\n",
    "for dim in np.power(2, np.arange(3, MAX_POWER+1)):\n",
    "    print(f'nodes: {dim}')\n",
    "    aucs = []\n",
    "    kappas = []\n",
    "\n",
    "    # Prepare training batches\n",
    "    model_input = []\n",
    "    model_target = []\n",
    "    for i, t in zip(input_data, target_data):\n",
    "        model_input.append(np.concatenate([np.zeros((PADDING - 1, i.shape[1])), i])[:PADDING,:])\n",
    "        model_target.append(np.argmax(t))\n",
    "    model_input = np.array(model_input)\n",
    "    model_target = np.array(model_target)\n",
    "\n",
    "    # Prepare k-fold training and test sets\n",
    "    for train_index, test_index in skf.split(model_input, model_target):\n",
    "        model_target[train_index.astype(int)]\n",
    "        X_train_raw, X_test_raw = model_input[train_index], model_input[test_index]\n",
    "        y_train_raw, y_test_raw = model_target[train_index], model_target[test_index]\n",
    "\n",
    "        X_train = np.stack(X_train_raw)\n",
    "        X_test = np.stack(X_test_raw)\n",
    "\n",
    "        y_train = np.zeros((y_train_raw.size, y_train_raw.max() + 1))\n",
    "        y_train[np.arange(y_train_raw.size),y_train_raw] = 1\n",
    "        y_test = np.zeros((y_test_raw.size, y_test_raw.max() + 1))\n",
    "        y_test[np.arange(y_test_raw.size),y_test_raw] = 1\n",
    "\n",
    "        # Make the resnet\n",
    "        x, y = build_resnet(X_train.shape[1:], dim, target_data[0].size)\n",
    "        model = Model(inputs=x, outputs=y)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        es = EarlyStopping(monitor='val_loss', patience=5, min_delta=0, restore_best_weights=True) \n",
    "        model.fit(X_train, y_train, epochs=1000, validation_split=0.25, callbacks=[es], verbose=True)\n",
    "\n",
    "        # Get the average auc and kappa for all affects and folds\n",
    "        y_pred = model.predict(X_test, batch_size=1)\n",
    "        for y_t, y_p in zip(y_test.T, y_pred.T):\n",
    "            y_p = mms.fit_transform(y_p.reshape(-1, 1))\n",
    "            aucs.append(roc_auc_score(y_t, y_p))\n",
    "            kappas.append(cohen_kappa_score(y_t, np.around(y_p)))\n",
    "\n",
    "    dimention.append(dim)\n",
    "    auc.append(np.mean(aucs))\n",
    "    kappa.append(np.mean(kappas))\n",
    "    print(f'auc: {auc[-1]}')\n",
    "    print(f'kappa: {kappa[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(dimention[i*(MAX_POWER-2):i*(MAX_POWER-2)+MAX_POWER-2], auc[i*(MAX_POWER-2):i*(MAX_POWER-2)+MAX_POWER-2], marker='.')\n",
    "plt.xlabel('Projected Dimensions')\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.title('1d ResNet')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(dimention[i*(MAX_POWER-2):i*(MAX_POWER-2)+MAX_POWER-2], kappa[i*(MAX_POWER-2):i*(MAX_POWER-2)+MAX_POWER-2], marker='.')\n",
    "plt.xlabel('1dCNN w/ scaled softmax output')\n",
    "plt.ylabel('Cohen\\'s Kappa')\n",
    "plt.title('1d ResNet')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
