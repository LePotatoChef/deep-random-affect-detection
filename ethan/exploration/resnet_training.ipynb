{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, BatchNormalization, Dropout, Dense, Conv1D, SeparableConv1D, Activation, Add, GlobalAveragePooling1D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import cohen_kappa_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROPOUT = 0.25\n",
    "\n",
    "def build_resnet(input_shape, n_feature_maps, nb_classes):\n",
    "    x = Input(shape=(input_shape))\n",
    "    conv_x = BatchNormalization()(x)\n",
    "    conv_x = Conv1D(n_feature_maps, kernel_size=3, strides=1, padding='same')(conv_x)\n",
    "    conv_x = BatchNormalization()(conv_x)\n",
    "    conv_x = Activation('relu')(conv_x)\n",
    "    conv_x = Dropout(DROPOUT)(conv_x)\n",
    "    conv_y = Conv1D(n_feature_maps, kernel_size=3, strides=1, padding='same')(conv_x)\n",
    "    conv_y = BatchNormalization()(conv_y)\n",
    "    conv_y = Activation('relu')(conv_y)\n",
    "    conv_y = Dropout(DROPOUT)(conv_y)\n",
    "    conv_z = Conv1D(n_feature_maps, kernel_size=3, strides=1, padding='same')(conv_y)\n",
    "    conv_z = BatchNormalization()(conv_z)\n",
    "    conv_z = Dropout(DROPOUT)(conv_z)\n",
    "    is_expand_channels = not (input_shape[-1] == n_feature_maps)\n",
    "    if is_expand_channels:\n",
    "        shortcut_y = Conv1D(n_feature_maps, kernel_size=1, strides=1, padding='same')(x)\n",
    "        shortcut_y = BatchNormalization()(shortcut_y)\n",
    "    else:\n",
    "        shortcut_y = BatchNormalization()(x)\n",
    "    y = Add()([shortcut_y, conv_z])\n",
    "    y = Activation('relu')(y)\n",
    "    x1 = y\n",
    "    conv_x = Conv1D(n_feature_maps*2, kernel_size=3, strides=1, padding='same')(x1)\n",
    "    conv_x = BatchNormalization()(conv_x)\n",
    "    conv_x = Activation('relu')(conv_x)\n",
    "    conv_x = Dropout(DROPOUT)(conv_x)\n",
    "    conv_y = Conv1D(n_feature_maps*2, kernel_size=3, strides=1, padding='same')(conv_x)\n",
    "    conv_y = BatchNormalization()(conv_y)\n",
    "    conv_y = Activation('relu')(conv_y)\n",
    "    conv_y = Dropout(DROPOUT)(conv_y)\n",
    "    conv_z = Conv1D(n_feature_maps*2, kernel_size=3, strides=1, padding='same')(conv_y)\n",
    "    conv_z = BatchNormalization()(conv_z)\n",
    "    conv_z = Dropout(DROPOUT)(conv_z)\n",
    "    is_expand_channels = not (input_shape[-1] == n_feature_maps*2)\n",
    "    if is_expand_channels:\n",
    "        shortcut_y = Conv1D(n_feature_maps*2, kernel_size=1, strides=1, padding='same')(x1)\n",
    "        shortcut_y = BatchNormalization()(shortcut_y)\n",
    "    else:\n",
    "        shortcut_y = BatchNormalization()(x1)\n",
    "    shortcut_y = Dropout(DROPOUT)(shortcut_y)\n",
    "    y = Add()([shortcut_y, conv_z])\n",
    "    y = Activation('relu')(y)\n",
    "    y = Dropout(DROPOUT)(y)\n",
    "    x1 = y\n",
    "    conv_x = Conv1D(n_feature_maps*2, kernel_size=3, strides=1, padding='same')(x1)\n",
    "    conv_x = BatchNormalization()(conv_x)\n",
    "    conv_x = Activation('relu')(conv_x)\n",
    "    conv_x = Dropout(DROPOUT)(conv_x)\n",
    "    conv_y = Conv1D(n_feature_maps*2, kernel_size=3, strides=1, padding='same')(conv_x)\n",
    "    conv_y = BatchNormalization()(conv_y)\n",
    "    conv_y = Activation('relu')(conv_y)\n",
    "    conv_y = Dropout(DROPOUT)(conv_y)\n",
    "    conv_z = Conv1D(n_feature_maps*2, kernel_size=3, strides=1, padding='same')(conv_y)\n",
    "    conv_z = BatchNormalization()(conv_z)\n",
    "    conv_z = Dropout(DROPOUT)(conv_z)\n",
    "    is_expand_channels = not (input_shape[-1] == n_feature_maps*2)\n",
    "    if is_expand_channels:\n",
    "        shortcut_y = Conv1D(n_feature_maps*2, kernel_size=1, strides=1, padding='same')(x1)\n",
    "        shortcut_y = BatchNormalization()(shortcut_y)\n",
    "    else:\n",
    "        shortcut_y = BatchNormalization()(x1)\n",
    "    shortcut_y = Dropout(DROPOUT)(shortcut_y)\n",
    "    y = Add()([shortcut_y, conv_z])\n",
    "    y = Activation('relu')(y)\n",
    "    y = Dropout(DROPOUT)(y)\n",
    "    full = GlobalAveragePooling1D()(y)\n",
    "    out = Dense(nb_classes, activation='softmax')(full)\n",
    "    return x, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROPOUT = 0.25\n",
    "\n",
    "def build_resnet(input_shape, n_feature_maps, nb_classes):\n",
    "    x = Input(shape=(input_shape))\n",
    "    conv_x = Conv1D(n_feature_maps*2, kernel_size=3, strides=1, padding='same')(x)\n",
    "    conv_x = BatchNormalization()(conv_x)\n",
    "    conv_x = Activation('relu')(conv_x)\n",
    "    conv_x = Dropout(DROPOUT)(conv_x)\n",
    "    conv_y = Conv1D(n_feature_maps*2, kernel_size=3, strides=1, padding='same')(conv_x)\n",
    "    conv_y = BatchNormalization()(conv_y)\n",
    "    conv_y = Activation('relu')(conv_y)\n",
    "    conv_y = Dropout(DROPOUT)(conv_y)\n",
    "    conv_z = Conv1D(n_feature_maps*2, kernel_size=3, strides=1, padding='same')(conv_y)\n",
    "    conv_z = BatchNormalization()(conv_z)\n",
    "    conv_z = Dropout(DROPOUT)(conv_z)\n",
    "    is_expand_channels = not (input_shape[-1] == n_feature_maps*2)\n",
    "    if is_expand_channels:\n",
    "        shortcut_y = Conv1D(n_feature_maps*2, kernel_size=1, strides=1, padding='same')(x)\n",
    "        shortcut_y = BatchNormalization()(shortcut_y)\n",
    "    else:\n",
    "        shortcut_y = BatchNormalization()(x1)\n",
    "    shortcut_y = Dropout(DROPOUT)(shortcut_y)\n",
    "    y = Add()([shortcut_y, conv_z])\n",
    "    y = Activation('relu')(y)\n",
    "    y = Dropout(DROPOUT)(y)\n",
    "    full = GlobalAveragePooling1D()(conv_z)\n",
    "    out = Dense(nb_classes, activation='softmax')(full)\n",
    "    return x, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes: 1\n",
      "WARNING:tensorflow:From C:\\Users\\Ethan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1854 samples, validate on 618 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 2s 1ms/step - loss: 1.3493 - accuracy: 0.6251 - val_loss: 1.3091 - val_accuracy: 0.8447\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 0s 209us/step - loss: 1.2719 - accuracy: 0.7891 - val_loss: 1.2222 - val_accuracy: 0.8447\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 0s 210us/step - loss: 1.1867 - accuracy: 0.7961 - val_loss: 1.1289 - val_accuracy: 0.8447\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 0s 211us/step - loss: 1.0941 - accuracy: 0.8042 - val_loss: 1.0365 - val_accuracy: 0.8447\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 0s 209us/step - loss: 0.9963 - accuracy: 0.8091 - val_loss: 0.9474 - val_accuracy: 0.8430\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 0s 221us/step - loss: 0.9085 - accuracy: 0.8069 - val_loss: 0.8594 - val_accuracy: 0.8430\n",
      "Epoch 7/1000\n",
      "1854/1854 [==============================] - 0s 220us/step - loss: 0.8244 - accuracy: 0.8139 - val_loss: 0.7844 - val_accuracy: 0.8414\n",
      "Epoch 8/1000\n",
      "1854/1854 [==============================] - 0s 258us/step - loss: 0.7605 - accuracy: 0.8053 - val_loss: 0.7227 - val_accuracy: 0.8430\n",
      "Epoch 9/1000\n",
      "1854/1854 [==============================] - 0s 234us/step - loss: 0.6954 - accuracy: 0.8107 - val_loss: 0.6712 - val_accuracy: 0.8430\n",
      "Epoch 10/1000\n",
      "1854/1854 [==============================] - 0s 220us/step - loss: 0.6587 - accuracy: 0.8123 - val_loss: 0.6415 - val_accuracy: 0.8430\n",
      "Epoch 11/1000\n",
      "1854/1854 [==============================] - 0s 218us/step - loss: 0.6291 - accuracy: 0.8161 - val_loss: 0.6257 - val_accuracy: 0.8430\n",
      "Epoch 12/1000\n",
      "1854/1854 [==============================] - 0s 211us/step - loss: 0.6074 - accuracy: 0.8145 - val_loss: 0.6176 - val_accuracy: 0.8430\n",
      "Epoch 13/1000\n",
      "1854/1854 [==============================] - 0s 218us/step - loss: 0.6014 - accuracy: 0.8182 - val_loss: 0.6162 - val_accuracy: 0.8430\n",
      "Epoch 14/1000\n",
      "1854/1854 [==============================] - 0s 218us/step - loss: 0.5915 - accuracy: 0.8182 - val_loss: 0.6164 - val_accuracy: 0.8430\n",
      "Epoch 15/1000\n",
      "1854/1854 [==============================] - 0s 215us/step - loss: 0.5849 - accuracy: 0.8172 - val_loss: 0.6178 - val_accuracy: 0.8430\n",
      "Epoch 16/1000\n",
      "1854/1854 [==============================] - 0s 215us/step - loss: 0.5932 - accuracy: 0.8161 - val_loss: 0.6172 - val_accuracy: 0.8430\n",
      "Epoch 17/1000\n",
      "1854/1854 [==============================] - 0s 208us/step - loss: 0.5863 - accuracy: 0.8145 - val_loss: 0.6150 - val_accuracy: 0.8430\n",
      "Epoch 18/1000\n",
      "1854/1854 [==============================] - 0s 208us/step - loss: 0.5882 - accuracy: 0.8145 - val_loss: 0.6207 - val_accuracy: 0.8430\n",
      "Epoch 19/1000\n",
      "1854/1854 [==============================] - 0s 210us/step - loss: 0.5886 - accuracy: 0.8161 - val_loss: 0.6189 - val_accuracy: 0.8430\n",
      "Epoch 20/1000\n",
      "1854/1854 [==============================] - 0s 211us/step - loss: 0.5876 - accuracy: 0.8145 - val_loss: 0.6207 - val_accuracy: 0.8430\n",
      "Epoch 21/1000\n",
      "1854/1854 [==============================] - 0s 213us/step - loss: 0.5850 - accuracy: 0.8172 - val_loss: 0.6227 - val_accuracy: 0.8414\n",
      "Epoch 22/1000\n",
      "1854/1854 [==============================] - 0s 208us/step - loss: 0.5823 - accuracy: 0.8134 - val_loss: 0.6245 - val_accuracy: 0.8382\n",
      "Train on 1854 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 1s 504us/step - loss: 1.3364 - accuracy: 0.6003 - val_loss: 1.2670 - val_accuracy: 0.8417\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 0s 212us/step - loss: 1.2189 - accuracy: 0.7611 - val_loss: 1.1370 - val_accuracy: 0.8417\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 0s 206us/step - loss: 1.0926 - accuracy: 0.8020 - val_loss: 0.9869 - val_accuracy: 0.8417\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 0s 223us/step - loss: 0.9640 - accuracy: 0.8182 - val_loss: 0.8554 - val_accuracy: 0.8417\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 0s 211us/step - loss: 0.8569 - accuracy: 0.8188 - val_loss: 0.7702 - val_accuracy: 0.8417\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 0s 216us/step - loss: 0.7696 - accuracy: 0.8198 - val_loss: 0.6886 - val_accuracy: 0.8417\n",
      "Epoch 7/1000\n",
      "1854/1854 [==============================] - 0s 225us/step - loss: 0.7103 - accuracy: 0.8198 - val_loss: 0.6655 - val_accuracy: 0.8417\n",
      "Epoch 8/1000\n",
      "1854/1854 [==============================] - 0s 218us/step - loss: 0.6670 - accuracy: 0.8198 - val_loss: 0.6279 - val_accuracy: 0.8417\n",
      "Epoch 9/1000\n",
      "1854/1854 [==============================] - 0s 213us/step - loss: 0.6497 - accuracy: 0.8198 - val_loss: 0.6158 - val_accuracy: 0.8417\n",
      "Epoch 10/1000\n",
      "1854/1854 [==============================] - 0s 206us/step - loss: 0.6327 - accuracy: 0.8198 - val_loss: 0.6128 - val_accuracy: 0.8417\n",
      "Epoch 11/1000\n",
      "1854/1854 [==============================] - 0s 204us/step - loss: 0.6246 - accuracy: 0.8198 - val_loss: 0.6128 - val_accuracy: 0.8417\n",
      "Epoch 12/1000\n",
      "1854/1854 [==============================] - 0s 211us/step - loss: 0.6173 - accuracy: 0.8198 - val_loss: 0.6128 - val_accuracy: 0.8417\n",
      "Epoch 13/1000\n",
      "1854/1854 [==============================] - 0s 208us/step - loss: 0.6181 - accuracy: 0.8198 - val_loss: 0.6155 - val_accuracy: 0.8417\n",
      "Epoch 14/1000\n",
      "1854/1854 [==============================] - 0s 210us/step - loss: 0.6133 - accuracy: 0.8198 - val_loss: 0.6151 - val_accuracy: 0.8417\n",
      "Epoch 15/1000\n",
      "1854/1854 [==============================] - 0s 207us/step - loss: 0.6096 - accuracy: 0.8198 - val_loss: 0.6179 - val_accuracy: 0.8417\n",
      "Epoch 16/1000\n",
      "1854/1854 [==============================] - 0s 204us/step - loss: 0.6016 - accuracy: 0.8198 - val_loss: 0.6180 - val_accuracy: 0.8417\n",
      "Epoch 17/1000\n",
      "1854/1854 [==============================] - 0s 207us/step - loss: 0.6010 - accuracy: 0.8198 - val_loss: 0.6173 - val_accuracy: 0.8417\n",
      "Train on 1856 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1856/1856 [==============================] - 1s 493us/step - loss: 1.3463 - accuracy: 0.4574 - val_loss: 1.3116 - val_accuracy: 0.8401\n",
      "Epoch 2/1000\n",
      "1856/1856 [==============================] - 0s 217us/step - loss: 1.2483 - accuracy: 0.8066 - val_loss: 1.2306 - val_accuracy: 0.8401\n",
      "Epoch 3/1000\n",
      "1856/1856 [==============================] - 0s 224us/step - loss: 1.1425 - accuracy: 0.8200 - val_loss: 1.1309 - val_accuracy: 0.8401\n",
      "Epoch 4/1000\n",
      "1856/1856 [==============================] - 0s 217us/step - loss: 1.0150 - accuracy: 0.8200 - val_loss: 1.0112 - val_accuracy: 0.8401\n",
      "Epoch 5/1000\n",
      "1856/1856 [==============================] - 0s 225us/step - loss: 0.8931 - accuracy: 0.8200 - val_loss: 0.8967 - val_accuracy: 0.8401\n",
      "Epoch 6/1000\n",
      "1856/1856 [==============================] - 0s 226us/step - loss: 0.7975 - accuracy: 0.8200 - val_loss: 0.7999 - val_accuracy: 0.8401\n",
      "Epoch 7/1000\n",
      "1856/1856 [==============================] - 0s 219us/step - loss: 0.7230 - accuracy: 0.8200 - val_loss: 0.7296 - val_accuracy: 0.8401\n",
      "Epoch 8/1000\n",
      "1856/1856 [==============================] - 0s 220us/step - loss: 0.6701 - accuracy: 0.8200 - val_loss: 0.6870 - val_accuracy: 0.8401\n",
      "Epoch 9/1000\n",
      "1856/1856 [==============================] - 0s 225us/step - loss: 0.6415 - accuracy: 0.8200 - val_loss: 0.6594 - val_accuracy: 0.8401\n",
      "Epoch 10/1000\n",
      "1856/1856 [==============================] - 0s 218us/step - loss: 0.6167 - accuracy: 0.8200 - val_loss: 0.6451 - val_accuracy: 0.8401\n",
      "Epoch 11/1000\n",
      "1856/1856 [==============================] - 0s 220us/step - loss: 0.6030 - accuracy: 0.8200 - val_loss: 0.6362 - val_accuracy: 0.8401\n",
      "Epoch 12/1000\n",
      "1856/1856 [==============================] - 0s 212us/step - loss: 0.5953 - accuracy: 0.8200 - val_loss: 0.6336 - val_accuracy: 0.8401\n",
      "Epoch 13/1000\n",
      "1856/1856 [==============================] - 0s 205us/step - loss: 0.5926 - accuracy: 0.8200 - val_loss: 0.6343 - val_accuracy: 0.8401\n",
      "Epoch 14/1000\n",
      "1856/1856 [==============================] - 0s 216us/step - loss: 0.5867 - accuracy: 0.8200 - val_loss: 0.6285 - val_accuracy: 0.8401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/1000\n",
      "1856/1856 [==============================] - 0s 214us/step - loss: 0.5853 - accuracy: 0.8200 - val_loss: 0.6267 - val_accuracy: 0.8401\n",
      "Epoch 16/1000\n",
      "1856/1856 [==============================] - 0s 218us/step - loss: 0.5829 - accuracy: 0.8200 - val_loss: 0.6431 - val_accuracy: 0.8401\n",
      "Epoch 17/1000\n",
      "1856/1856 [==============================] - 0s 214us/step - loss: 0.5760 - accuracy: 0.8200 - val_loss: 0.6362 - val_accuracy: 0.8401\n",
      "Epoch 18/1000\n",
      "1856/1856 [==============================] - 0s 205us/step - loss: 0.5735 - accuracy: 0.8200 - val_loss: 0.6367 - val_accuracy: 0.8401\n",
      "Epoch 19/1000\n",
      "1856/1856 [==============================] - 0s 238us/step - loss: 0.5703 - accuracy: 0.8200 - val_loss: 0.6393 - val_accuracy: 0.8401\n",
      "Epoch 20/1000\n",
      "1856/1856 [==============================] - 0s 217us/step - loss: 0.5689 - accuracy: 0.8200 - val_loss: 0.6394 - val_accuracy: 0.8401\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 1s 535us/step - loss: 1.3501 - accuracy: 0.3770 - val_loss: 1.3062 - val_accuracy: 0.8546\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 0s 229us/step - loss: 1.2642 - accuracy: 0.7862 - val_loss: 1.2111 - val_accuracy: 0.8546\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 0s 215us/step - loss: 1.1643 - accuracy: 0.8099 - val_loss: 1.1009 - val_accuracy: 0.8546\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 0s 221us/step - loss: 1.0539 - accuracy: 0.8142 - val_loss: 0.9921 - val_accuracy: 0.8546\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 0s 216us/step - loss: 0.9428 - accuracy: 0.8148 - val_loss: 0.8745 - val_accuracy: 0.8546\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 0s 219us/step - loss: 0.8447 - accuracy: 0.8142 - val_loss: 0.7745 - val_accuracy: 0.8546\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 0s 222us/step - loss: 0.7762 - accuracy: 0.8148 - val_loss: 0.7078 - val_accuracy: 0.8546\n",
      "Epoch 8/1000\n",
      "1857/1857 [==============================] - 0s 219us/step - loss: 0.7270 - accuracy: 0.8148 - val_loss: 0.6510 - val_accuracy: 0.8546\n",
      "Epoch 9/1000\n",
      "1857/1857 [==============================] - 0s 220us/step - loss: 0.6955 - accuracy: 0.8148 - val_loss: 0.6218 - val_accuracy: 0.8546\n",
      "Epoch 10/1000\n",
      "1857/1857 [==============================] - 0s 220us/step - loss: 0.6698 - accuracy: 0.8148 - val_loss: 0.5912 - val_accuracy: 0.8546\n",
      "Epoch 11/1000\n",
      "1857/1857 [==============================] - 0s 218us/step - loss: 0.6595 - accuracy: 0.8148 - val_loss: 0.5751 - val_accuracy: 0.8546\n",
      "Epoch 12/1000\n",
      "1857/1857 [==============================] - 0s 222us/step - loss: 0.6481 - accuracy: 0.8148 - val_loss: 0.5776 - val_accuracy: 0.8546\n",
      "Epoch 13/1000\n",
      "1857/1857 [==============================] - 0s 227us/step - loss: 0.6387 - accuracy: 0.8148 - val_loss: 0.5759 - val_accuracy: 0.8546\n",
      "Epoch 14/1000\n",
      "1857/1857 [==============================] - 0s 230us/step - loss: 0.6298 - accuracy: 0.8148 - val_loss: 0.5687 - val_accuracy: 0.8546\n",
      "Epoch 15/1000\n",
      "1857/1857 [==============================] - 0s 222us/step - loss: 0.6301 - accuracy: 0.8148 - val_loss: 0.5665 - val_accuracy: 0.8546\n",
      "Epoch 16/1000\n",
      "1857/1857 [==============================] - 0s 221us/step - loss: 0.6298 - accuracy: 0.8148 - val_loss: 0.5728 - val_accuracy: 0.8546\n",
      "Epoch 17/1000\n",
      "1857/1857 [==============================] - 0s 237us/step - loss: 0.6204 - accuracy: 0.8148 - val_loss: 0.5778 - val_accuracy: 0.8546\n",
      "Epoch 18/1000\n",
      "1857/1857 [==============================] - 0s 207us/step - loss: 0.6165 - accuracy: 0.8148 - val_loss: 0.5841 - val_accuracy: 0.8546\n",
      "Epoch 19/1000\n",
      "1857/1857 [==============================] - 0s 215us/step - loss: 0.6203 - accuracy: 0.8148 - val_loss: 0.5865 - val_accuracy: 0.8546\n",
      "Epoch 20/1000\n",
      "1857/1857 [==============================] - 0s 239us/step - loss: 0.6177 - accuracy: 0.8148 - val_loss: 0.5884 - val_accuracy: 0.8546\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 1s 525us/step - loss: 1.3388 - accuracy: 0.5062 - val_loss: 1.2655 - val_accuracy: 0.8368\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 0s 236us/step - loss: 1.2228 - accuracy: 0.7857 - val_loss: 1.1433 - val_accuracy: 0.8368\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 0s 234us/step - loss: 1.1019 - accuracy: 0.8191 - val_loss: 1.0280 - val_accuracy: 0.8368\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 0s 227us/step - loss: 0.9910 - accuracy: 0.8201 - val_loss: 0.9718 - val_accuracy: 0.8368\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 0s 217us/step - loss: 0.8946 - accuracy: 0.8207 - val_loss: 0.8470 - val_accuracy: 0.8368\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 1s 277us/step - loss: 0.8124 - accuracy: 0.8207 - val_loss: 0.7458 - val_accuracy: 0.8368\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 0s 216us/step - loss: 0.7499 - accuracy: 0.8207 - val_loss: 0.6919 - val_accuracy: 0.8368\n",
      "Epoch 8/1000\n",
      "1857/1857 [==============================] - 0s 226us/step - loss: 0.7143 - accuracy: 0.8207 - val_loss: 0.6648 - val_accuracy: 0.8368\n",
      "Epoch 9/1000\n",
      "1857/1857 [==============================] - 0s 224us/step - loss: 0.6825 - accuracy: 0.8207 - val_loss: 0.6498 - val_accuracy: 0.8368\n",
      "Epoch 10/1000\n",
      "1857/1857 [==============================] - 0s 227us/step - loss: 0.6646 - accuracy: 0.8207 - val_loss: 0.6381 - val_accuracy: 0.8368\n",
      "Epoch 11/1000\n",
      "1857/1857 [==============================] - 0s 226us/step - loss: 0.6523 - accuracy: 0.8207 - val_loss: 0.6315 - val_accuracy: 0.8368\n",
      "Epoch 12/1000\n",
      "1857/1857 [==============================] - 0s 224us/step - loss: 0.6395 - accuracy: 0.8207 - val_loss: 0.6271 - val_accuracy: 0.8368\n",
      "Epoch 13/1000\n",
      "1857/1857 [==============================] - 0s 224us/step - loss: 0.6278 - accuracy: 0.8207 - val_loss: 0.6249 - val_accuracy: 0.8368\n",
      "Epoch 14/1000\n",
      "1857/1857 [==============================] - 0s 230us/step - loss: 0.6233 - accuracy: 0.8207 - val_loss: 0.6220 - val_accuracy: 0.8368\n",
      "Epoch 15/1000\n",
      "1857/1857 [==============================] - 0s 223us/step - loss: 0.6165 - accuracy: 0.8207 - val_loss: 0.6185 - val_accuracy: 0.8368\n",
      "Epoch 16/1000\n",
      "1857/1857 [==============================] - 0s 219us/step - loss: 0.6016 - accuracy: 0.8207 - val_loss: 0.6192 - val_accuracy: 0.8368\n",
      "Epoch 17/1000\n",
      "1857/1857 [==============================] - 0s 215us/step - loss: 0.5996 - accuracy: 0.8207 - val_loss: 0.6202 - val_accuracy: 0.8368\n",
      "Epoch 18/1000\n",
      "1857/1857 [==============================] - 0s 241us/step - loss: 0.5994 - accuracy: 0.8207 - val_loss: 0.6198 - val_accuracy: 0.8368\n",
      "Epoch 19/1000\n",
      "1857/1857 [==============================] - 0s 219us/step - loss: 0.5876 - accuracy: 0.8207 - val_loss: 0.6157 - val_accuracy: 0.8368\n",
      "Epoch 20/1000\n",
      "1857/1857 [==============================] - 0s 215us/step - loss: 0.5889 - accuracy: 0.8207 - val_loss: 0.6163 - val_accuracy: 0.8368\n",
      "Epoch 21/1000\n",
      "1857/1857 [==============================] - 0s 217us/step - loss: 0.5882 - accuracy: 0.8207 - val_loss: 0.6172 - val_accuracy: 0.8368\n",
      "Epoch 22/1000\n",
      "1857/1857 [==============================] - 0s 222us/step - loss: 0.5860 - accuracy: 0.8207 - val_loss: 0.6203 - val_accuracy: 0.8368\n",
      "Epoch 23/1000\n",
      "1857/1857 [==============================] - 0s 216us/step - loss: 0.5802 - accuracy: 0.8207 - val_loss: 0.6209 - val_accuracy: 0.8368\n",
      "Epoch 24/1000\n",
      "1857/1857 [==============================] - 0s 216us/step - loss: 0.5804 - accuracy: 0.8207 - val_loss: 0.6239 - val_accuracy: 0.8368\n",
      "auc: 0.7176913954024597\n",
      "kappa: 0.07866145377875337\n",
      "nodes: 2\n",
      "Train on 1854 samples, validate on 618 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 1s 538us/step - loss: 1.3372 - accuracy: 0.5049 - val_loss: 1.2776 - val_accuracy: 0.8495\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 0s 236us/step - loss: 1.2062 - accuracy: 0.8037 - val_loss: 1.1381 - val_accuracy: 0.8495\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 0s 239us/step - loss: 1.0557 - accuracy: 0.8150 - val_loss: 0.9685 - val_accuracy: 0.8495\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 0s 222us/step - loss: 0.8977 - accuracy: 0.8177 - val_loss: 0.8126 - val_accuracy: 0.8495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 0s 222us/step - loss: 0.7766 - accuracy: 0.8177 - val_loss: 0.7039 - val_accuracy: 0.8495\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 0s 226us/step - loss: 0.6960 - accuracy: 0.8177 - val_loss: 0.6511 - val_accuracy: 0.8495\n",
      "Epoch 7/1000\n",
      "1854/1854 [==============================] - 0s 211us/step - loss: 0.6500 - accuracy: 0.8177 - val_loss: 0.6085 - val_accuracy: 0.8495\n",
      "Epoch 8/1000\n",
      "1854/1854 [==============================] - 0s 215us/step - loss: 0.6231 - accuracy: 0.8177 - val_loss: 0.5899 - val_accuracy: 0.8495\n",
      "Epoch 9/1000\n",
      "1854/1854 [==============================] - 0s 214us/step - loss: 0.6086 - accuracy: 0.8177 - val_loss: 0.5963 - val_accuracy: 0.8495\n",
      "Epoch 10/1000\n",
      "1854/1854 [==============================] - 0s 213us/step - loss: 0.5976 - accuracy: 0.8177 - val_loss: 0.5906 - val_accuracy: 0.8495\n",
      "Epoch 11/1000\n",
      "1854/1854 [==============================] - 0s 210us/step - loss: 0.5968 - accuracy: 0.8177 - val_loss: 0.5909 - val_accuracy: 0.8495\n",
      "Epoch 12/1000\n",
      "1854/1854 [==============================] - 0s 211us/step - loss: 0.5843 - accuracy: 0.8177 - val_loss: 0.5953 - val_accuracy: 0.8495\n",
      "Epoch 13/1000\n",
      "1854/1854 [==============================] - 0s 212us/step - loss: 0.5827 - accuracy: 0.8177 - val_loss: 0.6001 - val_accuracy: 0.8495\n",
      "Train on 1854 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 1s 537us/step - loss: 1.3306 - accuracy: 0.4477 - val_loss: 1.2502 - val_accuracy: 0.8465\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 0s 211us/step - loss: 1.1844 - accuracy: 0.7443 - val_loss: 1.1006 - val_accuracy: 0.8465\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 0s 215us/step - loss: 1.0268 - accuracy: 0.7977 - val_loss: 0.9426 - val_accuracy: 0.8465\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 0s 215us/step - loss: 0.8789 - accuracy: 0.8080 - val_loss: 0.8113 - val_accuracy: 0.8465\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 0s 211us/step - loss: 0.7712 - accuracy: 0.8096 - val_loss: 0.7246 - val_accuracy: 0.8465\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 0s 216us/step - loss: 0.6924 - accuracy: 0.8150 - val_loss: 0.6715 - val_accuracy: 0.8465\n",
      "Epoch 7/1000\n",
      "1854/1854 [==============================] - 0s 211us/step - loss: 0.6467 - accuracy: 0.8182 - val_loss: 0.6513 - val_accuracy: 0.8465\n",
      "Epoch 8/1000\n",
      "1854/1854 [==============================] - 0s 213us/step - loss: 0.6289 - accuracy: 0.8172 - val_loss: 0.6400 - val_accuracy: 0.8465\n",
      "Epoch 9/1000\n",
      "1854/1854 [==============================] - 0s 218us/step - loss: 0.6165 - accuracy: 0.8150 - val_loss: 0.6340 - val_accuracy: 0.8465\n",
      "Epoch 10/1000\n",
      "1854/1854 [==============================] - 0s 210us/step - loss: 0.5990 - accuracy: 0.8182 - val_loss: 0.6397 - val_accuracy: 0.8465\n",
      "Epoch 11/1000\n",
      "1854/1854 [==============================] - 0s 222us/step - loss: 0.5865 - accuracy: 0.8177 - val_loss: 0.6349 - val_accuracy: 0.8465\n",
      "Epoch 12/1000\n",
      "1854/1854 [==============================] - 0s 211us/step - loss: 0.5871 - accuracy: 0.8161 - val_loss: 0.6313 - val_accuracy: 0.8465\n",
      "Epoch 13/1000\n",
      "1854/1854 [==============================] - 0s 215us/step - loss: 0.5805 - accuracy: 0.8166 - val_loss: 0.6335 - val_accuracy: 0.8465\n",
      "Epoch 14/1000\n",
      "1854/1854 [==============================] - 0s 213us/step - loss: 0.5734 - accuracy: 0.8150 - val_loss: 0.6340 - val_accuracy: 0.8449\n",
      "Epoch 15/1000\n",
      "1854/1854 [==============================] - 0s 210us/step - loss: 0.5759 - accuracy: 0.8177 - val_loss: 0.6304 - val_accuracy: 0.8449\n",
      "Epoch 16/1000\n",
      "1854/1854 [==============================] - 0s 219us/step - loss: 0.5710 - accuracy: 0.8198 - val_loss: 0.6312 - val_accuracy: 0.8449\n",
      "Epoch 17/1000\n",
      "1854/1854 [==============================] - 0s 211us/step - loss: 0.5739 - accuracy: 0.8182 - val_loss: 0.6284 - val_accuracy: 0.8449\n",
      "Epoch 18/1000\n",
      "1854/1854 [==============================] - 0s 218us/step - loss: 0.5678 - accuracy: 0.8145 - val_loss: 0.6282 - val_accuracy: 0.8449\n",
      "Epoch 19/1000\n",
      "1854/1854 [==============================] - 0s 214us/step - loss: 0.5631 - accuracy: 0.8182 - val_loss: 0.6325 - val_accuracy: 0.8449\n",
      "Epoch 20/1000\n",
      "1854/1854 [==============================] - 0s 212us/step - loss: 0.5674 - accuracy: 0.8182 - val_loss: 0.6287 - val_accuracy: 0.8449\n",
      "Epoch 21/1000\n",
      "1854/1854 [==============================] - 0s 213us/step - loss: 0.5572 - accuracy: 0.8166 - val_loss: 0.6260 - val_accuracy: 0.8449\n",
      "Epoch 22/1000\n",
      "1854/1854 [==============================] - 0s 214us/step - loss: 0.5677 - accuracy: 0.8150 - val_loss: 0.6285 - val_accuracy: 0.8449\n",
      "Epoch 23/1000\n",
      "1854/1854 [==============================] - 0s 215us/step - loss: 0.5662 - accuracy: 0.8177 - val_loss: 0.6301 - val_accuracy: 0.8449\n",
      "Epoch 24/1000\n",
      "1854/1854 [==============================] - 0s 215us/step - loss: 0.5656 - accuracy: 0.8139 - val_loss: 0.6286 - val_accuracy: 0.8449\n",
      "Epoch 25/1000\n",
      "1854/1854 [==============================] - 0s 211us/step - loss: 0.5618 - accuracy: 0.8204 - val_loss: 0.6291 - val_accuracy: 0.8449\n",
      "Epoch 26/1000\n",
      "1854/1854 [==============================] - 0s 214us/step - loss: 0.5597 - accuracy: 0.8225 - val_loss: 0.6285 - val_accuracy: 0.8449\n",
      "Train on 1856 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1856/1856 [==============================] - 1s 552us/step - loss: 1.3267 - accuracy: 0.5630 - val_loss: 1.2557 - val_accuracy: 0.8401\n",
      "Epoch 2/1000\n",
      "1856/1856 [==============================] - 0s 217us/step - loss: 1.1924 - accuracy: 0.7753 - val_loss: 1.1018 - val_accuracy: 0.8401\n",
      "Epoch 3/1000\n",
      "1856/1856 [==============================] - 0s 215us/step - loss: 1.0357 - accuracy: 0.8012 - val_loss: 0.9411 - val_accuracy: 0.8401\n",
      "Epoch 4/1000\n",
      "1856/1856 [==============================] - 0s 219us/step - loss: 0.8858 - accuracy: 0.8125 - val_loss: 0.8066 - val_accuracy: 0.8401\n",
      "Epoch 5/1000\n",
      "1856/1856 [==============================] - 0s 213us/step - loss: 0.7671 - accuracy: 0.8130 - val_loss: 0.7181 - val_accuracy: 0.8401\n",
      "Epoch 6/1000\n",
      "1856/1856 [==============================] - 0s 218us/step - loss: 0.6883 - accuracy: 0.8195 - val_loss: 0.6710 - val_accuracy: 0.8401\n",
      "Epoch 7/1000\n",
      "1856/1856 [==============================] - 0s 216us/step - loss: 0.6543 - accuracy: 0.8163 - val_loss: 0.6504 - val_accuracy: 0.8401\n",
      "Epoch 8/1000\n",
      "1856/1856 [==============================] - 0s 212us/step - loss: 0.6287 - accuracy: 0.8141 - val_loss: 0.6393 - val_accuracy: 0.8401\n",
      "Epoch 9/1000\n",
      "1856/1856 [==============================] - 0s 218us/step - loss: 0.6075 - accuracy: 0.8190 - val_loss: 0.6369 - val_accuracy: 0.8401\n",
      "Epoch 10/1000\n",
      "1856/1856 [==============================] - 0s 213us/step - loss: 0.5954 - accuracy: 0.8211 - val_loss: 0.6364 - val_accuracy: 0.8401\n",
      "Epoch 11/1000\n",
      "1856/1856 [==============================] - 0s 217us/step - loss: 0.5941 - accuracy: 0.8157 - val_loss: 0.6352 - val_accuracy: 0.8401\n",
      "Epoch 12/1000\n",
      "1856/1856 [==============================] - 0s 219us/step - loss: 0.5786 - accuracy: 0.8179 - val_loss: 0.6352 - val_accuracy: 0.8401\n",
      "Epoch 13/1000\n",
      "1856/1856 [==============================] - 0s 214us/step - loss: 0.5749 - accuracy: 0.8173 - val_loss: 0.6371 - val_accuracy: 0.8401\n",
      "Epoch 14/1000\n",
      "1856/1856 [==============================] - 0s 218us/step - loss: 0.5751 - accuracy: 0.8190 - val_loss: 0.6348 - val_accuracy: 0.8401\n",
      "Epoch 15/1000\n",
      "1856/1856 [==============================] - 0s 214us/step - loss: 0.5805 - accuracy: 0.8168 - val_loss: 0.6343 - val_accuracy: 0.8401\n",
      "Epoch 16/1000\n",
      "1856/1856 [==============================] - 0s 216us/step - loss: 0.5796 - accuracy: 0.8190 - val_loss: 0.6357 - val_accuracy: 0.8401\n",
      "Epoch 17/1000\n",
      "1856/1856 [==============================] - 0s 216us/step - loss: 0.5724 - accuracy: 0.8184 - val_loss: 0.6373 - val_accuracy: 0.8401\n",
      "Epoch 18/1000\n",
      "1856/1856 [==============================] - 0s 213us/step - loss: 0.5726 - accuracy: 0.8190 - val_loss: 0.6342 - val_accuracy: 0.8417\n",
      "Epoch 19/1000\n",
      "1856/1856 [==============================] - 0s 219us/step - loss: 0.5714 - accuracy: 0.8173 - val_loss: 0.6370 - val_accuracy: 0.8401\n",
      "Epoch 20/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1856/1856 [==============================] - 0s 213us/step - loss: 0.5669 - accuracy: 0.8173 - val_loss: 0.6395 - val_accuracy: 0.8401\n",
      "Epoch 21/1000\n",
      "1856/1856 [==============================] - 0s 217us/step - loss: 0.5639 - accuracy: 0.8179 - val_loss: 0.6382 - val_accuracy: 0.8401\n",
      "Epoch 22/1000\n",
      "1856/1856 [==============================] - 0s 218us/step - loss: 0.5660 - accuracy: 0.8157 - val_loss: 0.6395 - val_accuracy: 0.8384\n",
      "Epoch 23/1000\n",
      "1856/1856 [==============================] - 0s 213us/step - loss: 0.5653 - accuracy: 0.8179 - val_loss: 0.6409 - val_accuracy: 0.8368\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 1s 601us/step - loss: 1.3085 - accuracy: 0.5423 - val_loss: 1.2547 - val_accuracy: 0.8449\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 0s 225us/step - loss: 1.1474 - accuracy: 0.8040 - val_loss: 1.1140 - val_accuracy: 0.8449\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 0s 233us/step - loss: 0.9809 - accuracy: 0.8169 - val_loss: 0.9472 - val_accuracy: 0.8449\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 0s 242us/step - loss: 0.8310 - accuracy: 0.8180 - val_loss: 0.8031 - val_accuracy: 0.8449\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 0s 235us/step - loss: 0.7343 - accuracy: 0.8180 - val_loss: 0.7153 - val_accuracy: 0.8449\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 0s 233us/step - loss: 0.6707 - accuracy: 0.8180 - val_loss: 0.6548 - val_accuracy: 0.8449\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 0s 238us/step - loss: 0.6311 - accuracy: 0.8180 - val_loss: 0.6254 - val_accuracy: 0.8449\n",
      "Epoch 8/1000\n",
      "1857/1857 [==============================] - 0s 235us/step - loss: 0.6184 - accuracy: 0.8180 - val_loss: 0.6150 - val_accuracy: 0.8449\n",
      "Epoch 9/1000\n",
      "1857/1857 [==============================] - 0s 223us/step - loss: 0.6029 - accuracy: 0.8180 - val_loss: 0.6132 - val_accuracy: 0.8449\n",
      "Epoch 10/1000\n",
      "1857/1857 [==============================] - 0s 225us/step - loss: 0.5969 - accuracy: 0.8180 - val_loss: 0.6124 - val_accuracy: 0.8449\n",
      "Epoch 11/1000\n",
      "1857/1857 [==============================] - 0s 247us/step - loss: 0.5898 - accuracy: 0.8180 - val_loss: 0.6113 - val_accuracy: 0.8449\n",
      "Epoch 12/1000\n",
      "1857/1857 [==============================] - 0s 238us/step - loss: 0.5851 - accuracy: 0.8180 - val_loss: 0.6115 - val_accuracy: 0.8449\n",
      "Epoch 13/1000\n",
      "1857/1857 [==============================] - 0s 227us/step - loss: 0.5805 - accuracy: 0.8180 - val_loss: 0.6111 - val_accuracy: 0.8449\n",
      "Epoch 14/1000\n",
      "1857/1857 [==============================] - 0s 237us/step - loss: 0.5785 - accuracy: 0.8180 - val_loss: 0.6139 - val_accuracy: 0.8449\n",
      "Epoch 15/1000\n",
      "1857/1857 [==============================] - 0s 238us/step - loss: 0.5735 - accuracy: 0.8180 - val_loss: 0.6137 - val_accuracy: 0.8449\n",
      "Epoch 16/1000\n",
      "1857/1857 [==============================] - 0s 230us/step - loss: 0.5761 - accuracy: 0.8180 - val_loss: 0.6122 - val_accuracy: 0.8449\n",
      "Epoch 17/1000\n",
      "1857/1857 [==============================] - 0s 233us/step - loss: 0.5728 - accuracy: 0.8180 - val_loss: 0.6155 - val_accuracy: 0.8449\n",
      "Epoch 18/1000\n",
      "1857/1857 [==============================] - 0s 230us/step - loss: 0.5652 - accuracy: 0.8180 - val_loss: 0.6107 - val_accuracy: 0.8449\n",
      "Epoch 19/1000\n",
      "1857/1857 [==============================] - 0s 233us/step - loss: 0.5702 - accuracy: 0.8180 - val_loss: 0.6093 - val_accuracy: 0.8449\n",
      "Epoch 20/1000\n",
      "1857/1857 [==============================] - 0s 230us/step - loss: 0.5666 - accuracy: 0.8180 - val_loss: 0.6147 - val_accuracy: 0.8449\n",
      "Epoch 21/1000\n",
      "1857/1857 [==============================] - 0s 229us/step - loss: 0.5682 - accuracy: 0.8180 - val_loss: 0.6202 - val_accuracy: 0.8449\n",
      "Epoch 22/1000\n",
      "1857/1857 [==============================] - 0s 228us/step - loss: 0.5576 - accuracy: 0.8180 - val_loss: 0.6174 - val_accuracy: 0.8449\n",
      "Epoch 23/1000\n",
      "1857/1857 [==============================] - 0s 233us/step - loss: 0.5566 - accuracy: 0.8180 - val_loss: 0.6177 - val_accuracy: 0.8449\n",
      "Epoch 24/1000\n",
      "1857/1857 [==============================] - 0s 230us/step - loss: 0.5588 - accuracy: 0.8180 - val_loss: 0.6234 - val_accuracy: 0.8449\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 1s 603us/step - loss: 1.3206 - accuracy: 0.5283 - val_loss: 1.2524 - val_accuracy: 0.8368\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 0s 230us/step - loss: 1.1687 - accuracy: 0.7760 - val_loss: 1.1005 - val_accuracy: 0.8368\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 0s 235us/step - loss: 1.0040 - accuracy: 0.8008 - val_loss: 0.9298 - val_accuracy: 0.8352\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 0s 244us/step - loss: 0.8526 - accuracy: 0.8110 - val_loss: 0.8016 - val_accuracy: 0.8352\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 0s 234us/step - loss: 0.7384 - accuracy: 0.8121 - val_loss: 0.7120 - val_accuracy: 0.8352\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 0s 247us/step - loss: 0.6631 - accuracy: 0.8185 - val_loss: 0.6696 - val_accuracy: 0.8352\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 0s 236us/step - loss: 0.6291 - accuracy: 0.8191 - val_loss: 0.6534 - val_accuracy: 0.8352\n",
      "Epoch 8/1000\n",
      "1857/1857 [==============================] - 0s 226us/step - loss: 0.6052 - accuracy: 0.8164 - val_loss: 0.6482 - val_accuracy: 0.8352\n",
      "Epoch 9/1000\n",
      "1857/1857 [==============================] - 0s 242us/step - loss: 0.5945 - accuracy: 0.8196 - val_loss: 0.6461 - val_accuracy: 0.8352\n",
      "Epoch 10/1000\n",
      "1857/1857 [==============================] - 0s 242us/step - loss: 0.5873 - accuracy: 0.8164 - val_loss: 0.6487 - val_accuracy: 0.8352\n",
      "Epoch 11/1000\n",
      "1857/1857 [==============================] - 0s 230us/step - loss: 0.5779 - accuracy: 0.8174 - val_loss: 0.6448 - val_accuracy: 0.8352\n",
      "Epoch 12/1000\n",
      "1857/1857 [==============================] - 0s 224us/step - loss: 0.5725 - accuracy: 0.8174 - val_loss: 0.6522 - val_accuracy: 0.8352\n",
      "Epoch 13/1000\n",
      "1857/1857 [==============================] - 0s 230us/step - loss: 0.5672 - accuracy: 0.8207 - val_loss: 0.6512 - val_accuracy: 0.8352\n",
      "Epoch 14/1000\n",
      "1857/1857 [==============================] - 0s 224us/step - loss: 0.5611 - accuracy: 0.8180 - val_loss: 0.6558 - val_accuracy: 0.8352\n",
      "Epoch 15/1000\n",
      "1857/1857 [==============================] - 0s 238us/step - loss: 0.5651 - accuracy: 0.8201 - val_loss: 0.6518 - val_accuracy: 0.8352\n",
      "Epoch 16/1000\n",
      "1857/1857 [==============================] - 0s 241us/step - loss: 0.5572 - accuracy: 0.8207 - val_loss: 0.6564 - val_accuracy: 0.8352\n",
      "auc: 0.7177742955890996\n",
      "kappa: 0.10919415278246088\n",
      "nodes: 4\n",
      "Train on 1854 samples, validate on 618 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 1s 631us/step - loss: 1.3149 - accuracy: 0.5804 - val_loss: 1.2252 - val_accuracy: 0.8301\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 0s 224us/step - loss: 1.1312 - accuracy: 0.7654 - val_loss: 0.9988 - val_accuracy: 0.8301\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 0s 235us/step - loss: 0.9139 - accuracy: 0.8064 - val_loss: 0.8059 - val_accuracy: 0.8301\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 0s 223us/step - loss: 0.7432 - accuracy: 0.8112 - val_loss: 0.6901 - val_accuracy: 0.8301\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 0s 226us/step - loss: 0.6354 - accuracy: 0.8215 - val_loss: 0.6504 - val_accuracy: 0.8301\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 0s 228us/step - loss: 0.5917 - accuracy: 0.8220 - val_loss: 0.6460 - val_accuracy: 0.8301\n",
      "Epoch 7/1000\n",
      "1854/1854 [==============================] - 0s 232us/step - loss: 0.5847 - accuracy: 0.8209 - val_loss: 0.6495 - val_accuracy: 0.8301\n",
      "Epoch 8/1000\n",
      "1854/1854 [==============================] - 0s 229us/step - loss: 0.5724 - accuracy: 0.8215 - val_loss: 0.6527 - val_accuracy: 0.8301\n",
      "Epoch 9/1000\n",
      "1854/1854 [==============================] - 0s 226us/step - loss: 0.5696 - accuracy: 0.8247 - val_loss: 0.6618 - val_accuracy: 0.8285\n",
      "Epoch 10/1000\n",
      "1854/1854 [==============================] - 0s 225us/step - loss: 0.5642 - accuracy: 0.8193 - val_loss: 0.6673 - val_accuracy: 0.8285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/1000\n",
      "1854/1854 [==============================] - 0s 232us/step - loss: 0.5535 - accuracy: 0.8220 - val_loss: 0.6768 - val_accuracy: 0.8188\n",
      "Train on 1854 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 1s 630us/step - loss: 1.3115 - accuracy: 0.4676 - val_loss: 1.2183 - val_accuracy: 0.8481\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 0s 228us/step - loss: 1.1156 - accuracy: 0.7756 - val_loss: 0.9985 - val_accuracy: 0.8481\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 0s 238us/step - loss: 0.8984 - accuracy: 0.8015 - val_loss: 0.7954 - val_accuracy: 0.8481\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 0s 236us/step - loss: 0.7345 - accuracy: 0.8058 - val_loss: 0.6579 - val_accuracy: 0.8481\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 0s 235us/step - loss: 0.6389 - accuracy: 0.8123 - val_loss: 0.6055 - val_accuracy: 0.8481\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 0s 235us/step - loss: 0.5945 - accuracy: 0.8166 - val_loss: 0.5894 - val_accuracy: 0.8481\n",
      "Epoch 7/1000\n",
      "1854/1854 [==============================] - 0s 230us/step - loss: 0.5789 - accuracy: 0.8150 - val_loss: 0.5865 - val_accuracy: 0.8481\n",
      "Epoch 8/1000\n",
      "1854/1854 [==============================] - 0s 235us/step - loss: 0.5725 - accuracy: 0.8128 - val_loss: 0.5902 - val_accuracy: 0.8481\n",
      "Epoch 9/1000\n",
      "1854/1854 [==============================] - 0s 229us/step - loss: 0.5738 - accuracy: 0.8161 - val_loss: 0.5875 - val_accuracy: 0.8481\n",
      "Epoch 10/1000\n",
      "1854/1854 [==============================] - 0s 228us/step - loss: 0.5588 - accuracy: 0.8150 - val_loss: 0.5945 - val_accuracy: 0.8481\n",
      "Epoch 11/1000\n",
      "1854/1854 [==============================] - 0s 236us/step - loss: 0.5542 - accuracy: 0.8166 - val_loss: 0.6043 - val_accuracy: 0.8433\n",
      "Epoch 12/1000\n",
      "1854/1854 [==============================] - 0s 226us/step - loss: 0.5573 - accuracy: 0.8198 - val_loss: 0.5982 - val_accuracy: 0.8481\n",
      "Train on 1856 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1856/1856 [==============================] - 1s 644us/step - loss: 1.3063 - accuracy: 0.5162 - val_loss: 1.1968 - val_accuracy: 0.8336\n",
      "Epoch 2/1000\n",
      "1856/1856 [==============================] - 0s 227us/step - loss: 1.1012 - accuracy: 0.7683 - val_loss: 0.9727 - val_accuracy: 0.8336\n",
      "Epoch 3/1000\n",
      "1856/1856 [==============================] - 0s 232us/step - loss: 0.8854 - accuracy: 0.8001 - val_loss: 0.7840 - val_accuracy: 0.8336\n",
      "Epoch 4/1000\n",
      "1856/1856 [==============================] - 0s 233us/step - loss: 0.7238 - accuracy: 0.8120 - val_loss: 0.6766 - val_accuracy: 0.8336\n",
      "Epoch 5/1000\n",
      "1856/1856 [==============================] - 0s 240us/step - loss: 0.6320 - accuracy: 0.8157 - val_loss: 0.6498 - val_accuracy: 0.8336\n",
      "Epoch 6/1000\n",
      "1856/1856 [==============================] - 0s 230us/step - loss: 0.5950 - accuracy: 0.8163 - val_loss: 0.6398 - val_accuracy: 0.8336\n",
      "Epoch 7/1000\n",
      "1856/1856 [==============================] - 0s 232us/step - loss: 0.5807 - accuracy: 0.8195 - val_loss: 0.6462 - val_accuracy: 0.8336\n",
      "Epoch 8/1000\n",
      "1856/1856 [==============================] - 0s 236us/step - loss: 0.5716 - accuracy: 0.8173 - val_loss: 0.6513 - val_accuracy: 0.8336\n",
      "Epoch 9/1000\n",
      "1856/1856 [==============================] - 0s 229us/step - loss: 0.5642 - accuracy: 0.8211 - val_loss: 0.6569 - val_accuracy: 0.8336\n",
      "Epoch 10/1000\n",
      "1856/1856 [==============================] - 0s 227us/step - loss: 0.5618 - accuracy: 0.8173 - val_loss: 0.6611 - val_accuracy: 0.8336\n",
      "Epoch 11/1000\n",
      "1856/1856 [==============================] - 0s 225us/step - loss: 0.5573 - accuracy: 0.8206 - val_loss: 0.6649 - val_accuracy: 0.8320\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 1s 666us/step - loss: 1.2864 - accuracy: 0.5423 - val_loss: 1.1657 - val_accuracy: 0.8578\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 0s 235us/step - loss: 1.0658 - accuracy: 0.7421 - val_loss: 0.9210 - val_accuracy: 0.8578\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 0s 235us/step - loss: 0.8461 - accuracy: 0.7889 - val_loss: 0.7225 - val_accuracy: 0.8578\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 0s 235us/step - loss: 0.7215 - accuracy: 0.7981 - val_loss: 0.6224 - val_accuracy: 0.8578\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 0s 240us/step - loss: 0.6517 - accuracy: 0.8072 - val_loss: 0.5850 - val_accuracy: 0.8578\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 0s 238us/step - loss: 0.6208 - accuracy: 0.8083 - val_loss: 0.5724 - val_accuracy: 0.8578\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 0s 234us/step - loss: 0.6120 - accuracy: 0.8099 - val_loss: 0.5788 - val_accuracy: 0.8578\n",
      "Epoch 8/1000\n",
      "1857/1857 [==============================] - 0s 233us/step - loss: 0.5995 - accuracy: 0.8094 - val_loss: 0.5811 - val_accuracy: 0.8578\n",
      "Epoch 9/1000\n",
      "1857/1857 [==============================] - 0s 248us/step - loss: 0.5958 - accuracy: 0.8099 - val_loss: 0.5864 - val_accuracy: 0.8578\n",
      "Epoch 10/1000\n",
      "1857/1857 [==============================] - 0s 242us/step - loss: 0.5875 - accuracy: 0.8158 - val_loss: 0.5897 - val_accuracy: 0.8578\n",
      "Epoch 11/1000\n",
      "1857/1857 [==============================] - 0s 241us/step - loss: 0.5879 - accuracy: 0.8056 - val_loss: 0.5930 - val_accuracy: 0.8578\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 1s 695us/step - loss: 1.3077 - accuracy: 0.5810 - val_loss: 1.1924 - val_accuracy: 0.8481\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 0s 243us/step - loss: 1.1067 - accuracy: 0.7728 - val_loss: 0.9695 - val_accuracy: 0.8481\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 0s 236us/step - loss: 0.8955 - accuracy: 0.7916 - val_loss: 0.7767 - val_accuracy: 0.8481\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 0s 242us/step - loss: 0.7385 - accuracy: 0.8029 - val_loss: 0.6657 - val_accuracy: 0.8481\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 0s 237us/step - loss: 0.6545 - accuracy: 0.8126 - val_loss: 0.6219 - val_accuracy: 0.8481\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 0s 239us/step - loss: 0.6064 - accuracy: 0.8191 - val_loss: 0.6079 - val_accuracy: 0.8481\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 0s 236us/step - loss: 0.5862 - accuracy: 0.8174 - val_loss: 0.6048 - val_accuracy: 0.8481\n",
      "Epoch 8/1000\n",
      "1857/1857 [==============================] - 0s 241us/step - loss: 0.5799 - accuracy: 0.8185 - val_loss: 0.6111 - val_accuracy: 0.8481\n",
      "Epoch 9/1000\n",
      "1857/1857 [==============================] - 0s 236us/step - loss: 0.5662 - accuracy: 0.8207 - val_loss: 0.6082 - val_accuracy: 0.8481\n",
      "Epoch 10/1000\n",
      "1857/1857 [==============================] - 0s 239us/step - loss: 0.5812 - accuracy: 0.8115 - val_loss: 0.6176 - val_accuracy: 0.8481\n",
      "Epoch 11/1000\n",
      "1857/1857 [==============================] - 0s 236us/step - loss: 0.5636 - accuracy: 0.8174 - val_loss: 0.6205 - val_accuracy: 0.8465\n",
      "Epoch 12/1000\n",
      "1857/1857 [==============================] - 0s 234us/step - loss: 0.5643 - accuracy: 0.8174 - val_loss: 0.6139 - val_accuracy: 0.8465\n",
      "auc: 0.7132627376776779\n",
      "kappa: 0.11807673068399013\n",
      "nodes: 8\n",
      "Train on 1854 samples, validate on 618 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 1s 708us/step - loss: 1.2607 - accuracy: 0.5669 - val_loss: 1.1220 - val_accuracy: 0.8528\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 0s 242us/step - loss: 0.9808 - accuracy: 0.7627 - val_loss: 0.8279 - val_accuracy: 0.8528\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 0s 234us/step - loss: 0.7493 - accuracy: 0.8015 - val_loss: 0.6485 - val_accuracy: 0.8528\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 0s 239us/step - loss: 0.6338 - accuracy: 0.8101 - val_loss: 0.5998 - val_accuracy: 0.8528\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 0s 236us/step - loss: 0.5960 - accuracy: 0.8128 - val_loss: 0.5831 - val_accuracy: 0.8528\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 0s 237us/step - loss: 0.5802 - accuracy: 0.8118 - val_loss: 0.5783 - val_accuracy: 0.8528\n",
      "Epoch 7/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1854/1854 [==============================] - 0s 238us/step - loss: 0.5701 - accuracy: 0.8161 - val_loss: 0.5813 - val_accuracy: 0.8528\n",
      "Epoch 8/1000\n",
      "1854/1854 [==============================] - 0s 235us/step - loss: 0.5642 - accuracy: 0.8166 - val_loss: 0.5921 - val_accuracy: 0.8511\n",
      "Epoch 9/1000\n",
      "1854/1854 [==============================] - 0s 239us/step - loss: 0.5514 - accuracy: 0.8107 - val_loss: 0.5943 - val_accuracy: 0.8511\n",
      "Epoch 10/1000\n",
      "1854/1854 [==============================] - 0s 235us/step - loss: 0.5518 - accuracy: 0.8182 - val_loss: 0.5970 - val_accuracy: 0.8463\n",
      "Epoch 11/1000\n",
      "1854/1854 [==============================] - 0s 236us/step - loss: 0.5454 - accuracy: 0.8172 - val_loss: 0.5995 - val_accuracy: 0.8528\n",
      "Train on 1854 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 1s 716us/step - loss: 1.2510 - accuracy: 0.6138 - val_loss: 1.0893 - val_accuracy: 0.8530\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 0s 238us/step - loss: 0.9590 - accuracy: 0.7638 - val_loss: 0.7792 - val_accuracy: 0.8530\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 0s 237us/step - loss: 0.7255 - accuracy: 0.7961 - val_loss: 0.6126 - val_accuracy: 0.8530\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 0s 238us/step - loss: 0.6251 - accuracy: 0.8091 - val_loss: 0.5759 - val_accuracy: 0.8530\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 0s 251us/step - loss: 0.5813 - accuracy: 0.8215 - val_loss: 0.5789 - val_accuracy: 0.8530\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 0s 238us/step - loss: 0.5691 - accuracy: 0.8123 - val_loss: 0.5807 - val_accuracy: 0.8514\n",
      "Epoch 7/1000\n",
      "1854/1854 [==============================] - 0s 242us/step - loss: 0.5650 - accuracy: 0.8172 - val_loss: 0.5867 - val_accuracy: 0.8514\n",
      "Epoch 8/1000\n",
      "1854/1854 [==============================] - 0s 240us/step - loss: 0.5568 - accuracy: 0.8139 - val_loss: 0.5925 - val_accuracy: 0.8481\n",
      "Epoch 9/1000\n",
      "1854/1854 [==============================] - 0s 238us/step - loss: 0.5531 - accuracy: 0.8091 - val_loss: 0.5964 - val_accuracy: 0.8498\n",
      "Train on 1856 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1856/1856 [==============================] - 1s 727us/step - loss: 1.2738 - accuracy: 0.6169 - val_loss: 1.1371 - val_accuracy: 0.8481\n",
      "Epoch 2/1000\n",
      "1856/1856 [==============================] - 0s 241us/step - loss: 1.0113 - accuracy: 0.7554 - val_loss: 0.8307 - val_accuracy: 0.8481\n",
      "Epoch 3/1000\n",
      "1856/1856 [==============================] - 0s 241us/step - loss: 0.7741 - accuracy: 0.7904 - val_loss: 0.6401 - val_accuracy: 0.8481\n",
      "Epoch 4/1000\n",
      "1856/1856 [==============================] - 0s 240us/step - loss: 0.6307 - accuracy: 0.8168 - val_loss: 0.5929 - val_accuracy: 0.8481\n",
      "Epoch 5/1000\n",
      "1856/1856 [==============================] - 0s 239us/step - loss: 0.5956 - accuracy: 0.8087 - val_loss: 0.5909 - val_accuracy: 0.8481\n",
      "Epoch 6/1000\n",
      "1856/1856 [==============================] - 0s 242us/step - loss: 0.5813 - accuracy: 0.8098 - val_loss: 0.5973 - val_accuracy: 0.8481\n",
      "Epoch 7/1000\n",
      "1856/1856 [==============================] - 0s 246us/step - loss: 0.5638 - accuracy: 0.8098 - val_loss: 0.5967 - val_accuracy: 0.8481\n",
      "Epoch 8/1000\n",
      "1856/1856 [==============================] - 0s 237us/step - loss: 0.5609 - accuracy: 0.8141 - val_loss: 0.6078 - val_accuracy: 0.8465\n",
      "Epoch 9/1000\n",
      "1856/1856 [==============================] - 0s 237us/step - loss: 0.5473 - accuracy: 0.8163 - val_loss: 0.6179 - val_accuracy: 0.8465\n",
      "Epoch 10/1000\n",
      "1856/1856 [==============================] - 0s 240us/step - loss: 0.5519 - accuracy: 0.8163 - val_loss: 0.6153 - val_accuracy: 0.8449\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 1s 762us/step - loss: 1.2608 - accuracy: 0.5428 - val_loss: 1.1426 - val_accuracy: 0.8207\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 1s 296us/step - loss: 0.9620 - accuracy: 0.7900 - val_loss: 0.8708 - val_accuracy: 0.8207\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 0s 268us/step - loss: 0.7245 - accuracy: 0.8137 - val_loss: 0.7149 - val_accuracy: 0.8207\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 0s 256us/step - loss: 0.5930 - accuracy: 0.8288 - val_loss: 0.6769 - val_accuracy: 0.8207\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - ETA: 0s - loss: 0.5668 - accuracy: 0.82 - 0s 248us/step - loss: 0.5651 - accuracy: 0.8277 - val_loss: 0.6791 - val_accuracy: 0.8207\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 0s 255us/step - loss: 0.5581 - accuracy: 0.8223 - val_loss: 0.6894 - val_accuracy: 0.8207\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 0s 255us/step - loss: 0.5408 - accuracy: 0.8282 - val_loss: 0.7009 - val_accuracy: 0.8207\n",
      "Epoch 8/1000\n",
      "1857/1857 [==============================] - 1s 272us/step - loss: 0.5386 - accuracy: 0.8207 - val_loss: 0.7012 - val_accuracy: 0.8207\n",
      "Epoch 9/1000\n",
      "1857/1857 [==============================] - 0s 255us/step - loss: 0.5376 - accuracy: 0.8266 - val_loss: 0.7083 - val_accuracy: 0.8191\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 1s 775us/step - loss: 1.2683 - accuracy: 0.5934 - val_loss: 1.0914 - val_accuracy: 0.8433\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 0s 252us/step - loss: 0.9938 - accuracy: 0.7528 - val_loss: 0.7821 - val_accuracy: 0.8433\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 0s 258us/step - loss: 0.7539 - accuracy: 0.8008 - val_loss: 0.6190 - val_accuracy: 0.8433\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 0s 249us/step - loss: 0.6389 - accuracy: 0.8121 - val_loss: 0.5971 - val_accuracy: 0.8433\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 0s 250us/step - loss: 0.6002 - accuracy: 0.8153 - val_loss: 0.6006 - val_accuracy: 0.8433\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 0s 252us/step - loss: 0.5755 - accuracy: 0.8207 - val_loss: 0.6062 - val_accuracy: 0.8433\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 0s 250us/step - loss: 0.5801 - accuracy: 0.8185 - val_loss: 0.6125 - val_accuracy: 0.8433\n",
      "Epoch 8/1000\n",
      "1857/1857 [==============================] - 0s 254us/step - loss: 0.5670 - accuracy: 0.8131 - val_loss: 0.6132 - val_accuracy: 0.8401\n",
      "Epoch 9/1000\n",
      "1857/1857 [==============================] - 0s 248us/step - loss: 0.5551 - accuracy: 0.8191 - val_loss: 0.6062 - val_accuracy: 0.8433\n",
      "auc: 0.7151809644420328\n",
      "kappa: 0.08911318181018313\n",
      "nodes: 16\n",
      "Train on 1854 samples, validate on 618 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 1s 803us/step - loss: 1.2247 - accuracy: 0.6063 - val_loss: 1.0439 - val_accuracy: 0.8625\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 0s 247us/step - loss: 0.8705 - accuracy: 0.7697 - val_loss: 0.6917 - val_accuracy: 0.8625\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 0s 253us/step - loss: 0.6477 - accuracy: 0.8161 - val_loss: 0.5499 - val_accuracy: 0.8625\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 0s 254us/step - loss: 0.5861 - accuracy: 0.8134 - val_loss: 0.5476 - val_accuracy: 0.8625\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 0s 253us/step - loss: 0.5695 - accuracy: 0.8134 - val_loss: 0.5518 - val_accuracy: 0.8625\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 0s 253us/step - loss: 0.5604 - accuracy: 0.8134 - val_loss: 0.5660 - val_accuracy: 0.8625\n",
      "Epoch 7/1000\n",
      "1854/1854 [==============================] - 0s 251us/step - loss: 0.5522 - accuracy: 0.8155 - val_loss: 0.5777 - val_accuracy: 0.8560\n",
      "Epoch 8/1000\n",
      "1854/1854 [==============================] - 0s 259us/step - loss: 0.5402 - accuracy: 0.8177 - val_loss: 0.5731 - val_accuracy: 0.8625\n",
      "Epoch 9/1000\n",
      "1854/1854 [==============================] - 0s 268us/step - loss: 0.5361 - accuracy: 0.8161 - val_loss: 0.5950 - val_accuracy: 0.8479\n",
      "Train on 1854 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 2s 813us/step - loss: 1.2207 - accuracy: 0.6063 - val_loss: 1.0758 - val_accuracy: 0.8368\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 0s 256us/step - loss: 0.8556 - accuracy: 0.7864 - val_loss: 0.7325 - val_accuracy: 0.8368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 0s 254us/step - loss: 0.6329 - accuracy: 0.8204 - val_loss: 0.6334 - val_accuracy: 0.8368\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 0s 256us/step - loss: 0.5653 - accuracy: 0.8225 - val_loss: 0.6169 - val_accuracy: 0.8368\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 0s 254us/step - loss: 0.5565 - accuracy: 0.8145 - val_loss: 0.6237 - val_accuracy: 0.8368\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 0s 259us/step - loss: 0.5434 - accuracy: 0.8236 - val_loss: 0.6325 - val_accuracy: 0.8336\n",
      "Epoch 7/1000\n",
      "1854/1854 [==============================] - 0s 262us/step - loss: 0.5402 - accuracy: 0.8188 - val_loss: 0.6305 - val_accuracy: 0.8368\n",
      "Epoch 8/1000\n",
      "1854/1854 [==============================] - 0s 253us/step - loss: 0.5220 - accuracy: 0.8279 - val_loss: 0.6386 - val_accuracy: 0.8368\n",
      "Epoch 9/1000\n",
      "1854/1854 [==============================] - 0s 249us/step - loss: 0.5353 - accuracy: 0.8252 - val_loss: 0.6413 - val_accuracy: 0.8368\n",
      "Train on 1856 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1856/1856 [==============================] - 2s 828us/step - loss: 1.2176 - accuracy: 0.6126 - val_loss: 0.9966 - val_accuracy: 0.8417\n",
      "Epoch 2/1000\n",
      "1856/1856 [==============================] - 0s 254us/step - loss: 0.8488 - accuracy: 0.7769 - val_loss: 0.6666 - val_accuracy: 0.8417\n",
      "Epoch 3/1000\n",
      "1856/1856 [==============================] - 0s 259us/step - loss: 0.6389 - accuracy: 0.8103 - val_loss: 0.6038 - val_accuracy: 0.8417\n",
      "Epoch 4/1000\n",
      "1856/1856 [==============================] - 0s 257us/step - loss: 0.5653 - accuracy: 0.8168 - val_loss: 0.6193 - val_accuracy: 0.8417\n",
      "Epoch 5/1000\n",
      "1856/1856 [==============================] - 0s 260us/step - loss: 0.5530 - accuracy: 0.8168 - val_loss: 0.6346 - val_accuracy: 0.8417\n",
      "Epoch 6/1000\n",
      "1856/1856 [==============================] - 0s 255us/step - loss: 0.5450 - accuracy: 0.8147 - val_loss: 0.6295 - val_accuracy: 0.8417\n",
      "Epoch 7/1000\n",
      "1856/1856 [==============================] - 0s 258us/step - loss: 0.5435 - accuracy: 0.8173 - val_loss: 0.6387 - val_accuracy: 0.8384\n",
      "Epoch 8/1000\n",
      "1856/1856 [==============================] - 0s 256us/step - loss: 0.5343 - accuracy: 0.8152 - val_loss: 0.6324 - val_accuracy: 0.8368\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 2s 847us/step - loss: 1.2494 - accuracy: 0.5687 - val_loss: 1.0859 - val_accuracy: 0.8352\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 0s 268us/step - loss: 0.8871 - accuracy: 0.7835 - val_loss: 0.7271 - val_accuracy: 0.8352\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 1s 270us/step - loss: 0.6345 - accuracy: 0.8169 - val_loss: 0.6244 - val_accuracy: 0.8352\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 1s 270us/step - loss: 0.5709 - accuracy: 0.8164 - val_loss: 0.6270 - val_accuracy: 0.8352\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 1s 279us/step - loss: 0.5529 - accuracy: 0.8191 - val_loss: 0.6356 - val_accuracy: 0.8352\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 0s 267us/step - loss: 0.5441 - accuracy: 0.8201 - val_loss: 0.6557 - val_accuracy: 0.8352\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 1s 270us/step - loss: 0.5364 - accuracy: 0.8185 - val_loss: 0.6478 - val_accuracy: 0.8352\n",
      "Epoch 8/1000\n",
      "1857/1857 [==============================] - 1s 271us/step - loss: 0.5329 - accuracy: 0.8201 - val_loss: 0.6597 - val_accuracy: 0.8352\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 2s 872us/step - loss: 1.2093 - accuracy: 0.6376 - val_loss: 0.9615 - val_accuracy: 0.8417\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 1s 271us/step - loss: 0.8564 - accuracy: 0.7684 - val_loss: 0.6435 - val_accuracy: 0.8417\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 1s 275us/step - loss: 0.6423 - accuracy: 0.8083 - val_loss: 0.6080 - val_accuracy: 0.8417\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 1s 277us/step - loss: 0.5827 - accuracy: 0.8131 - val_loss: 0.6157 - val_accuracy: 0.8417\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 1s 275us/step - loss: 0.5472 - accuracy: 0.8212 - val_loss: 0.6323 - val_accuracy: 0.8417\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 1s 271us/step - loss: 0.5509 - accuracy: 0.8164 - val_loss: 0.6208 - val_accuracy: 0.8417\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 1s 271us/step - loss: 0.5309 - accuracy: 0.8191 - val_loss: 0.6271 - val_accuracy: 0.8401\n",
      "Epoch 8/1000\n",
      "1857/1857 [==============================] - 1s 270us/step - loss: 0.5203 - accuracy: 0.8261 - val_loss: 0.6306 - val_accuracy: 0.8384\n",
      "auc: 0.7130095477704733\n",
      "kappa: 0.1300401535467524\n",
      "nodes: 32\n",
      "Train on 1854 samples, validate on 618 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 2s 952us/step - loss: 1.1333 - accuracy: 0.6338 - val_loss: 0.8702 - val_accuracy: 0.8463\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 1s 285us/step - loss: 0.7355 - accuracy: 0.7967 - val_loss: 0.5980 - val_accuracy: 0.8463\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 1s 276us/step - loss: 0.5792 - accuracy: 0.8166 - val_loss: 0.6074 - val_accuracy: 0.8463\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 1s 304us/step - loss: 0.5480 - accuracy: 0.8225 - val_loss: 0.6495 - val_accuracy: 0.8463\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 1s 314us/step - loss: 0.5400 - accuracy: 0.8193 - val_loss: 0.6539 - val_accuracy: 0.8463\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 1s 295us/step - loss: 0.5167 - accuracy: 0.8177 - val_loss: 0.6482 - val_accuracy: 0.8463\n",
      "Epoch 7/1000\n",
      "1854/1854 [==============================] - 1s 296us/step - loss: 0.5166 - accuracy: 0.8215 - val_loss: 0.6574 - val_accuracy: 0.8204\n",
      "Train on 1854 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 2s 956us/step - loss: 1.1546 - accuracy: 0.6300 - val_loss: 0.8855 - val_accuracy: 0.8417\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 1s 278us/step - loss: 0.7350 - accuracy: 0.8031 - val_loss: 0.6164 - val_accuracy: 0.8417\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 1s 280us/step - loss: 0.5723 - accuracy: 0.8209 - val_loss: 0.6217 - val_accuracy: 0.8417\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 1s 280us/step - loss: 0.5448 - accuracy: 0.8182 - val_loss: 0.6191 - val_accuracy: 0.8417\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 1s 276us/step - loss: 0.5325 - accuracy: 0.8188 - val_loss: 0.6444 - val_accuracy: 0.8417\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 1s 278us/step - loss: 0.5386 - accuracy: 0.8177 - val_loss: 0.6300 - val_accuracy: 0.8417\n",
      "Epoch 7/1000\n",
      "1854/1854 [==============================] - 1s 280us/step - loss: 0.5217 - accuracy: 0.8209 - val_loss: 0.6261 - val_accuracy: 0.8368\n",
      "Train on 1856 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1856/1856 [==============================] - 2s 946us/step - loss: 1.1521 - accuracy: 0.6288 - val_loss: 0.9077 - val_accuracy: 0.8401\n",
      "Epoch 2/1000\n",
      "1856/1856 [==============================] - 1s 283us/step - loss: 0.7391 - accuracy: 0.7969 - val_loss: 0.6125 - val_accuracy: 0.8401\n",
      "Epoch 3/1000\n",
      "1856/1856 [==============================] - 1s 272us/step - loss: 0.5792 - accuracy: 0.8173 - val_loss: 0.6267 - val_accuracy: 0.8401\n",
      "Epoch 4/1000\n",
      "1856/1856 [==============================] - 1s 271us/step - loss: 0.5482 - accuracy: 0.8157 - val_loss: 0.6450 - val_accuracy: 0.8401\n",
      "Epoch 5/1000\n",
      "1856/1856 [==============================] - 1s 271us/step - loss: 0.5420 - accuracy: 0.8227 - val_loss: 0.6279 - val_accuracy: 0.8401\n",
      "Epoch 6/1000\n",
      "1856/1856 [==============================] - 1s 274us/step - loss: 0.5319 - accuracy: 0.8217 - val_loss: 0.6429 - val_accuracy: 0.8384\n",
      "Epoch 7/1000\n",
      "1856/1856 [==============================] - 1s 270us/step - loss: 0.5275 - accuracy: 0.8206 - val_loss: 0.6356 - val_accuracy: 0.8336\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 2s 946us/step - loss: 1.1503 - accuracy: 0.6586 - val_loss: 0.8831 - val_accuracy: 0.8384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 1s 271us/step - loss: 0.7397 - accuracy: 0.7938 - val_loss: 0.6242 - val_accuracy: 0.8384\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 0s 264us/step - loss: 0.5792 - accuracy: 0.8142 - val_loss: 0.6287 - val_accuracy: 0.8384\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 0s 263us/step - loss: 0.5389 - accuracy: 0.8207 - val_loss: 0.6233 - val_accuracy: 0.8384\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 0s 266us/step - loss: 0.5419 - accuracy: 0.8201 - val_loss: 0.6180 - val_accuracy: 0.8384\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 1s 271us/step - loss: 0.5416 - accuracy: 0.8169 - val_loss: 0.6194 - val_accuracy: 0.8384\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 0s 265us/step - loss: 0.5138 - accuracy: 0.8234 - val_loss: 0.6178 - val_accuracy: 0.8336\n",
      "Epoch 8/1000\n",
      "1857/1857 [==============================] - 0s 265us/step - loss: 0.5105 - accuracy: 0.8250 - val_loss: 0.6399 - val_accuracy: 0.8207\n",
      "Epoch 9/1000\n",
      "1857/1857 [==============================] - 0s 267us/step - loss: 0.5043 - accuracy: 0.8239 - val_loss: 0.6388 - val_accuracy: 0.8271\n",
      "Epoch 10/1000\n",
      "1857/1857 [==============================] - 0s 267us/step - loss: 0.4888 - accuracy: 0.8255 - val_loss: 0.6500 - val_accuracy: 0.8384\n",
      "Epoch 11/1000\n",
      "1857/1857 [==============================] - 1s 285us/step - loss: 0.4990 - accuracy: 0.8314 - val_loss: 0.6446 - val_accuracy: 0.8174\n",
      "Epoch 12/1000\n",
      "1857/1857 [==============================] - 1s 270us/step - loss: 0.4798 - accuracy: 0.8433 - val_loss: 0.6599 - val_accuracy: 0.8207\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 2s 975us/step - loss: 1.1432 - accuracy: 0.6344 - val_loss: 0.8807 - val_accuracy: 0.8514\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 1s 282us/step - loss: 0.7268 - accuracy: 0.7997 - val_loss: 0.6031 - val_accuracy: 0.8514\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 1s 284us/step - loss: 0.5800 - accuracy: 0.8174 - val_loss: 0.5877 - val_accuracy: 0.8514\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 1s 275us/step - loss: 0.5682 - accuracy: 0.8121 - val_loss: 0.6018 - val_accuracy: 0.8514\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 1s 277us/step - loss: 0.5535 - accuracy: 0.8137 - val_loss: 0.6201 - val_accuracy: 0.8514\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 1s 279us/step - loss: 0.5370 - accuracy: 0.8185 - val_loss: 0.6018 - val_accuracy: 0.8514\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 1s 281us/step - loss: 0.5415 - accuracy: 0.8207 - val_loss: 0.6027 - val_accuracy: 0.8498\n",
      "Epoch 8/1000\n",
      "1857/1857 [==============================] - 1s 275us/step - loss: 0.5219 - accuracy: 0.8271 - val_loss: 0.6290 - val_accuracy: 0.8465\n",
      "auc: 0.7208414399067028\n",
      "kappa: 0.09490843011561818\n",
      "nodes: 64\n",
      "Train on 1854 samples, validate on 618 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 2s 1ms/step - loss: 1.0726 - accuracy: 0.6715 - val_loss: 0.7318 - val_accuracy: 0.8479\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 1s 284us/step - loss: 0.6386 - accuracy: 0.8080 - val_loss: 0.5972 - val_accuracy: 0.8479\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 1s 296us/step - loss: 0.5663 - accuracy: 0.8150 - val_loss: 0.6012 - val_accuracy: 0.8479\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 1s 280us/step - loss: 0.5438 - accuracy: 0.8139 - val_loss: 0.6228 - val_accuracy: 0.8479\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 1s 301us/step - loss: 0.5388 - accuracy: 0.8155 - val_loss: 0.5994 - val_accuracy: 0.8479\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 1s 297us/step - loss: 0.5125 - accuracy: 0.8269 - val_loss: 0.6083 - val_accuracy: 0.8479\n",
      "Epoch 7/1000\n",
      "1854/1854 [==============================] - 1s 302us/step - loss: 0.5054 - accuracy: 0.8269 - val_loss: 0.6371 - val_accuracy: 0.8414\n",
      "Train on 1854 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 2s 1ms/step - loss: 1.0792 - accuracy: 0.6785 - val_loss: 0.7459 - val_accuracy: 0.8401\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 1s 318us/step - loss: 0.6499 - accuracy: 0.8037 - val_loss: 0.6161 - val_accuracy: 0.8401\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 1s 323us/step - loss: 0.5474 - accuracy: 0.8177 - val_loss: 0.6312 - val_accuracy: 0.8401\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 1s 315us/step - loss: 0.5297 - accuracy: 0.8193 - val_loss: 0.6289 - val_accuracy: 0.8401\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 1s 314us/step - loss: 0.5101 - accuracy: 0.8172 - val_loss: 0.6316 - val_accuracy: 0.8401\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 1s 321us/step - loss: 0.5055 - accuracy: 0.8204 - val_loss: 0.6449 - val_accuracy: 0.8401\n",
      "Epoch 7/1000\n",
      "1854/1854 [==============================] - 1s 324us/step - loss: 0.5092 - accuracy: 0.8231 - val_loss: 0.6634 - val_accuracy: 0.8320\n",
      "Train on 1856 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1856/1856 [==============================] - 2s 1ms/step - loss: 1.0938 - accuracy: 0.6584 - val_loss: 0.7632 - val_accuracy: 0.8320\n",
      "Epoch 2/1000\n",
      "1856/1856 [==============================] - 1s 319us/step - loss: 0.6412 - accuracy: 0.8141 - val_loss: 0.6385 - val_accuracy: 0.8320\n",
      "Epoch 3/1000\n",
      "1856/1856 [==============================] - 1s 315us/step - loss: 0.5623 - accuracy: 0.8190 - val_loss: 0.6655 - val_accuracy: 0.8320\n",
      "Epoch 4/1000\n",
      "1856/1856 [==============================] - 1s 311us/step - loss: 0.5344 - accuracy: 0.8179 - val_loss: 0.6616 - val_accuracy: 0.8320\n",
      "Epoch 5/1000\n",
      "1856/1856 [==============================] - 1s 317us/step - loss: 0.5272 - accuracy: 0.8249 - val_loss: 0.6628 - val_accuracy: 0.8320\n",
      "Epoch 6/1000\n",
      "1856/1856 [==============================] - 1s 319us/step - loss: 0.5122 - accuracy: 0.8249 - val_loss: 0.6519 - val_accuracy: 0.8142\n",
      "Epoch 7/1000\n",
      "1856/1856 [==============================] - 1s 316us/step - loss: 0.5035 - accuracy: 0.8265 - val_loss: 0.7004 - val_accuracy: 0.8110\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 2s 1ms/step - loss: 1.0850 - accuracy: 0.6602 - val_loss: 0.7515 - val_accuracy: 0.8562\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 1s 326us/step - loss: 0.6355 - accuracy: 0.8034 - val_loss: 0.5691 - val_accuracy: 0.8562\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 1s 323us/step - loss: 0.5599 - accuracy: 0.8174 - val_loss: 0.5691 - val_accuracy: 0.8562\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 1s 327us/step - loss: 0.5538 - accuracy: 0.8131 - val_loss: 0.5795 - val_accuracy: 0.8562\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 1s 327us/step - loss: 0.5377 - accuracy: 0.8126 - val_loss: 0.5669 - val_accuracy: 0.8562\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 1s 322us/step - loss: 0.5179 - accuracy: 0.8169 - val_loss: 0.5754 - val_accuracy: 0.8562\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 1s 330us/step - loss: 0.5177 - accuracy: 0.8180 - val_loss: 0.6099 - val_accuracy: 0.8562\n",
      "Epoch 8/1000\n",
      "1857/1857 [==============================] - 1s 325us/step - loss: 0.5100 - accuracy: 0.8174 - val_loss: 0.5859 - val_accuracy: 0.8562\n",
      "Epoch 9/1000\n",
      "1857/1857 [==============================] - 1s 324us/step - loss: 0.4982 - accuracy: 0.8261 - val_loss: 0.6180 - val_accuracy: 0.8401\n",
      "Epoch 10/1000\n",
      "1857/1857 [==============================] - 1s 325us/step - loss: 0.4858 - accuracy: 0.8228 - val_loss: 0.6082 - val_accuracy: 0.8336\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 2s 1ms/step - loss: 1.0739 - accuracy: 0.6575 - val_loss: 0.7453 - val_accuracy: 0.8417\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 1s 325us/step - loss: 0.6434 - accuracy: 0.8072 - val_loss: 0.6027 - val_accuracy: 0.8417\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 1s 330us/step - loss: 0.5577 - accuracy: 0.8174 - val_loss: 0.6149 - val_accuracy: 0.8417\n",
      "Epoch 4/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1857/1857 [==============================] - 1s 326us/step - loss: 0.5402 - accuracy: 0.8180 - val_loss: 0.6156 - val_accuracy: 0.8417\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 1s 325us/step - loss: 0.5300 - accuracy: 0.8180 - val_loss: 0.6172 - val_accuracy: 0.8417\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 1s 325us/step - loss: 0.5204 - accuracy: 0.8218 - val_loss: 0.6243 - val_accuracy: 0.8417\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 1s 325us/step - loss: 0.5041 - accuracy: 0.8288 - val_loss: 0.6379 - val_accuracy: 0.8288\n",
      "auc: 0.7109865754335076\n",
      "kappa: 0.10702149960351026\n",
      "nodes: 128\n",
      "Train on 1854 samples, validate on 618 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 3s 1ms/step - loss: 1.0130 - accuracy: 0.6807 - val_loss: 0.6273 - val_accuracy: 0.8447\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 1s 403us/step - loss: 0.5915 - accuracy: 0.8155 - val_loss: 0.6136 - val_accuracy: 0.8447\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 1s 367us/step - loss: 0.5592 - accuracy: 0.8085 - val_loss: 0.6148 - val_accuracy: 0.8447\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 1s 375us/step - loss: 0.5285 - accuracy: 0.8215 - val_loss: 0.6472 - val_accuracy: 0.8447\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 1s 381us/step - loss: 0.5201 - accuracy: 0.8252 - val_loss: 0.6243 - val_accuracy: 0.8447\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 1s 370us/step - loss: 0.5097 - accuracy: 0.8339 - val_loss: 0.6251 - val_accuracy: 0.8414\n",
      "Epoch 7/1000\n",
      "1854/1854 [==============================] - 1s 363us/step - loss: 0.5058 - accuracy: 0.8225 - val_loss: 0.6359 - val_accuracy: 0.8398\n",
      "Train on 1854 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 2s 1ms/step - loss: 1.0126 - accuracy: 0.6899 - val_loss: 0.6512 - val_accuracy: 0.8465\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 1s 368us/step - loss: 0.5886 - accuracy: 0.8161 - val_loss: 0.6281 - val_accuracy: 0.8465\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 1s 364us/step - loss: 0.5511 - accuracy: 0.8198 - val_loss: 0.6147 - val_accuracy: 0.8465\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 1s 367us/step - loss: 0.5457 - accuracy: 0.8139 - val_loss: 0.6252 - val_accuracy: 0.8465\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 1s 365us/step - loss: 0.5151 - accuracy: 0.8263 - val_loss: 0.5981 - val_accuracy: 0.8465\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 1s 366us/step - loss: 0.5221 - accuracy: 0.8150 - val_loss: 0.6192 - val_accuracy: 0.8465\n",
      "Epoch 7/1000\n",
      "1854/1854 [==============================] - 1s 367us/step - loss: 0.5062 - accuracy: 0.8279 - val_loss: 0.6182 - val_accuracy: 0.8449\n",
      "Epoch 8/1000\n",
      "1854/1854 [==============================] - 1s 368us/step - loss: 0.4953 - accuracy: 0.8285 - val_loss: 0.6172 - val_accuracy: 0.8384\n",
      "Epoch 9/1000\n",
      "1854/1854 [==============================] - 1s 363us/step - loss: 0.4835 - accuracy: 0.8231 - val_loss: 0.6488 - val_accuracy: 0.8417\n",
      "Epoch 10/1000\n",
      "1854/1854 [==============================] - 1s 366us/step - loss: 0.4663 - accuracy: 0.8452 - val_loss: 0.6886 - val_accuracy: 0.8094\n",
      "Train on 1856 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1856/1856 [==============================] - 2s 1ms/step - loss: 0.9946 - accuracy: 0.7004 - val_loss: 0.6156 - val_accuracy: 0.8465\n",
      "Epoch 2/1000\n",
      "1856/1856 [==============================] - 1s 362us/step - loss: 0.5868 - accuracy: 0.8130 - val_loss: 0.6213 - val_accuracy: 0.8465\n",
      "Epoch 3/1000\n",
      "1856/1856 [==============================] - 1s 365us/step - loss: 0.5409 - accuracy: 0.8211 - val_loss: 0.6300 - val_accuracy: 0.8465\n",
      "Epoch 4/1000\n",
      "1856/1856 [==============================] - 1s 365us/step - loss: 0.5339 - accuracy: 0.8200 - val_loss: 0.6140 - val_accuracy: 0.8465\n",
      "Epoch 5/1000\n",
      "1856/1856 [==============================] - 1s 364us/step - loss: 0.5279 - accuracy: 0.8141 - val_loss: 0.6062 - val_accuracy: 0.8465\n",
      "Epoch 6/1000\n",
      "1856/1856 [==============================] - 1s 366us/step - loss: 0.5017 - accuracy: 0.8244 - val_loss: 0.6215 - val_accuracy: 0.8465\n",
      "Epoch 7/1000\n",
      "1856/1856 [==============================] - 1s 366us/step - loss: 0.4953 - accuracy: 0.8244 - val_loss: 0.6914 - val_accuracy: 0.8465\n",
      "Epoch 8/1000\n",
      "1856/1856 [==============================] - 1s 364us/step - loss: 0.4917 - accuracy: 0.8362 - val_loss: 0.6348 - val_accuracy: 0.8401\n",
      "Epoch 9/1000\n",
      "1856/1856 [==============================] - 1s 364us/step - loss: 0.4839 - accuracy: 0.8265 - val_loss: 0.6764 - val_accuracy: 0.8126\n",
      "Epoch 10/1000\n",
      "1856/1856 [==============================] - 1s 366us/step - loss: 0.4764 - accuracy: 0.8335 - val_loss: 0.7116 - val_accuracy: 0.7900\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 2s 1ms/step - loss: 1.0250 - accuracy: 0.6694 - val_loss: 0.6546 - val_accuracy: 0.8401\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 1s 378us/step - loss: 0.5992 - accuracy: 0.8115 - val_loss: 0.6651 - val_accuracy: 0.8401\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 1s 379us/step - loss: 0.5388 - accuracy: 0.8174 - val_loss: 0.6718 - val_accuracy: 0.8401\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 1s 374us/step - loss: 0.5261 - accuracy: 0.8180 - val_loss: 0.6576 - val_accuracy: 0.8401\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 1s 379us/step - loss: 0.5128 - accuracy: 0.8212 - val_loss: 0.6525 - val_accuracy: 0.8401\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 1s 372us/step - loss: 0.4979 - accuracy: 0.8298 - val_loss: 0.6502 - val_accuracy: 0.8433\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 1s 383us/step - loss: 0.4924 - accuracy: 0.8239 - val_loss: 0.6667 - val_accuracy: 0.8352\n",
      "Epoch 8/1000\n",
      "1857/1857 [==============================] - 1s 380us/step - loss: 0.4853 - accuracy: 0.8358 - val_loss: 0.6619 - val_accuracy: 0.8255\n",
      "Epoch 9/1000\n",
      "1857/1857 [==============================] - 1s 374us/step - loss: 0.4747 - accuracy: 0.8336 - val_loss: 0.6960 - val_accuracy: 0.8271\n",
      "Epoch 10/1000\n",
      "1857/1857 [==============================] - 1s 381us/step - loss: 0.4673 - accuracy: 0.8379 - val_loss: 0.7543 - val_accuracy: 0.7948\n",
      "Epoch 11/1000\n",
      "1857/1857 [==============================] - 1s 379us/step - loss: 0.4400 - accuracy: 0.8433 - val_loss: 0.7896 - val_accuracy: 0.7900\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 2s 1ms/step - loss: 1.0168 - accuracy: 0.6624 - val_loss: 0.6562 - val_accuracy: 0.8401\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 1s 374us/step - loss: 0.5831 - accuracy: 0.8121 - val_loss: 0.6363 - val_accuracy: 0.8401\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 1s 371us/step - loss: 0.5460 - accuracy: 0.8148 - val_loss: 0.6196 - val_accuracy: 0.8401\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 1s 377us/step - loss: 0.5269 - accuracy: 0.8142 - val_loss: 0.6213 - val_accuracy: 0.8401\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 1s 376us/step - loss: 0.5196 - accuracy: 0.8244 - val_loss: 0.6164 - val_accuracy: 0.8401\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 1s 373us/step - loss: 0.5144 - accuracy: 0.8201 - val_loss: 0.6367 - val_accuracy: 0.8401\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 1s 376us/step - loss: 0.4933 - accuracy: 0.8250 - val_loss: 0.6533 - val_accuracy: 0.8384\n",
      "Epoch 8/1000\n",
      "1857/1857 [==============================] - 1s 380us/step - loss: 0.5004 - accuracy: 0.8223 - val_loss: 0.6617 - val_accuracy: 0.8158\n",
      "Epoch 9/1000\n",
      "1857/1857 [==============================] - 1s 373us/step - loss: 0.4844 - accuracy: 0.8320 - val_loss: 0.6865 - val_accuracy: 0.8094\n",
      "Epoch 10/1000\n",
      "1857/1857 [==============================] - 1s 377us/step - loss: 0.4797 - accuracy: 0.8390 - val_loss: 0.7393 - val_accuracy: 0.7803\n",
      "auc: 0.7202697572486418\n",
      "kappa: 0.10444409551026021\n",
      "nodes: 256\n",
      "Train on 1854 samples, validate on 618 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 3s 2ms/step - loss: 0.9346 - accuracy: 0.7066 - val_loss: 0.6233 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 1s 549us/step - loss: 0.5610 - accuracy: 0.8172 - val_loss: 0.6472 - val_accuracy: 0.8333\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 1s 549us/step - loss: 0.5308 - accuracy: 0.8188 - val_loss: 0.6479 - val_accuracy: 0.8333\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 1s 541us/step - loss: 0.5292 - accuracy: 0.8274 - val_loss: 0.6270 - val_accuracy: 0.8333\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 1s 548us/step - loss: 0.5048 - accuracy: 0.8285 - val_loss: 0.6434 - val_accuracy: 0.8333\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 1s 544us/step - loss: 0.4952 - accuracy: 0.8430 - val_loss: 0.6272 - val_accuracy: 0.8333\n",
      "Train on 1854 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 3s 2ms/step - loss: 0.9434 - accuracy: 0.7136 - val_loss: 0.5765 - val_accuracy: 0.8546\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 1s 552us/step - loss: 0.5632 - accuracy: 0.8134 - val_loss: 0.6102 - val_accuracy: 0.8546\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 1s 556us/step - loss: 0.5482 - accuracy: 0.8128 - val_loss: 0.6124 - val_accuracy: 0.8546\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 1s 552us/step - loss: 0.5212 - accuracy: 0.8193 - val_loss: 0.6091 - val_accuracy: 0.8546\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 1s 555us/step - loss: 0.5192 - accuracy: 0.8134 - val_loss: 0.5948 - val_accuracy: 0.8546\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 1s 551us/step - loss: 0.5076 - accuracy: 0.8177 - val_loss: 0.6222 - val_accuracy: 0.8530\n",
      "Train on 1856 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1856/1856 [==============================] - 3s 2ms/step - loss: 0.9527 - accuracy: 0.7047 - val_loss: 0.6091 - val_accuracy: 0.8401\n",
      "Epoch 2/1000\n",
      "1856/1856 [==============================] - 1s 560us/step - loss: 0.5789 - accuracy: 0.8184 - val_loss: 0.6343 - val_accuracy: 0.8401\n",
      "Epoch 3/1000\n",
      "1856/1856 [==============================] - 1s 556us/step - loss: 0.5443 - accuracy: 0.8200 - val_loss: 0.6298 - val_accuracy: 0.8401\n",
      "Epoch 4/1000\n",
      "1856/1856 [==============================] - 1s 559us/step - loss: 0.5268 - accuracy: 0.8195 - val_loss: 0.6371 - val_accuracy: 0.8401\n",
      "Epoch 5/1000\n",
      "1856/1856 [==============================] - 1s 560us/step - loss: 0.5102 - accuracy: 0.8244 - val_loss: 0.6188 - val_accuracy: 0.8401\n",
      "Epoch 6/1000\n",
      "1856/1856 [==============================] - 1s 562us/step - loss: 0.5009 - accuracy: 0.8330 - val_loss: 0.6185 - val_accuracy: 0.8384\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 3s 2ms/step - loss: 0.9414 - accuracy: 0.7065 - val_loss: 0.6056 - val_accuracy: 0.8433\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 1s 565us/step - loss: 0.5693 - accuracy: 0.8126 - val_loss: 0.6203 - val_accuracy: 0.8433\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 1s 555us/step - loss: 0.5469 - accuracy: 0.8164 - val_loss: 0.6371 - val_accuracy: 0.8433\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 1s 557us/step - loss: 0.5269 - accuracy: 0.8191 - val_loss: 0.6279 - val_accuracy: 0.8433\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 1s 555us/step - loss: 0.5257 - accuracy: 0.8201 - val_loss: 0.6412 - val_accuracy: 0.8433\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 1s 554us/step - loss: 0.5028 - accuracy: 0.8271 - val_loss: 0.6729 - val_accuracy: 0.8433\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 3s 2ms/step - loss: 0.9559 - accuracy: 0.7027 - val_loss: 0.5992 - val_accuracy: 0.8465\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 1s 561us/step - loss: 0.5739 - accuracy: 0.8094 - val_loss: 0.6206 - val_accuracy: 0.8465\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 1s 565us/step - loss: 0.5554 - accuracy: 0.8099 - val_loss: 0.5978 - val_accuracy: 0.8465\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 1s 562us/step - loss: 0.5321 - accuracy: 0.8180 - val_loss: 0.5926 - val_accuracy: 0.8465\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 1s 566us/step - loss: 0.5265 - accuracy: 0.8223 - val_loss: 0.5951 - val_accuracy: 0.8465\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 1s 568us/step - loss: 0.5073 - accuracy: 0.8212 - val_loss: 0.6213 - val_accuracy: 0.8465\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 1s 572us/step - loss: 0.4951 - accuracy: 0.8288 - val_loss: 0.6494 - val_accuracy: 0.8433\n",
      "Epoch 8/1000\n",
      "1857/1857 [==============================] - 1s 568us/step - loss: 0.4956 - accuracy: 0.8347 - val_loss: 0.6396 - val_accuracy: 0.8449\n",
      "Epoch 9/1000\n",
      "1857/1857 [==============================] - 1s 562us/step - loss: 0.4822 - accuracy: 0.8282 - val_loss: 0.6649 - val_accuracy: 0.8304\n",
      "auc: 0.6902584474977994\n",
      "kappa: 0.13944950138120035\n",
      "nodes: 512\n",
      "Train on 1854 samples, validate on 618 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 5s 2ms/step - loss: 0.8836 - accuracy: 0.7190 - val_loss: 0.6319 - val_accuracy: 0.8414\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 2s 1ms/step - loss: 0.5589 - accuracy: 0.8074 - val_loss: 0.6722 - val_accuracy: 0.8414\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 2s 1ms/step - loss: 0.5401 - accuracy: 0.8172 - val_loss: 0.6206 - val_accuracy: 0.8414\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 2s 1ms/step - loss: 0.5167 - accuracy: 0.8242 - val_loss: 0.6154 - val_accuracy: 0.8414\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 2s 1ms/step - loss: 0.5182 - accuracy: 0.8215 - val_loss: 0.6102 - val_accuracy: 0.8414\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 2s 1ms/step - loss: 0.4983 - accuracy: 0.8333 - val_loss: 0.6171 - val_accuracy: 0.8414\n",
      "Epoch 7/1000\n",
      "1854/1854 [==============================] - 2s 1ms/step - loss: 0.4878 - accuracy: 0.8225 - val_loss: 0.6501 - val_accuracy: 0.8301\n",
      "Epoch 8/1000\n",
      "1854/1854 [==============================] - 2s 1ms/step - loss: 0.4791 - accuracy: 0.8333 - val_loss: 0.6970 - val_accuracy: 0.8398\n",
      "Epoch 9/1000\n",
      "1854/1854 [==============================] - 2s 1ms/step - loss: 0.4875 - accuracy: 0.8269 - val_loss: 0.6872 - val_accuracy: 0.8350\n",
      "Epoch 10/1000\n",
      "1854/1854 [==============================] - 2s 1ms/step - loss: 0.4687 - accuracy: 0.8285 - val_loss: 0.7232 - val_accuracy: 0.8091\n",
      "Train on 1854 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 4s 2ms/step - loss: 0.8605 - accuracy: 0.7206 - val_loss: 0.6372 - val_accuracy: 0.8401\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 2s 1ms/step - loss: 0.5432 - accuracy: 0.8231 - val_loss: 0.6265 - val_accuracy: 0.8401\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 2s 1ms/step - loss: 0.5303 - accuracy: 0.8231 - val_loss: 0.6106 - val_accuracy: 0.8401\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 2s 1ms/step - loss: 0.5076 - accuracy: 0.8236 - val_loss: 0.6145 - val_accuracy: 0.8401\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 2s 1ms/step - loss: 0.5135 - accuracy: 0.8274 - val_loss: 0.5992 - val_accuracy: 0.8401\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 2s 1ms/step - loss: 0.4859 - accuracy: 0.8258 - val_loss: 0.6310 - val_accuracy: 0.8401\n",
      "Epoch 7/1000\n",
      "1854/1854 [==============================] - 2s 1ms/step - loss: 0.4814 - accuracy: 0.8269 - val_loss: 0.6393 - val_accuracy: 0.8401\n",
      "Epoch 8/1000\n",
      "1854/1854 [==============================] - 2s 1ms/step - loss: 0.4839 - accuracy: 0.8215 - val_loss: 0.6646 - val_accuracy: 0.8336\n",
      "Epoch 9/1000\n",
      "1854/1854 [==============================] - 2s 1ms/step - loss: 0.4586 - accuracy: 0.8279 - val_loss: 0.7787 - val_accuracy: 0.8078\n",
      "Epoch 10/1000\n",
      "1854/1854 [==============================] - 2s 1ms/step - loss: 0.4557 - accuracy: 0.8371 - val_loss: 0.7954 - val_accuracy: 0.8013\n",
      "Train on 1856 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1856/1856 [==============================] - 4s 2ms/step - loss: 0.8975 - accuracy: 0.7306 - val_loss: 0.5966 - val_accuracy: 0.8481\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1856/1856 [==============================] - 2s 1ms/step - loss: 0.5665 - accuracy: 0.8103 - val_loss: 0.6454 - val_accuracy: 0.8481\n",
      "Epoch 3/1000\n",
      "1856/1856 [==============================] - 2s 1ms/step - loss: 0.5546 - accuracy: 0.8147 - val_loss: 0.6314 - val_accuracy: 0.8481\n",
      "Epoch 4/1000\n",
      "1856/1856 [==============================] - 2s 1ms/step - loss: 0.5390 - accuracy: 0.8098 - val_loss: 0.6207 - val_accuracy: 0.8481\n",
      "Epoch 5/1000\n",
      "1856/1856 [==============================] - 2s 1ms/step - loss: 0.5213 - accuracy: 0.8227 - val_loss: 0.6376 - val_accuracy: 0.8481\n",
      "Epoch 6/1000\n",
      "1856/1856 [==============================] - 2s 1ms/step - loss: 0.5164 - accuracy: 0.8254 - val_loss: 0.6077 - val_accuracy: 0.8481\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 4s 2ms/step - loss: 0.8794 - accuracy: 0.7157 - val_loss: 0.5979 - val_accuracy: 0.8465\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 2s 1ms/step - loss: 0.5749 - accuracy: 0.8110 - val_loss: 0.5890 - val_accuracy: 0.8465\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 2s 1ms/step - loss: 0.5520 - accuracy: 0.8110 - val_loss: 0.6113 - val_accuracy: 0.8465\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 2s 1ms/step - loss: 0.5488 - accuracy: 0.8121 - val_loss: 0.5841 - val_accuracy: 0.8465\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 2s 1ms/step - loss: 0.5348 - accuracy: 0.8158 - val_loss: 0.5973 - val_accuracy: 0.8465\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 2s 1ms/step - loss: 0.5255 - accuracy: 0.8261 - val_loss: 0.6002 - val_accuracy: 0.8465\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 2s 1ms/step - loss: 0.5140 - accuracy: 0.8180 - val_loss: 0.6089 - val_accuracy: 0.8465\n",
      "Epoch 8/1000\n",
      "1857/1857 [==============================] - 2s 1ms/step - loss: 0.5002 - accuracy: 0.8228 - val_loss: 0.6478 - val_accuracy: 0.8223\n",
      "Epoch 9/1000\n",
      "1857/1857 [==============================] - 2s 1ms/step - loss: 0.4837 - accuracy: 0.8320 - val_loss: 0.6553 - val_accuracy: 0.8352\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 4s 2ms/step - loss: 0.8923 - accuracy: 0.7151 - val_loss: 0.6182 - val_accuracy: 0.8417\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 2s 1ms/step - loss: 0.5677 - accuracy: 0.8115 - val_loss: 0.6242 - val_accuracy: 0.8417\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 2s 1ms/step - loss: 0.5569 - accuracy: 0.8094 - val_loss: 0.6207 - val_accuracy: 0.8417\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 2s 1ms/step - loss: 0.5348 - accuracy: 0.8174 - val_loss: 0.6224 - val_accuracy: 0.8417\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 2s 1ms/step - loss: 0.5157 - accuracy: 0.8228 - val_loss: 0.6063 - val_accuracy: 0.8417\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 2s 1ms/step - loss: 0.5102 - accuracy: 0.8244 - val_loss: 0.6029 - val_accuracy: 0.8417\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 2s 1ms/step - loss: 0.5041 - accuracy: 0.8212 - val_loss: 0.6282 - val_accuracy: 0.8417\n",
      "Epoch 8/1000\n",
      "1857/1857 [==============================] - 2s 1ms/step - loss: 0.4783 - accuracy: 0.8320 - val_loss: 0.6416 - val_accuracy: 0.8288\n",
      "Epoch 9/1000\n",
      "1857/1857 [==============================] - 2s 1ms/step - loss: 0.4705 - accuracy: 0.8395 - val_loss: 0.6761 - val_accuracy: 0.8174\n",
      "Epoch 10/1000\n",
      "1857/1857 [==============================] - 2s 1ms/step - loss: 0.4703 - accuracy: 0.8309 - val_loss: 0.7056 - val_accuracy: 0.8207\n",
      "Epoch 11/1000\n",
      "1857/1857 [==============================] - 2s 1ms/step - loss: 0.4442 - accuracy: 0.8368 - val_loss: 0.8112 - val_accuracy: 0.7609\n",
      "auc: 0.7308084190447386\n",
      "kappa: 0.11930349100231133\n"
     ]
    }
   ],
   "source": [
    "FOLDS = 5\n",
    "PADDING = 50\n",
    "MAX_POWER = 9\n",
    "\n",
    "# Prepare training batches\n",
    "input_data = pk.load(open('input_data3.pkl', 'rb'))\n",
    "target_data = pk.load(open('target_data3.pkl', 'rb'))\n",
    "model_input = []\n",
    "model_target = []\n",
    "for i, t in zip(input_data, target_data):\n",
    "    model_input.append(np.concatenate([np.zeros((PADDING - 1, i.shape[1])), i])[:PADDING,:])\n",
    "    model_target.append(np.argmax(t))\n",
    "model_input = np.array(model_input)\n",
    "model_target = np.array(model_target)\n",
    "\n",
    "#keys, values = np.unique(model_target, return_counts=True)\n",
    "#values = (1 / values) / max((1 / values))\n",
    "#class_weight = dict(zip(keys, values))\n",
    "class_weight = dict(zip(np.arange(target_data[0].size), np.ones((target_data[0].size,))))\n",
    "\n",
    "skf = StratifiedKFold(n_splits=FOLDS, shuffle=True)\n",
    "mms = MinMaxScaler()\n",
    "\n",
    "dimention = []\n",
    "auc = []\n",
    "kappa = []\n",
    "for dim in np.power(2, np.arange(MAX_POWER+1)):\n",
    "    print(f'nodes: {dim}')\n",
    "    aucs = []\n",
    "    kappas = []\n",
    "    \n",
    "    # Prepare k-fold training and test sets\n",
    "    for train_index, test_index in skf.split(model_input, model_target):\n",
    "        model_target[train_index.astype(int)]\n",
    "        X_train_raw, X_test_raw = model_input[train_index], model_input[test_index]\n",
    "        y_train_raw, y_test_raw = model_target[train_index], model_target[test_index]\n",
    "\n",
    "        X_train = np.stack(X_train_raw)\n",
    "        X_test = np.stack(X_test_raw)\n",
    "\n",
    "        y_train = np.zeros((y_train_raw.size, y_train_raw.max() + 1))\n",
    "        y_train[np.arange(y_train_raw.size),y_train_raw] = 1\n",
    "        y_test = np.zeros((y_test_raw.size, y_test_raw.max() + 1))\n",
    "        y_test[np.arange(y_test_raw.size),y_test_raw] = 1\n",
    "\n",
    "        # Make the resnet\n",
    "        x, y = build_resnet(X_train.shape[1:], dim, target_data[0].size)\n",
    "        model = Model(inputs=x, outputs=y)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        #print(model.summary())\n",
    "        es = EarlyStopping(monitor='val_loss', patience=5, min_delta=0, restore_best_weights=True) \n",
    "        model.fit(X_train, y_train, class_weight=class_weight, epochs=1000, validation_split=0.25, callbacks=[es])\n",
    "\n",
    "        # Get the average auc and kappa for all affects and folds\n",
    "        y_pred = model.predict(X_test, batch_size=1)\n",
    "        for y_t, y_p in zip(y_test.T, y_pred.T):\n",
    "            y_p = mms.fit_transform(y_p.reshape(-1, 1))\n",
    "            aucs.append(roc_auc_score(y_t, y_p))\n",
    "            kappas.append(cohen_kappa_score(y_t, np.around(y_p)))\n",
    "\n",
    "    dimention.append(dim)\n",
    "    auc.append(np.mean(aucs))\n",
    "    kappa.append(np.mean(kappas))\n",
    "    print(f'auc: {auc[-1]}')\n",
    "    print(f'kappa: {kappa[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(dimention[:MAX_POWER+1], auc[:MAX_POWER+1], marker='.')\n",
    "plt.xlabel('Nodes')\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.title('1d ResNet')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(dimention[:MAX_POWER+1], kappa[:MAX_POWER+1], marker='.')\n",
    "plt.xlabel('Nodes')\n",
    "plt.ylabel('Cohen\\'s Kappa')\n",
    "plt.title('1d ResNet')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
