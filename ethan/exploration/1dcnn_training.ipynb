{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SeparableConv1D, Conv1D,Dropout, MaxPooling1D, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import cohen_kappa_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers: 1, nodes: 1\n",
      "Train on 1854 samples, validate on 618 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 1s 491us/step - loss: 1.5102 - accuracy: 0.0329 - val_loss: 1.3690 - val_accuracy: 0.0566\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 0s 185us/step - loss: 1.3241 - accuracy: 0.7379 - val_loss: 1.2780 - val_accuracy: 0.8447\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 0s 186us/step - loss: 1.2522 - accuracy: 0.8193 - val_loss: 1.2137 - val_accuracy: 0.8447\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 0s 183us/step - loss: 1.1944 - accuracy: 0.8193 - val_loss: 1.1561 - val_accuracy: 0.8447\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 0s 185us/step - loss: 1.1424 - accuracy: 0.8193 - val_loss: 1.1045 - val_accuracy: 0.8447\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 0s 187us/step - loss: 1.0951 - accuracy: 0.8193 - val_loss: 1.0568 - val_accuracy: 0.8447\n",
      "Epoch 7/1000\n",
      "1854/1854 [==============================] - 0s 184us/step - loss: 1.0515 - accuracy: 0.8193 - val_loss: 1.0131 - val_accuracy: 0.8447\n",
      "Epoch 8/1000\n",
      "1854/1854 [==============================] - 0s 192us/step - loss: 1.0116 - accuracy: 0.8193 - val_loss: 0.9728 - val_accuracy: 0.8447\n",
      "Epoch 9/1000\n",
      "1854/1854 [==============================] - 0s 196us/step - loss: 0.9751 - accuracy: 0.8193 - val_loss: 0.9357 - val_accuracy: 0.8447\n",
      "Epoch 10/1000\n",
      "1854/1854 [==============================] - 0s 188us/step - loss: 0.9418 - accuracy: 0.8193 - val_loss: 0.9022 - val_accuracy: 0.8447\n",
      "Epoch 11/1000\n",
      "1854/1854 [==============================] - 0s 185us/step - loss: 0.9116 - accuracy: 0.8193 - val_loss: 0.8714 - val_accuracy: 0.8447\n",
      "Epoch 12/1000\n",
      "1854/1854 [==============================] - 0s 194us/step - loss: 0.8841 - accuracy: 0.8193 - val_loss: 0.8436 - val_accuracy: 0.8447\n",
      "Epoch 13/1000\n",
      "1854/1854 [==============================] - 0s 188us/step - loss: 0.8592 - accuracy: 0.8193 - val_loss: 0.8185 - val_accuracy: 0.8447\n",
      "Epoch 14/1000\n",
      "1854/1854 [==============================] - 0s 187us/step - loss: 0.8369 - accuracy: 0.8193 - val_loss: 0.7956 - val_accuracy: 0.8447\n",
      "Epoch 15/1000\n",
      "1854/1854 [==============================] - 0s 187us/step - loss: 0.8167 - accuracy: 0.8193 - val_loss: 0.7750 - val_accuracy: 0.8447\n",
      "Epoch 16/1000\n",
      "1854/1854 [==============================] - 0s 196us/step - loss: 0.7985 - accuracy: 0.8193 - val_loss: 0.7570 - val_accuracy: 0.8447\n",
      "Epoch 17/1000\n",
      "1854/1854 [==============================] - 0s 209us/step - loss: 0.7823 - accuracy: 0.8193 - val_loss: 0.7400 - val_accuracy: 0.8447\n",
      "Epoch 18/1000\n",
      "1854/1854 [==============================] - 0s 197us/step - loss: 0.7677 - accuracy: 0.8193 - val_loss: 0.7250 - val_accuracy: 0.8447\n",
      "Epoch 19/1000\n",
      "1854/1854 [==============================] - 0s 209us/step - loss: 0.7546 - accuracy: 0.8193 - val_loss: 0.7117 - val_accuracy: 0.8447\n",
      "Epoch 20/1000\n",
      "1854/1854 [==============================] - ETA: 0s - loss: 0.7416 - accuracy: 0.82 - 0s 188us/step - loss: 0.7429 - accuracy: 0.8193 - val_loss: 0.7000 - val_accuracy: 0.8447\n",
      "Epoch 21/1000\n",
      "1854/1854 [==============================] - 0s 194us/step - loss: 0.7324 - accuracy: 0.8193 - val_loss: 0.6893 - val_accuracy: 0.8447\n",
      "Epoch 22/1000\n",
      "1854/1854 [==============================] - 0s 197us/step - loss: 0.7230 - accuracy: 0.8193 - val_loss: 0.6797 - val_accuracy: 0.8447\n",
      "Epoch 23/1000\n",
      "1854/1854 [==============================] - 0s 197us/step - loss: 0.7147 - accuracy: 0.8193 - val_loss: 0.6709 - val_accuracy: 0.8447\n",
      "Epoch 24/1000\n",
      "1854/1854 [==============================] - 0s 196us/step - loss: 0.7071 - accuracy: 0.8193 - val_loss: 0.6634 - val_accuracy: 0.8447\n",
      "Epoch 25/1000\n",
      "1854/1854 [==============================] - 0s 194us/step - loss: 0.7005 - accuracy: 0.8193 - val_loss: 0.6567 - val_accuracy: 0.8447\n",
      "Epoch 26/1000\n",
      "1854/1854 [==============================] - 0s 186us/step - loss: 0.6944 - accuracy: 0.8193 - val_loss: 0.6506 - val_accuracy: 0.8447\n",
      "Epoch 27/1000\n",
      "1854/1854 [==============================] - 0s 187us/step - loss: 0.6891 - accuracy: 0.8193 - val_loss: 0.6453 - val_accuracy: 0.8447\n",
      "Epoch 28/1000\n",
      "1854/1854 [==============================] - 0s 187us/step - loss: 0.6843 - accuracy: 0.8193 - val_loss: 0.6406 - val_accuracy: 0.8447\n",
      "Epoch 29/1000\n",
      "1854/1854 [==============================] - 0s 189us/step - loss: 0.6801 - accuracy: 0.8193 - val_loss: 0.6360 - val_accuracy: 0.8447\n",
      "Epoch 30/1000\n",
      "1854/1854 [==============================] - 0s 186us/step - loss: 0.6762 - accuracy: 0.8193 - val_loss: 0.6324 - val_accuracy: 0.8447\n",
      "Epoch 31/1000\n",
      "1854/1854 [==============================] - 0s 186us/step - loss: 0.6727 - accuracy: 0.8193 - val_loss: 0.6292 - val_accuracy: 0.8447\n",
      "Epoch 32/1000\n",
      "1854/1854 [==============================] - 0s 199us/step - loss: 0.6697 - accuracy: 0.8193 - val_loss: 0.6260 - val_accuracy: 0.8447\n",
      "Epoch 33/1000\n",
      "1854/1854 [==============================] - 0s 193us/step - loss: 0.6669 - accuracy: 0.8193 - val_loss: 0.6235 - val_accuracy: 0.8447\n",
      "Epoch 34/1000\n",
      "1854/1854 [==============================] - 0s 201us/step - loss: 0.6644 - accuracy: 0.8193 - val_loss: 0.6212 - val_accuracy: 0.8447\n",
      "Epoch 35/1000\n",
      "1854/1854 [==============================] - 0s 188us/step - loss: 0.6622 - accuracy: 0.8193 - val_loss: 0.6192 - val_accuracy: 0.8447\n",
      "Epoch 36/1000\n",
      "1854/1854 [==============================] - 0s 193us/step - loss: 0.6602 - accuracy: 0.8193 - val_loss: 0.6173 - val_accuracy: 0.8447\n",
      "Epoch 37/1000\n",
      "1854/1854 [==============================] - 0s 195us/step - loss: 0.6584 - accuracy: 0.8193 - val_loss: 0.6158 - val_accuracy: 0.8447\n",
      "Epoch 38/1000\n",
      "1854/1854 [==============================] - 0s 200us/step - loss: 0.6568 - accuracy: 0.8193 - val_loss: 0.6143 - val_accuracy: 0.8447\n",
      "Epoch 39/1000\n",
      "1854/1854 [==============================] - 0s 200us/step - loss: 0.6553 - accuracy: 0.8193 - val_loss: 0.6133 - val_accuracy: 0.8447\n",
      "Epoch 40/1000\n",
      "1854/1854 [==============================] - 0s 197us/step - loss: 0.6540 - accuracy: 0.8193 - val_loss: 0.6120 - val_accuracy: 0.8447\n",
      "Epoch 41/1000\n",
      "1854/1854 [==============================] - 0s 196us/step - loss: 0.6528 - accuracy: 0.8193 - val_loss: 0.6113 - val_accuracy: 0.8447\n",
      "Epoch 42/1000\n",
      "1854/1854 [==============================] - 0s 195us/step - loss: 0.6517 - accuracy: 0.8193 - val_loss: 0.6105 - val_accuracy: 0.8447\n",
      "Epoch 43/1000\n",
      "1854/1854 [==============================] - 0s 192us/step - loss: 0.6508 - accuracy: 0.8193 - val_loss: 0.6098 - val_accuracy: 0.8447\n",
      "Epoch 44/1000\n",
      "1854/1854 [==============================] - 0s 210us/step - loss: 0.6499 - accuracy: 0.8193 - val_loss: 0.6093 - val_accuracy: 0.8447\n",
      "Epoch 45/1000\n",
      "1854/1854 [==============================] - 0s 190us/step - loss: 0.6491 - accuracy: 0.8193 - val_loss: 0.6086 - val_accuracy: 0.8447\n",
      "Epoch 46/1000\n",
      "1854/1854 [==============================] - 0s 189us/step - loss: 0.6484 - accuracy: 0.8193 - val_loss: 0.6085 - val_accuracy: 0.8447\n",
      "Epoch 47/1000\n",
      "1854/1854 [==============================] - 0s 185us/step - loss: 0.6478 - accuracy: 0.8193 - val_loss: 0.6080 - val_accuracy: 0.8447\n",
      "Epoch 48/1000\n",
      "1854/1854 [==============================] - 0s 190us/step - loss: 0.6472 - accuracy: 0.8193 - val_loss: 0.6078 - val_accuracy: 0.8447\n",
      "Epoch 49/1000\n",
      "1854/1854 [==============================] - 0s 188us/step - loss: 0.6467 - accuracy: 0.8193 - val_loss: 0.6075 - val_accuracy: 0.8447\n",
      "Epoch 50/1000\n",
      "1854/1854 [==============================] - 0s 193us/step - loss: 0.6462 - accuracy: 0.8193 - val_loss: 0.6075 - val_accuracy: 0.8447\n",
      "Epoch 51/1000\n",
      "1854/1854 [==============================] - 0s 193us/step - loss: 0.6458 - accuracy: 0.8193 - val_loss: 0.6074 - val_accuracy: 0.8447\n",
      "Epoch 52/1000\n",
      "1854/1854 [==============================] - 0s 200us/step - loss: 0.6455 - accuracy: 0.8193 - val_loss: 0.6072 - val_accuracy: 0.8447\n",
      "Epoch 53/1000\n",
      "1854/1854 [==============================] - 0s 193us/step - loss: 0.6451 - accuracy: 0.8193 - val_loss: 0.6072 - val_accuracy: 0.8447\n",
      "Epoch 54/1000\n",
      "1854/1854 [==============================] - 0s 194us/step - loss: 0.6448 - accuracy: 0.8193 - val_loss: 0.6073 - val_accuracy: 0.8447\n",
      "Epoch 55/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1854/1854 [==============================] - 0s 194us/step - loss: 0.6445 - accuracy: 0.8193 - val_loss: 0.6074 - val_accuracy: 0.8447\n",
      "Train on 1854 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 1s 485us/step - loss: 1.2929 - accuracy: 0.1127 - val_loss: 1.2327 - val_accuracy: 0.0598\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 0s 187us/step - loss: 1.1708 - accuracy: 0.7039 - val_loss: 1.1101 - val_accuracy: 0.8611\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 0s 192us/step - loss: 1.0689 - accuracy: 0.8134 - val_loss: 1.0089 - val_accuracy: 0.8611\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 0s 201us/step - loss: 0.9849 - accuracy: 0.8134 - val_loss: 0.9232 - val_accuracy: 0.8611\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 0s 189us/step - loss: 0.9159 - accuracy: 0.8134 - val_loss: 0.8532 - val_accuracy: 0.8611\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 0s 186us/step - loss: 0.8604 - accuracy: 0.8134 - val_loss: 0.7955 - val_accuracy: 0.8611\n",
      "Epoch 7/1000\n",
      "1854/1854 [==============================] - 0s 188us/step - loss: 0.8160 - accuracy: 0.8134 - val_loss: 0.7497 - val_accuracy: 0.8611\n",
      "Epoch 8/1000\n",
      "1854/1854 [==============================] - 0s 196us/step - loss: 0.7810 - accuracy: 0.8134 - val_loss: 0.7124 - val_accuracy: 0.8611\n",
      "Epoch 9/1000\n",
      "1854/1854 [==============================] - 0s 189us/step - loss: 0.7535 - accuracy: 0.8134 - val_loss: 0.6828 - val_accuracy: 0.8611\n",
      "Epoch 10/1000\n",
      "1854/1854 [==============================] - 0s 193us/step - loss: 0.7320 - accuracy: 0.8134 - val_loss: 0.6590 - val_accuracy: 0.8611\n",
      "Epoch 11/1000\n",
      "1854/1854 [==============================] - 0s 190us/step - loss: 0.7153 - accuracy: 0.8134 - val_loss: 0.6408 - val_accuracy: 0.8611\n",
      "Epoch 12/1000\n",
      "1854/1854 [==============================] - 0s 186us/step - loss: 0.7023 - accuracy: 0.8134 - val_loss: 0.6258 - val_accuracy: 0.8611\n",
      "Epoch 13/1000\n",
      "1854/1854 [==============================] - 0s 190us/step - loss: 0.6923 - accuracy: 0.8134 - val_loss: 0.6138 - val_accuracy: 0.8611\n",
      "Epoch 14/1000\n",
      "1854/1854 [==============================] - 0s 191us/step - loss: 0.6846 - accuracy: 0.8134 - val_loss: 0.6040 - val_accuracy: 0.8611\n",
      "Epoch 15/1000\n",
      "1854/1854 [==============================] - 0s 186us/step - loss: 0.6787 - accuracy: 0.8134 - val_loss: 0.5968 - val_accuracy: 0.8611\n",
      "Epoch 16/1000\n",
      "1854/1854 [==============================] - 0s 193us/step - loss: 0.6741 - accuracy: 0.8134 - val_loss: 0.5904 - val_accuracy: 0.8611\n",
      "Epoch 17/1000\n",
      "1854/1854 [==============================] - 0s 193us/step - loss: 0.6705 - accuracy: 0.8134 - val_loss: 0.5860 - val_accuracy: 0.8611\n",
      "Epoch 18/1000\n",
      "1854/1854 [==============================] - 0s 186us/step - loss: 0.6678 - accuracy: 0.8134 - val_loss: 0.5824 - val_accuracy: 0.8611\n",
      "Epoch 19/1000\n",
      "1854/1854 [==============================] - 0s 183us/step - loss: 0.6657 - accuracy: 0.8134 - val_loss: 0.5791 - val_accuracy: 0.8611\n",
      "Epoch 20/1000\n",
      "1854/1854 [==============================] - 0s 187us/step - loss: 0.6640 - accuracy: 0.8134 - val_loss: 0.5772 - val_accuracy: 0.8611\n",
      "Epoch 21/1000\n",
      "1854/1854 [==============================] - 0s 183us/step - loss: 0.6627 - accuracy: 0.8134 - val_loss: 0.5752 - val_accuracy: 0.8611\n",
      "Epoch 22/1000\n",
      "1854/1854 [==============================] - 0s 185us/step - loss: 0.6617 - accuracy: 0.8134 - val_loss: 0.5738 - val_accuracy: 0.8611\n",
      "Epoch 23/1000\n",
      "1854/1854 [==============================] - 0s 190us/step - loss: 0.6609 - accuracy: 0.8134 - val_loss: 0.5728 - val_accuracy: 0.8611\n",
      "Epoch 24/1000\n",
      "1854/1854 [==============================] - 0s 187us/step - loss: 0.6602 - accuracy: 0.8134 - val_loss: 0.5721 - val_accuracy: 0.8611\n",
      "Epoch 25/1000\n",
      "1854/1854 [==============================] - 0s 187us/step - loss: 0.6597 - accuracy: 0.8134 - val_loss: 0.5716 - val_accuracy: 0.8611\n",
      "Epoch 26/1000\n",
      "1854/1854 [==============================] - 0s 186us/step - loss: 0.6593 - accuracy: 0.8134 - val_loss: 0.5712 - val_accuracy: 0.8611\n",
      "Epoch 27/1000\n",
      "1854/1854 [==============================] - 0s 186us/step - loss: 0.6590 - accuracy: 0.8134 - val_loss: 0.5706 - val_accuracy: 0.8611\n",
      "Epoch 28/1000\n",
      "1854/1854 [==============================] - 0s 187us/step - loss: 0.6588 - accuracy: 0.8134 - val_loss: 0.5705 - val_accuracy: 0.8611\n",
      "Epoch 29/1000\n",
      "1854/1854 [==============================] - 0s 188us/step - loss: 0.6586 - accuracy: 0.8134 - val_loss: 0.5699 - val_accuracy: 0.8611\n",
      "Epoch 30/1000\n",
      "1854/1854 [==============================] - 0s 184us/step - loss: 0.6583 - accuracy: 0.8134 - val_loss: 0.5702 - val_accuracy: 0.8611\n",
      "Epoch 31/1000\n",
      "1854/1854 [==============================] - 0s 186us/step - loss: 0.6582 - accuracy: 0.8134 - val_loss: 0.5706 - val_accuracy: 0.8611\n",
      "Epoch 32/1000\n",
      "1854/1854 [==============================] - 0s 186us/step - loss: 0.6581 - accuracy: 0.8134 - val_loss: 0.5706 - val_accuracy: 0.8611\n",
      "Train on 1856 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1856/1856 [==============================] - 1s 465us/step - loss: 1.4498 - accuracy: 0.0388 - val_loss: 1.3501 - val_accuracy: 0.0291\n",
      "Epoch 2/1000\n",
      "1856/1856 [==============================] - 0s 185us/step - loss: 1.3102 - accuracy: 0.7839 - val_loss: 1.2700 - val_accuracy: 0.8433\n",
      "Epoch 3/1000\n",
      "1856/1856 [==============================] - 0s 189us/step - loss: 1.2444 - accuracy: 0.8190 - val_loss: 1.2074 - val_accuracy: 0.8433\n",
      "Epoch 4/1000\n",
      "1856/1856 [==============================] - ETA: 0s - loss: 1.1926 - accuracy: 0.82 - 0s 184us/step - loss: 1.1884 - accuracy: 0.8190 - val_loss: 1.1523 - val_accuracy: 0.8433\n",
      "Epoch 5/1000\n",
      "1856/1856 [==============================] - 0s 189us/step - loss: 1.1375 - accuracy: 0.8190 - val_loss: 1.1012 - val_accuracy: 0.8433\n",
      "Epoch 6/1000\n",
      "1856/1856 [==============================] - 0s 189us/step - loss: 1.0906 - accuracy: 0.8190 - val_loss: 1.0546 - val_accuracy: 0.8433\n",
      "Epoch 7/1000\n",
      "1856/1856 [==============================] - 0s 183us/step - loss: 1.0477 - accuracy: 0.8190 - val_loss: 1.0111 - val_accuracy: 0.8433\n",
      "Epoch 8/1000\n",
      "1856/1856 [==============================] - 0s 188us/step - loss: 1.0081 - accuracy: 0.8190 - val_loss: 0.9713 - val_accuracy: 0.8433\n",
      "Epoch 9/1000\n",
      "1856/1856 [==============================] - 0s 186us/step - loss: 0.9721 - accuracy: 0.8190 - val_loss: 0.9347 - val_accuracy: 0.8433\n",
      "Epoch 10/1000\n",
      "1856/1856 [==============================] - 0s 183us/step - loss: 0.9391 - accuracy: 0.8190 - val_loss: 0.9017 - val_accuracy: 0.8433\n",
      "Epoch 11/1000\n",
      "1856/1856 [==============================] - 0s 193us/step - loss: 0.9091 - accuracy: 0.8190 - val_loss: 0.8716 - val_accuracy: 0.8433\n",
      "Epoch 12/1000\n",
      "1856/1856 [==============================] - 0s 188us/step - loss: 0.8820 - accuracy: 0.8190 - val_loss: 0.8439 - val_accuracy: 0.8433\n",
      "Epoch 13/1000\n",
      "1856/1856 [==============================] - 0s 186us/step - loss: 0.8574 - accuracy: 0.8190 - val_loss: 0.8195 - val_accuracy: 0.8433\n",
      "Epoch 14/1000\n",
      "1856/1856 [==============================] - 0s 185us/step - loss: 0.8353 - accuracy: 0.8190 - val_loss: 0.7969 - val_accuracy: 0.8433\n",
      "Epoch 15/1000\n",
      "1856/1856 [==============================] - 0s 185us/step - loss: 0.8152 - accuracy: 0.8190 - val_loss: 0.7775 - val_accuracy: 0.8433\n",
      "Epoch 16/1000\n",
      "1856/1856 [==============================] - 0s 188us/step - loss: 0.7974 - accuracy: 0.8190 - val_loss: 0.7589 - val_accuracy: 0.8433\n",
      "Epoch 17/1000\n",
      "1856/1856 [==============================] - 0s 192us/step - loss: 0.7812 - accuracy: 0.8190 - val_loss: 0.7426 - val_accuracy: 0.8433\n",
      "Epoch 18/1000\n",
      "1856/1856 [==============================] - 0s 185us/step - loss: 0.7667 - accuracy: 0.8190 - val_loss: 0.7281 - val_accuracy: 0.8433\n",
      "Epoch 19/1000\n",
      "1856/1856 [==============================] - 0s 185us/step - loss: 0.7537 - accuracy: 0.8190 - val_loss: 0.7150 - val_accuracy: 0.8433\n",
      "Epoch 20/1000\n",
      "1856/1856 [==============================] - 0s 189us/step - loss: 0.7421 - accuracy: 0.8190 - val_loss: 0.7037 - val_accuracy: 0.8433\n",
      "Epoch 21/1000\n",
      "1856/1856 [==============================] - 0s 188us/step - loss: 0.7318 - accuracy: 0.8190 - val_loss: 0.6930 - val_accuracy: 0.8433\n",
      "Epoch 22/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1856/1856 [==============================] - 0s 188us/step - loss: 0.7225 - accuracy: 0.8190 - val_loss: 0.6837 - val_accuracy: 0.8433\n",
      "Epoch 23/1000\n",
      "1856/1856 [==============================] - 0s 188us/step - loss: 0.7142 - accuracy: 0.8190 - val_loss: 0.6755 - val_accuracy: 0.8433\n",
      "Epoch 24/1000\n",
      "1856/1856 [==============================] - 0s 183us/step - loss: 0.7068 - accuracy: 0.8190 - val_loss: 0.6678 - val_accuracy: 0.8433\n",
      "Epoch 25/1000\n",
      "1856/1856 [==============================] - 0s 185us/step - loss: 0.7001 - accuracy: 0.8190 - val_loss: 0.6617 - val_accuracy: 0.8433\n",
      "Epoch 26/1000\n",
      "1856/1856 [==============================] - 0s 185us/step - loss: 0.6942 - accuracy: 0.8190 - val_loss: 0.6557 - val_accuracy: 0.8433\n",
      "Epoch 27/1000\n",
      "1856/1856 [==============================] - 0s 184us/step - loss: 0.6889 - accuracy: 0.8190 - val_loss: 0.6505 - val_accuracy: 0.8433\n",
      "Epoch 28/1000\n",
      "1856/1856 [==============================] - 0s 190us/step - loss: 0.6841 - accuracy: 0.8190 - val_loss: 0.6460 - val_accuracy: 0.8433\n",
      "Epoch 29/1000\n",
      "1856/1856 [==============================] - 0s 188us/step - loss: 0.6798 - accuracy: 0.8190 - val_loss: 0.6418 - val_accuracy: 0.8433\n",
      "Epoch 30/1000\n",
      "1856/1856 [==============================] - 0s 185us/step - loss: 0.6760 - accuracy: 0.8190 - val_loss: 0.6382 - val_accuracy: 0.8433\n",
      "Epoch 31/1000\n",
      "1856/1856 [==============================] - 0s 188us/step - loss: 0.6726 - accuracy: 0.8190 - val_loss: 0.6353 - val_accuracy: 0.8433\n",
      "Epoch 32/1000\n",
      "1856/1856 [==============================] - 0s 183us/step - loss: 0.6695 - accuracy: 0.8190 - val_loss: 0.6324 - val_accuracy: 0.8433\n",
      "Epoch 33/1000\n",
      "1856/1856 [==============================] - 0s 185us/step - loss: 0.6667 - accuracy: 0.8190 - val_loss: 0.6299 - val_accuracy: 0.8433\n",
      "Epoch 34/1000\n",
      "1856/1856 [==============================] - 0s 189us/step - loss: 0.6643 - accuracy: 0.8190 - val_loss: 0.6277 - val_accuracy: 0.8433\n",
      "Epoch 35/1000\n",
      "1856/1856 [==============================] - 0s 189us/step - loss: 0.6620 - accuracy: 0.8190 - val_loss: 0.6258 - val_accuracy: 0.8433\n",
      "Epoch 36/1000\n",
      "1856/1856 [==============================] - 0s 185us/step - loss: 0.6601 - accuracy: 0.8190 - val_loss: 0.6240 - val_accuracy: 0.8433\n",
      "Epoch 37/1000\n",
      "1856/1856 [==============================] - 0s 186us/step - loss: 0.6583 - accuracy: 0.8190 - val_loss: 0.6228 - val_accuracy: 0.8433\n",
      "Epoch 38/1000\n",
      "1856/1856 [==============================] - 0s 199us/step - loss: 0.6566 - accuracy: 0.8190 - val_loss: 0.6215 - val_accuracy: 0.8433\n",
      "Epoch 39/1000\n",
      "1856/1856 [==============================] - 0s 187us/step - loss: 0.6552 - accuracy: 0.8190 - val_loss: 0.6207 - val_accuracy: 0.8433\n",
      "Epoch 40/1000\n",
      "1856/1856 [==============================] - 0s 203us/step - loss: 0.6539 - accuracy: 0.8190 - val_loss: 0.6197 - val_accuracy: 0.8433\n",
      "Epoch 41/1000\n",
      "1856/1856 [==============================] - 0s 199us/step - loss: 0.6527 - accuracy: 0.8190 - val_loss: 0.6190 - val_accuracy: 0.8433\n",
      "Epoch 42/1000\n",
      "1856/1856 [==============================] - 0s 195us/step - loss: 0.6516 - accuracy: 0.8190 - val_loss: 0.6184 - val_accuracy: 0.8433\n",
      "Epoch 43/1000\n",
      "1856/1856 [==============================] - 0s 198us/step - loss: 0.6506 - accuracy: 0.8190 - val_loss: 0.6179 - val_accuracy: 0.8433\n",
      "Epoch 44/1000\n",
      "1856/1856 [==============================] - 0s 185us/step - loss: 0.6497 - accuracy: 0.8190 - val_loss: 0.6174 - val_accuracy: 0.8433\n",
      "Epoch 45/1000\n",
      "1856/1856 [==============================] - 0s 205us/step - loss: 0.6489 - accuracy: 0.8190 - val_loss: 0.6171 - val_accuracy: 0.8433\n",
      "Epoch 46/1000\n",
      "1856/1856 [==============================] - 0s 189us/step - loss: 0.6483 - accuracy: 0.8190 - val_loss: 0.6169 - val_accuracy: 0.8433\n",
      "Epoch 47/1000\n",
      "1856/1856 [==============================] - 0s 186us/step - loss: 0.6476 - accuracy: 0.8190 - val_loss: 0.6165 - val_accuracy: 0.8433\n",
      "Epoch 48/1000\n",
      "1856/1856 [==============================] - 0s 191us/step - loss: 0.6470 - accuracy: 0.8190 - val_loss: 0.6163 - val_accuracy: 0.8433\n",
      "Epoch 49/1000\n",
      "1856/1856 [==============================] - 0s 188us/step - loss: 0.6465 - accuracy: 0.8190 - val_loss: 0.6163 - val_accuracy: 0.8433\n",
      "Epoch 50/1000\n",
      "1856/1856 [==============================] - 0s 184us/step - loss: 0.6460 - accuracy: 0.8190 - val_loss: 0.6163 - val_accuracy: 0.8433\n",
      "Epoch 51/1000\n",
      "1856/1856 [==============================] - 0s 190us/step - loss: 0.6456 - accuracy: 0.8190 - val_loss: 0.6163 - val_accuracy: 0.8433\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 1s 483us/step - loss: 1.1541 - accuracy: 0.7119 - val_loss: 1.0433 - val_accuracy: 0.8417\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 0s 185us/step - loss: 1.0481 - accuracy: 0.8191 - val_loss: 0.9501 - val_accuracy: 0.8417\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 0s 192us/step - loss: 0.9676 - accuracy: 0.8191 - val_loss: 0.8759 - val_accuracy: 0.8417\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 0s 190us/step - loss: 0.9033 - accuracy: 0.8191 - val_loss: 0.8168 - val_accuracy: 0.8417\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 0s 199us/step - loss: 0.8520 - accuracy: 0.8191 - val_loss: 0.7701 - val_accuracy: 0.8417\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 0s 197us/step - loss: 0.8113 - accuracy: 0.8191 - val_loss: 0.7329 - val_accuracy: 0.8417\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 0s 197us/step - loss: 0.7789 - accuracy: 0.8191 - val_loss: 0.7045 - val_accuracy: 0.8417\n",
      "Epoch 8/1000\n",
      "1857/1857 [==============================] - 0s 207us/step - loss: 0.7535 - accuracy: 0.8191 - val_loss: 0.6815 - val_accuracy: 0.8417\n",
      "Epoch 9/1000\n",
      "1857/1857 [==============================] - 0s 191us/step - loss: 0.7334 - accuracy: 0.8191 - val_loss: 0.6635 - val_accuracy: 0.8417\n",
      "Epoch 10/1000\n",
      "1857/1857 [==============================] - 0s 194us/step - loss: 0.7172 - accuracy: 0.8191 - val_loss: 0.6504 - val_accuracy: 0.8417\n",
      "Epoch 11/1000\n",
      "1857/1857 [==============================] - 0s 191us/step - loss: 0.7044 - accuracy: 0.8191 - val_loss: 0.6393 - val_accuracy: 0.8417\n",
      "Epoch 12/1000\n",
      "1857/1857 [==============================] - 0s 191us/step - loss: 0.6940 - accuracy: 0.8191 - val_loss: 0.6312 - val_accuracy: 0.8417\n",
      "Epoch 13/1000\n",
      "1857/1857 [==============================] - 0s 187us/step - loss: 0.6860 - accuracy: 0.8191 - val_loss: 0.6258 - val_accuracy: 0.8417\n",
      "Epoch 14/1000\n",
      "1857/1857 [==============================] - 0s 204us/step - loss: 0.6792 - accuracy: 0.8191 - val_loss: 0.6204 - val_accuracy: 0.8417\n",
      "Epoch 15/1000\n",
      "1857/1857 [==============================] - 0s 198us/step - loss: 0.6736 - accuracy: 0.8191 - val_loss: 0.6163 - val_accuracy: 0.8417\n",
      "Epoch 16/1000\n",
      "1857/1857 [==============================] - 0s 192us/step - loss: 0.6690 - accuracy: 0.8191 - val_loss: 0.6141 - val_accuracy: 0.8417\n",
      "Epoch 17/1000\n",
      "1857/1857 [==============================] - 0s 193us/step - loss: 0.6652 - accuracy: 0.8191 - val_loss: 0.6117 - val_accuracy: 0.8417\n",
      "Epoch 18/1000\n",
      "1857/1857 [==============================] - 0s 189us/step - loss: 0.6620 - accuracy: 0.8191 - val_loss: 0.6098 - val_accuracy: 0.8417\n",
      "Epoch 19/1000\n",
      "1857/1857 [==============================] - 0s 195us/step - loss: 0.6601 - accuracy: 0.8191 - val_loss: 0.6089 - val_accuracy: 0.8417\n",
      "Epoch 20/1000\n",
      "1857/1857 [==============================] - 0s 196us/step - loss: 0.6581 - accuracy: 0.8191 - val_loss: 0.6085 - val_accuracy: 0.8417\n",
      "Epoch 21/1000\n",
      "1857/1857 [==============================] - 0s 188us/step - loss: 0.6560 - accuracy: 0.8191 - val_loss: 0.6078 - val_accuracy: 0.8417\n",
      "Epoch 22/1000\n",
      "1857/1857 [==============================] - 0s 193us/step - loss: 0.6542 - accuracy: 0.8191 - val_loss: 0.6072 - val_accuracy: 0.8417\n",
      "Epoch 23/1000\n",
      "1857/1857 [==============================] - 0s 186us/step - loss: 0.6528 - accuracy: 0.8191 - val_loss: 0.6068 - val_accuracy: 0.8417\n",
      "Epoch 24/1000\n",
      "1857/1857 [==============================] - 0s 182us/step - loss: 0.6517 - accuracy: 0.8191 - val_loss: 0.6079 - val_accuracy: 0.8417\n",
      "Epoch 25/1000\n",
      "1857/1857 [==============================] - 0s 186us/step - loss: 0.6507 - accuracy: 0.8191 - val_loss: 0.6086 - val_accuracy: 0.8417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/1000\n",
      "1857/1857 [==============================] - 0s 183us/step - loss: 0.6496 - accuracy: 0.8191 - val_loss: 0.6085 - val_accuracy: 0.8417\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 1s 478us/step - loss: 1.3743 - accuracy: 0.2768 - val_loss: 1.3303 - val_accuracy: 0.8271\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 0s 185us/step - loss: 1.2918 - accuracy: 0.8239 - val_loss: 1.2642 - val_accuracy: 0.8271\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 0s 193us/step - loss: 1.2319 - accuracy: 0.8239 - val_loss: 1.2075 - val_accuracy: 0.8271\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 0s 193us/step - loss: 1.1741 - accuracy: 0.8239 - val_loss: 1.1531 - val_accuracy: 0.8271\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 0s 185us/step - loss: 1.1125 - accuracy: 0.8239 - val_loss: 1.0963 - val_accuracy: 0.8271\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 0s 185us/step - loss: 1.0167 - accuracy: 0.8239 - val_loss: 0.9981 - val_accuracy: 0.8271\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 0s 197us/step - loss: 0.8934 - accuracy: 0.8239 - val_loss: 0.8933 - val_accuracy: 0.8271\n",
      "Epoch 8/1000\n",
      "1857/1857 [==============================] - 0s 193us/step - loss: 0.8075 - accuracy: 0.8239 - val_loss: 0.8251 - val_accuracy: 0.8271\n",
      "Epoch 9/1000\n",
      "1857/1857 [==============================] - 0s 190us/step - loss: 0.7544 - accuracy: 0.8239 - val_loss: 0.7811 - val_accuracy: 0.8271\n",
      "Epoch 10/1000\n",
      "1857/1857 [==============================] - 0s 193us/step - loss: 0.7195 - accuracy: 0.8239 - val_loss: 0.7506 - val_accuracy: 0.8271\n",
      "Epoch 11/1000\n",
      "1857/1857 [==============================] - 0s 188us/step - loss: 0.6953 - accuracy: 0.8239 - val_loss: 0.7297 - val_accuracy: 0.8271\n",
      "Epoch 12/1000\n",
      "1857/1857 [==============================] - 0s 191us/step - loss: 0.6785 - accuracy: 0.8239 - val_loss: 0.7143 - val_accuracy: 0.8271\n",
      "Epoch 13/1000\n",
      "1857/1857 [==============================] - 0s 184us/step - loss: 0.6672 - accuracy: 0.8239 - val_loss: 0.7052 - val_accuracy: 0.8271\n",
      "Epoch 14/1000\n",
      "1857/1857 [==============================] - 0s 187us/step - loss: 0.6583 - accuracy: 0.8239 - val_loss: 0.6967 - val_accuracy: 0.8271\n",
      "Epoch 15/1000\n",
      "1857/1857 [==============================] - 0s 201us/step - loss: 0.6514 - accuracy: 0.8239 - val_loss: 0.6907 - val_accuracy: 0.8271\n",
      "Epoch 16/1000\n",
      "1857/1857 [==============================] - 0s 190us/step - loss: 0.6463 - accuracy: 0.8239 - val_loss: 0.6857 - val_accuracy: 0.8271\n",
      "Epoch 17/1000\n",
      "1857/1857 [==============================] - 0s 186us/step - loss: 0.6425 - accuracy: 0.8239 - val_loss: 0.6824 - val_accuracy: 0.8271\n",
      "Epoch 18/1000\n",
      "1857/1857 [==============================] - 0s 190us/step - loss: 0.6397 - accuracy: 0.8239 - val_loss: 0.6794 - val_accuracy: 0.8271\n",
      "Epoch 19/1000\n",
      "1857/1857 [==============================] - 0s 184us/step - loss: 0.6374 - accuracy: 0.8239 - val_loss: 0.6776 - val_accuracy: 0.8271\n",
      "Epoch 20/1000\n",
      "1857/1857 [==============================] - 0s 194us/step - loss: 0.6357 - accuracy: 0.8239 - val_loss: 0.6760 - val_accuracy: 0.8271\n",
      "Epoch 21/1000\n",
      "1857/1857 [==============================] - 0s 193us/step - loss: 0.6343 - accuracy: 0.8239 - val_loss: 0.6750 - val_accuracy: 0.8271\n",
      "Epoch 22/1000\n",
      "1857/1857 [==============================] - 0s 191us/step - loss: 0.6333 - accuracy: 0.8239 - val_loss: 0.6738 - val_accuracy: 0.8271\n",
      "Epoch 23/1000\n",
      "1857/1857 [==============================] - 0s 193us/step - loss: 0.6324 - accuracy: 0.8239 - val_loss: 0.6731 - val_accuracy: 0.8271\n",
      "Epoch 24/1000\n",
      "1857/1857 [==============================] - 0s 191us/step - loss: 0.6317 - accuracy: 0.8239 - val_loss: 0.6725 - val_accuracy: 0.8271\n",
      "Epoch 25/1000\n",
      "1857/1857 [==============================] - 0s 195us/step - loss: 0.6312 - accuracy: 0.8239 - val_loss: 0.6718 - val_accuracy: 0.8271\n",
      "Epoch 26/1000\n",
      "1857/1857 [==============================] - 0s 193us/step - loss: 0.6307 - accuracy: 0.8239 - val_loss: 0.6717 - val_accuracy: 0.8271\n",
      "Epoch 27/1000\n",
      "1857/1857 [==============================] - 0s 196us/step - loss: 0.6303 - accuracy: 0.8239 - val_loss: 0.6716 - val_accuracy: 0.8271\n",
      "Epoch 28/1000\n",
      "1857/1857 [==============================] - 0s 196us/step - loss: 0.6300 - accuracy: 0.8239 - val_loss: 0.6713 - val_accuracy: 0.8271\n",
      "Epoch 29/1000\n",
      "1857/1857 [==============================] - 0s 193us/step - loss: 0.6297 - accuracy: 0.8239 - val_loss: 0.6711 - val_accuracy: 0.8271\n",
      "Epoch 30/1000\n",
      "1857/1857 [==============================] - 0s 190us/step - loss: 0.6295 - accuracy: 0.8239 - val_loss: 0.6708 - val_accuracy: 0.8271\n",
      "Epoch 31/1000\n",
      "1857/1857 [==============================] - 0s 195us/step - loss: 0.6294 - accuracy: 0.8239 - val_loss: 0.6704 - val_accuracy: 0.8271\n",
      "Epoch 32/1000\n",
      "1857/1857 [==============================] - 0s 206us/step - loss: 0.6292 - accuracy: 0.8239 - val_loss: 0.6704 - val_accuracy: 0.8271\n",
      "Epoch 33/1000\n",
      "1857/1857 [==============================] - 0s 208us/step - loss: 0.6291 - accuracy: 0.8239 - val_loss: 0.6704 - val_accuracy: 0.8271\n",
      "Epoch 34/1000\n",
      "1857/1857 [==============================] - 0s 192us/step - loss: 0.6291 - accuracy: 0.8239 - val_loss: 0.6702 - val_accuracy: 0.8271\n",
      "Epoch 35/1000\n",
      "1857/1857 [==============================] - 0s 184us/step - loss: 0.6289 - accuracy: 0.8239 - val_loss: 0.6703 - val_accuracy: 0.8271\n",
      "Epoch 36/1000\n",
      "1857/1857 [==============================] - 0s 188us/step - loss: 0.6288 - accuracy: 0.8239 - val_loss: 0.6701 - val_accuracy: 0.8271\n",
      "Epoch 37/1000\n",
      "1857/1857 [==============================] - 0s 194us/step - loss: 0.6287 - accuracy: 0.8239 - val_loss: 0.6686 - val_accuracy: 0.8271\n",
      "Epoch 38/1000\n",
      "1857/1857 [==============================] - 0s 197us/step - loss: 0.6288 - accuracy: 0.8239 - val_loss: 0.6685 - val_accuracy: 0.8271\n",
      "Epoch 39/1000\n",
      "1857/1857 [==============================] - 0s 188us/step - loss: 0.6287 - accuracy: 0.8239 - val_loss: 0.6686 - val_accuracy: 0.8271\n",
      "Epoch 40/1000\n",
      "1857/1857 [==============================] - 0s 197us/step - loss: 0.6287 - accuracy: 0.8239 - val_loss: 0.6689 - val_accuracy: 0.8271\n",
      "Epoch 41/1000\n",
      "1857/1857 [==============================] - 0s 192us/step - loss: 0.6285 - accuracy: 0.8239 - val_loss: 0.6687 - val_accuracy: 0.8271\n",
      "auc: 0.6589411530829588\n",
      "kappa: 0.0\n",
      "layers: 1, nodes: 2\n",
      "Train on 1854 samples, validate on 618 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 1s 505us/step - loss: 1.2001 - accuracy: 0.5874 - val_loss: 1.0622 - val_accuracy: 0.8382\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 0s 185us/step - loss: 1.0494 - accuracy: 0.8215 - val_loss: 0.9625 - val_accuracy: 0.8382\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 0s 187us/step - loss: 0.9650 - accuracy: 0.8215 - val_loss: 0.8861 - val_accuracy: 0.8382\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 0s 187us/step - loss: 0.8988 - accuracy: 0.8215 - val_loss: 0.8255 - val_accuracy: 0.8382\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 0s 188us/step - loss: 0.8463 - accuracy: 0.8215 - val_loss: 0.7780 - val_accuracy: 0.8382\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 0s 184us/step - loss: 0.8047 - accuracy: 0.8215 - val_loss: 0.7409 - val_accuracy: 0.8382\n",
      "Epoch 7/1000\n",
      "1854/1854 [==============================] - 0s 190us/step - loss: 0.7720 - accuracy: 0.8215 - val_loss: 0.7116 - val_accuracy: 0.8382\n",
      "Epoch 8/1000\n",
      "1854/1854 [==============================] - 0s 192us/step - loss: 0.7463 - accuracy: 0.8215 - val_loss: 0.6890 - val_accuracy: 0.8382\n",
      "Epoch 9/1000\n",
      "1854/1854 [==============================] - 0s 187us/step - loss: 0.7260 - accuracy: 0.8215 - val_loss: 0.6712 - val_accuracy: 0.8382\n",
      "Epoch 10/1000\n",
      "1854/1854 [==============================] - 0s 192us/step - loss: 0.7100 - accuracy: 0.8215 - val_loss: 0.6578 - val_accuracy: 0.8382\n",
      "Epoch 11/1000\n",
      "1854/1854 [==============================] - 0s 190us/step - loss: 0.6971 - accuracy: 0.8215 - val_loss: 0.6470 - val_accuracy: 0.8382\n",
      "Epoch 12/1000\n",
      "1854/1854 [==============================] - 0s 183us/step - loss: 0.6869 - accuracy: 0.8215 - val_loss: 0.6390 - val_accuracy: 0.8382\n",
      "Epoch 13/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1854/1854 [==============================] - 0s 184us/step - loss: 0.6786 - accuracy: 0.8215 - val_loss: 0.6327 - val_accuracy: 0.8382\n",
      "Epoch 14/1000\n",
      "1854/1854 [==============================] - 0s 183us/step - loss: 0.6719 - accuracy: 0.8215 - val_loss: 0.6280 - val_accuracy: 0.8382\n",
      "Epoch 15/1000\n",
      "1854/1854 [==============================] - 0s 186us/step - loss: 0.6664 - accuracy: 0.8215 - val_loss: 0.6241 - val_accuracy: 0.8382\n",
      "Epoch 16/1000\n",
      "1854/1854 [==============================] - 0s 189us/step - loss: 0.6618 - accuracy: 0.8215 - val_loss: 0.6218 - val_accuracy: 0.8382\n",
      "Epoch 17/1000\n",
      "1854/1854 [==============================] - 0s 190us/step - loss: 0.6581 - accuracy: 0.8215 - val_loss: 0.6195 - val_accuracy: 0.8382\n",
      "Epoch 18/1000\n",
      "1854/1854 [==============================] - 0s 193us/step - loss: 0.6549 - accuracy: 0.8215 - val_loss: 0.6184 - val_accuracy: 0.8382\n",
      "Epoch 19/1000\n",
      "1854/1854 [==============================] - 0s 187us/step - loss: 0.6523 - accuracy: 0.8215 - val_loss: 0.6173 - val_accuracy: 0.8382\n",
      "Epoch 20/1000\n",
      "1854/1854 [==============================] - 0s 188us/step - loss: 0.6501 - accuracy: 0.8215 - val_loss: 0.6168 - val_accuracy: 0.8382\n",
      "Epoch 21/1000\n",
      "1854/1854 [==============================] - 0s 188us/step - loss: 0.6481 - accuracy: 0.8215 - val_loss: 0.6164 - val_accuracy: 0.8382\n",
      "Epoch 22/1000\n",
      "1854/1854 [==============================] - 0s 193us/step - loss: 0.6465 - accuracy: 0.8215 - val_loss: 0.6162 - val_accuracy: 0.8382\n",
      "Epoch 23/1000\n",
      "1854/1854 [==============================] - 0s 186us/step - loss: 0.6451 - accuracy: 0.8215 - val_loss: 0.6165 - val_accuracy: 0.8382\n",
      "Epoch 24/1000\n",
      "1854/1854 [==============================] - 0s 187us/step - loss: 0.6440 - accuracy: 0.8215 - val_loss: 0.6168 - val_accuracy: 0.8382\n",
      "Epoch 25/1000\n",
      "1854/1854 [==============================] - 0s 183us/step - loss: 0.6430 - accuracy: 0.8215 - val_loss: 0.6168 - val_accuracy: 0.8382\n",
      "Train on 1854 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 1s 493us/step - loss: 1.2308 - accuracy: 0.6170 - val_loss: 1.1448 - val_accuracy: 0.8465\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 0s 198us/step - loss: 1.0914 - accuracy: 0.8182 - val_loss: 1.0380 - val_accuracy: 0.8465\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 0s 195us/step - loss: 1.0003 - accuracy: 0.8182 - val_loss: 0.9510 - val_accuracy: 0.8465\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 0s 199us/step - loss: 0.9260 - accuracy: 0.8182 - val_loss: 0.8797 - val_accuracy: 0.8465\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 0s 200us/step - loss: 0.8662 - accuracy: 0.8182 - val_loss: 0.8211 - val_accuracy: 0.8465\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 0s 193us/step - loss: 0.8183 - accuracy: 0.8182 - val_loss: 0.7747 - val_accuracy: 0.8465\n",
      "Epoch 7/1000\n",
      "1854/1854 [==============================] - 0s 197us/step - loss: 0.7806 - accuracy: 0.8182 - val_loss: 0.7378 - val_accuracy: 0.8465\n",
      "Epoch 8/1000\n",
      "1854/1854 [==============================] - 0s 198us/step - loss: 0.7510 - accuracy: 0.8182 - val_loss: 0.7093 - val_accuracy: 0.8465\n",
      "Epoch 9/1000\n",
      "1854/1854 [==============================] - 0s 190us/step - loss: 0.7280 - accuracy: 0.8182 - val_loss: 0.6861 - val_accuracy: 0.8465\n",
      "Epoch 10/1000\n",
      "1854/1854 [==============================] - 0s 198us/step - loss: 0.7100 - accuracy: 0.8182 - val_loss: 0.6684 - val_accuracy: 0.8465\n",
      "Epoch 11/1000\n",
      "1854/1854 [==============================] - 0s 188us/step - loss: 0.6961 - accuracy: 0.8182 - val_loss: 0.6542 - val_accuracy: 0.8465\n",
      "Epoch 12/1000\n",
      "1854/1854 [==============================] - 0s 193us/step - loss: 0.6852 - accuracy: 0.8182 - val_loss: 0.6432 - val_accuracy: 0.8465\n",
      "Epoch 13/1000\n",
      "1854/1854 [==============================] - 0s 195us/step - loss: 0.6769 - accuracy: 0.8182 - val_loss: 0.6346 - val_accuracy: 0.8465\n",
      "Epoch 14/1000\n",
      "1854/1854 [==============================] - 0s 186us/step - loss: 0.6704 - accuracy: 0.8182 - val_loss: 0.6277 - val_accuracy: 0.8465\n",
      "Epoch 15/1000\n",
      "1854/1854 [==============================] - 0s 194us/step - loss: 0.6653 - accuracy: 0.8182 - val_loss: 0.6224 - val_accuracy: 0.8465\n",
      "Epoch 16/1000\n",
      "1854/1854 [==============================] - 0s 187us/step - loss: 0.6613 - accuracy: 0.8182 - val_loss: 0.6186 - val_accuracy: 0.8465\n",
      "Epoch 17/1000\n",
      "1854/1854 [==============================] - 0s 187us/step - loss: 0.6582 - accuracy: 0.8182 - val_loss: 0.6154 - val_accuracy: 0.8465\n",
      "Epoch 18/1000\n",
      "1854/1854 [==============================] - 0s 190us/step - loss: 0.6557 - accuracy: 0.8182 - val_loss: 0.6129 - val_accuracy: 0.8465\n",
      "Epoch 19/1000\n",
      "1854/1854 [==============================] - 0s 193us/step - loss: 0.6537 - accuracy: 0.8182 - val_loss: 0.6109 - val_accuracy: 0.8465\n",
      "Epoch 20/1000\n",
      "1854/1854 [==============================] - 0s 196us/step - loss: 0.6522 - accuracy: 0.8182 - val_loss: 0.6099 - val_accuracy: 0.8465\n",
      "Epoch 21/1000\n",
      "1854/1854 [==============================] - 0s 196us/step - loss: 0.6510 - accuracy: 0.8182 - val_loss: 0.6083 - val_accuracy: 0.8465\n",
      "Epoch 22/1000\n",
      "1854/1854 [==============================] - 0s 192us/step - loss: 0.6499 - accuracy: 0.8182 - val_loss: 0.6079 - val_accuracy: 0.8465\n",
      "Epoch 23/1000\n",
      "1854/1854 [==============================] - 0s 187us/step - loss: 0.6491 - accuracy: 0.8182 - val_loss: 0.6071 - val_accuracy: 0.8465\n",
      "Epoch 24/1000\n",
      "1854/1854 [==============================] - 0s 189us/step - loss: 0.6484 - accuracy: 0.8182 - val_loss: 0.6068 - val_accuracy: 0.8465\n",
      "Epoch 25/1000\n",
      "1854/1854 [==============================] - 0s 190us/step - loss: 0.6479 - accuracy: 0.8182 - val_loss: 0.6064 - val_accuracy: 0.8465\n",
      "Epoch 26/1000\n",
      "1854/1854 [==============================] - 0s 202us/step - loss: 0.6475 - accuracy: 0.8182 - val_loss: 0.6064 - val_accuracy: 0.8465\n",
      "Epoch 27/1000\n",
      "1854/1854 [==============================] - 0s 200us/step - loss: 0.6471 - accuracy: 0.8182 - val_loss: 0.6061 - val_accuracy: 0.8465\n",
      "Epoch 28/1000\n",
      "1854/1854 [==============================] - 0s 194us/step - loss: 0.6468 - accuracy: 0.8182 - val_loss: 0.6060 - val_accuracy: 0.8465\n",
      "Epoch 29/1000\n",
      "1854/1854 [==============================] - 0s 193us/step - loss: 0.6466 - accuracy: 0.8182 - val_loss: 0.6061 - val_accuracy: 0.8465\n",
      "Epoch 30/1000\n",
      "1854/1854 [==============================] - 0s 189us/step - loss: 0.6464 - accuracy: 0.8182 - val_loss: 0.6064 - val_accuracy: 0.8465\n",
      "Epoch 31/1000\n",
      "1854/1854 [==============================] - 0s 190us/step - loss: 0.6462 - accuracy: 0.8182 - val_loss: 0.6064 - val_accuracy: 0.8465\n",
      "Train on 1856 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1856/1856 [==============================] - 1s 496us/step - loss: 0.9256 - accuracy: 0.8152 - val_loss: 0.8190 - val_accuracy: 0.8546\n",
      "Epoch 2/1000\n",
      "1856/1856 [==============================] - 0s 196us/step - loss: 0.8022 - accuracy: 0.8152 - val_loss: 0.7557 - val_accuracy: 0.8546\n",
      "Epoch 3/1000\n",
      "1856/1856 [==============================] - 0s 193us/step - loss: 0.7567 - accuracy: 0.8152 - val_loss: 0.7109 - val_accuracy: 0.8546\n",
      "Epoch 4/1000\n",
      "1856/1856 [==============================] - 0s 189us/step - loss: 0.7247 - accuracy: 0.8152 - val_loss: 0.6776 - val_accuracy: 0.8546\n",
      "Epoch 5/1000\n",
      "1856/1856 [==============================] - 0s 196us/step - loss: 0.7022 - accuracy: 0.8152 - val_loss: 0.6535 - val_accuracy: 0.8546\n",
      "Epoch 6/1000\n",
      "1856/1856 [==============================] - 0s 191us/step - loss: 0.6861 - accuracy: 0.8152 - val_loss: 0.6369 - val_accuracy: 0.8546\n",
      "Epoch 7/1000\n",
      "1856/1856 [==============================] - 0s 215us/step - loss: 0.6751 - accuracy: 0.8152 - val_loss: 0.6238 - val_accuracy: 0.8546\n",
      "Epoch 8/1000\n",
      "1856/1856 [==============================] - 0s 218us/step - loss: 0.6674 - accuracy: 0.8152 - val_loss: 0.6145 - val_accuracy: 0.8546\n",
      "Epoch 9/1000\n",
      "1856/1856 [==============================] - 0s 191us/step - loss: 0.6623 - accuracy: 0.8152 - val_loss: 0.6077 - val_accuracy: 0.8546\n",
      "Epoch 10/1000\n",
      "1856/1856 [==============================] - 0s 199us/step - loss: 0.6588 - accuracy: 0.8152 - val_loss: 0.6027 - val_accuracy: 0.8546\n",
      "Epoch 11/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1856/1856 [==============================] - 0s 200us/step - loss: 0.6564 - accuracy: 0.8152 - val_loss: 0.5994 - val_accuracy: 0.8546\n",
      "Epoch 12/1000\n",
      "1856/1856 [==============================] - 0s 199us/step - loss: 0.6548 - accuracy: 0.8152 - val_loss: 0.5970 - val_accuracy: 0.8546\n",
      "Epoch 13/1000\n",
      "1856/1856 [==============================] - 0s 191us/step - loss: 0.6537 - accuracy: 0.8152 - val_loss: 0.5957 - val_accuracy: 0.8546\n",
      "Epoch 14/1000\n",
      "1856/1856 [==============================] - 0s 210us/step - loss: 0.6530 - accuracy: 0.8152 - val_loss: 0.5944 - val_accuracy: 0.8546\n",
      "Epoch 15/1000\n",
      "1856/1856 [==============================] - 0s 202us/step - loss: 0.6525 - accuracy: 0.8152 - val_loss: 0.5932 - val_accuracy: 0.8546\n",
      "Epoch 16/1000\n",
      "1856/1856 [==============================] - 0s 199us/step - loss: 0.6522 - accuracy: 0.8152 - val_loss: 0.5930 - val_accuracy: 0.8546\n",
      "Epoch 17/1000\n",
      "1856/1856 [==============================] - 0s 191us/step - loss: 0.6520 - accuracy: 0.8152 - val_loss: 0.5927 - val_accuracy: 0.8546\n",
      "Epoch 18/1000\n",
      "1856/1856 [==============================] - 0s 189us/step - loss: 0.6519 - accuracy: 0.8152 - val_loss: 0.5921 - val_accuracy: 0.8546\n",
      "Epoch 19/1000\n",
      "1856/1856 [==============================] - 0s 194us/step - loss: 0.6518 - accuracy: 0.8152 - val_loss: 0.5930 - val_accuracy: 0.8546\n",
      "Epoch 20/1000\n",
      "1856/1856 [==============================] - 0s 197us/step - loss: 0.6516 - accuracy: 0.8152 - val_loss: 0.5925 - val_accuracy: 0.8546\n",
      "Epoch 21/1000\n",
      "1856/1856 [==============================] - 0s 198us/step - loss: 0.6516 - accuracy: 0.8152 - val_loss: 0.5925 - val_accuracy: 0.8546\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 1s 501us/step - loss: 1.0875 - accuracy: 0.7555 - val_loss: 1.0102 - val_accuracy: 0.8336\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 0s 194us/step - loss: 0.9297 - accuracy: 0.8218 - val_loss: 0.8936 - val_accuracy: 0.8336\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 0s 195us/step - loss: 0.8263 - accuracy: 0.8218 - val_loss: 0.8070 - val_accuracy: 0.8336\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 0s 194us/step - loss: 0.7534 - accuracy: 0.8218 - val_loss: 0.7472 - val_accuracy: 0.8336\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 0s 195us/step - loss: 0.7075 - accuracy: 0.8218 - val_loss: 0.7082 - val_accuracy: 0.8336\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 0s 196us/step - loss: 0.6790 - accuracy: 0.8218 - val_loss: 0.6847 - val_accuracy: 0.8336\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 0s 193us/step - loss: 0.6618 - accuracy: 0.8218 - val_loss: 0.6699 - val_accuracy: 0.8336\n",
      "Epoch 8/1000\n",
      "1857/1857 [==============================] - 0s 200us/step - loss: 0.6512 - accuracy: 0.8218 - val_loss: 0.6605 - val_accuracy: 0.8336\n",
      "Epoch 9/1000\n",
      "1857/1857 [==============================] - 0s 205us/step - loss: 0.6449 - accuracy: 0.8218 - val_loss: 0.6543 - val_accuracy: 0.8336\n",
      "Epoch 10/1000\n",
      "1857/1857 [==============================] - 0s 205us/step - loss: 0.6408 - accuracy: 0.8218 - val_loss: 0.6517 - val_accuracy: 0.8336\n",
      "Epoch 11/1000\n",
      "1857/1857 [==============================] - 0s 211us/step - loss: 0.6384 - accuracy: 0.8218 - val_loss: 0.6489 - val_accuracy: 0.8336\n",
      "Epoch 12/1000\n",
      "1857/1857 [==============================] - 0s 210us/step - loss: 0.6370 - accuracy: 0.8218 - val_loss: 0.6479 - val_accuracy: 0.8336\n",
      "Epoch 13/1000\n",
      "1857/1857 [==============================] - 0s 204us/step - loss: 0.6360 - accuracy: 0.8218 - val_loss: 0.6471 - val_accuracy: 0.8336\n",
      "Epoch 14/1000\n",
      "1857/1857 [==============================] - 0s 200us/step - loss: 0.6355 - accuracy: 0.8218 - val_loss: 0.6467 - val_accuracy: 0.8336\n",
      "Epoch 15/1000\n",
      "1857/1857 [==============================] - 0s 202us/step - loss: 0.6351 - accuracy: 0.8218 - val_loss: 0.6470 - val_accuracy: 0.8336\n",
      "Epoch 16/1000\n",
      "1857/1857 [==============================] - 0s 206us/step - loss: 0.6349 - accuracy: 0.8218 - val_loss: 0.6473 - val_accuracy: 0.8336\n",
      "Epoch 17/1000\n",
      "1857/1857 [==============================] - 0s 207us/step - loss: 0.6348 - accuracy: 0.8218 - val_loss: 0.6470 - val_accuracy: 0.8336\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 1s 495us/step - loss: 1.4491 - accuracy: 0.2693 - val_loss: 1.3363 - val_accuracy: 0.8449\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 0s 196us/step - loss: 1.3045 - accuracy: 0.8180 - val_loss: 1.2652 - val_accuracy: 0.8449\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 0s 193us/step - loss: 1.2422 - accuracy: 0.8180 - val_loss: 1.2040 - val_accuracy: 0.8449\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 0s 201us/step - loss: 1.1863 - accuracy: 0.8180 - val_loss: 1.1482 - val_accuracy: 0.8449\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 0s 192us/step - loss: 1.1366 - accuracy: 0.8180 - val_loss: 1.0983 - val_accuracy: 0.8449\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 0s 200us/step - loss: 1.0909 - accuracy: 0.8180 - val_loss: 1.0530 - val_accuracy: 0.8449\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 0s 204us/step - loss: 1.0492 - accuracy: 0.8180 - val_loss: 1.0106 - val_accuracy: 0.8449\n",
      "Epoch 8/1000\n",
      "1857/1857 [==============================] - 0s 200us/step - loss: 1.0108 - accuracy: 0.8180 - val_loss: 0.9717 - val_accuracy: 0.8449\n",
      "Epoch 9/1000\n",
      "1857/1857 [==============================] - 0s 198us/step - loss: 0.9744 - accuracy: 0.8180 - val_loss: 0.9346 - val_accuracy: 0.8449\n",
      "Epoch 10/1000\n",
      "1857/1857 [==============================] - 0s 201us/step - loss: 0.9410 - accuracy: 0.8180 - val_loss: 0.9010 - val_accuracy: 0.8449\n",
      "Epoch 11/1000\n",
      "1857/1857 [==============================] - 0s 207us/step - loss: 0.9107 - accuracy: 0.8180 - val_loss: 0.8699 - val_accuracy: 0.8449\n",
      "Epoch 12/1000\n",
      "1857/1857 [==============================] - 0s 209us/step - loss: 0.8831 - accuracy: 0.8180 - val_loss: 0.8419 - val_accuracy: 0.8449\n",
      "Epoch 13/1000\n",
      "1857/1857 [==============================] - 0s 205us/step - loss: 0.8582 - accuracy: 0.8180 - val_loss: 0.8169 - val_accuracy: 0.8449\n",
      "Epoch 14/1000\n",
      "1857/1857 [==============================] - 0s 200us/step - loss: 0.8368 - accuracy: 0.8180 - val_loss: 0.7951 - val_accuracy: 0.8449\n",
      "Epoch 15/1000\n",
      "1857/1857 [==============================] - 0s 197us/step - loss: 0.8166 - accuracy: 0.8180 - val_loss: 0.7747 - val_accuracy: 0.8449\n",
      "Epoch 16/1000\n",
      "1857/1857 [==============================] - 0s 204us/step - loss: 0.7985 - accuracy: 0.8180 - val_loss: 0.7559 - val_accuracy: 0.8449\n",
      "Epoch 17/1000\n",
      "1857/1857 [==============================] - 0s 209us/step - loss: 0.7821 - accuracy: 0.8180 - val_loss: 0.7391 - val_accuracy: 0.8449\n",
      "Epoch 18/1000\n",
      "1857/1857 [==============================] - 0s 204us/step - loss: 0.7675 - accuracy: 0.8180 - val_loss: 0.7240 - val_accuracy: 0.8449\n",
      "Epoch 19/1000\n",
      "1857/1857 [==============================] - 0s 198us/step - loss: 0.7544 - accuracy: 0.8180 - val_loss: 0.7107 - val_accuracy: 0.8449\n",
      "Epoch 20/1000\n",
      "1857/1857 [==============================] - 0s 202us/step - loss: 0.7427 - accuracy: 0.8180 - val_loss: 0.6989 - val_accuracy: 0.8449\n",
      "Epoch 21/1000\n",
      "1857/1857 [==============================] - 0s 192us/step - loss: 0.7330 - accuracy: 0.8180 - val_loss: 0.6889 - val_accuracy: 0.8449\n",
      "Epoch 22/1000\n",
      "1857/1857 [==============================] - 0s 195us/step - loss: 0.7237 - accuracy: 0.8180 - val_loss: 0.6791 - val_accuracy: 0.8449\n",
      "Epoch 23/1000\n",
      "1857/1857 [==============================] - 0s 198us/step - loss: 0.7153 - accuracy: 0.8180 - val_loss: 0.6707 - val_accuracy: 0.8449\n",
      "Epoch 24/1000\n",
      "1857/1857 [==============================] - 0s 193us/step - loss: 0.7079 - accuracy: 0.8180 - val_loss: 0.6627 - val_accuracy: 0.8449\n",
      "Epoch 25/1000\n",
      "1857/1857 [==============================] - 0s 193us/step - loss: 0.7012 - accuracy: 0.8180 - val_loss: 0.6560 - val_accuracy: 0.8449\n",
      "Epoch 26/1000\n",
      "1857/1857 [==============================] - 0s 194us/step - loss: 0.6953 - accuracy: 0.8180 - val_loss: 0.6498 - val_accuracy: 0.8449\n",
      "Epoch 27/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1857/1857 [==============================] - 0s 195us/step - loss: 0.6900 - accuracy: 0.8180 - val_loss: 0.6443 - val_accuracy: 0.8449\n",
      "Epoch 28/1000\n",
      "1857/1857 [==============================] - 0s 195us/step - loss: 0.6853 - accuracy: 0.8180 - val_loss: 0.6397 - val_accuracy: 0.8449\n",
      "Epoch 29/1000\n",
      "1857/1857 [==============================] - 0s 197us/step - loss: 0.6812 - accuracy: 0.8180 - val_loss: 0.6351 - val_accuracy: 0.8449\n",
      "Epoch 30/1000\n",
      "1857/1857 [==============================] - 0s 193us/step - loss: 0.6774 - accuracy: 0.8180 - val_loss: 0.6312 - val_accuracy: 0.8449\n",
      "Epoch 31/1000\n",
      "1857/1857 [==============================] - 0s 193us/step - loss: 0.6741 - accuracy: 0.8180 - val_loss: 0.6280 - val_accuracy: 0.8449\n",
      "Epoch 32/1000\n",
      "1857/1857 [==============================] - 0s 192us/step - loss: 0.6717 - accuracy: 0.8180 - val_loss: 0.6258 - val_accuracy: 0.8449\n",
      "Epoch 33/1000\n",
      "1857/1857 [==============================] - 0s 195us/step - loss: 0.6691 - accuracy: 0.8180 - val_loss: 0.6231 - val_accuracy: 0.8449\n",
      "Epoch 34/1000\n",
      "1857/1857 [==============================] - 0s 201us/step - loss: 0.6667 - accuracy: 0.8180 - val_loss: 0.6208 - val_accuracy: 0.8449\n",
      "Epoch 35/1000\n",
      "1857/1857 [==============================] - 0s 195us/step - loss: 0.6646 - accuracy: 0.8180 - val_loss: 0.6188 - val_accuracy: 0.8449\n",
      "Epoch 36/1000\n",
      "1857/1857 [==============================] - 0s 193us/step - loss: 0.6627 - accuracy: 0.8180 - val_loss: 0.6170 - val_accuracy: 0.8449\n",
      "Epoch 37/1000\n",
      "1857/1857 [==============================] - 0s 193us/step - loss: 0.6611 - accuracy: 0.8180 - val_loss: 0.6160 - val_accuracy: 0.8449\n",
      "Epoch 38/1000\n",
      "1857/1857 [==============================] - 0s 191us/step - loss: 0.6599 - accuracy: 0.8180 - val_loss: 0.6153 - val_accuracy: 0.8449\n",
      "Epoch 39/1000\n",
      "1857/1857 [==============================] - 0s 193us/step - loss: 0.6586 - accuracy: 0.8180 - val_loss: 0.6138 - val_accuracy: 0.8449\n",
      "Epoch 40/1000\n",
      "1857/1857 [==============================] - 0s 196us/step - loss: 0.6573 - accuracy: 0.8180 - val_loss: 0.6127 - val_accuracy: 0.8449\n",
      "Epoch 41/1000\n",
      "1857/1857 [==============================] - 0s 192us/step - loss: 0.6561 - accuracy: 0.8180 - val_loss: 0.6118 - val_accuracy: 0.8449\n",
      "Epoch 42/1000\n",
      "1857/1857 [==============================] - 0s 192us/step - loss: 0.6551 - accuracy: 0.8180 - val_loss: 0.6108 - val_accuracy: 0.8449\n",
      "Epoch 43/1000\n",
      "1857/1857 [==============================] - 0s 195us/step - loss: 0.6542 - accuracy: 0.8180 - val_loss: 0.6100 - val_accuracy: 0.8449\n",
      "Epoch 44/1000\n",
      "1857/1857 [==============================] - 0s 193us/step - loss: 0.6536 - accuracy: 0.8180 - val_loss: 0.6095 - val_accuracy: 0.8449\n",
      "Epoch 45/1000\n",
      "1857/1857 [==============================] - 0s 198us/step - loss: 0.6529 - accuracy: 0.8180 - val_loss: 0.6089 - val_accuracy: 0.8449\n",
      "Epoch 46/1000\n",
      "1857/1857 [==============================] - 0s 197us/step - loss: 0.6523 - accuracy: 0.8180 - val_loss: 0.6084 - val_accuracy: 0.8449\n",
      "Epoch 47/1000\n",
      "1857/1857 [==============================] - 0s 192us/step - loss: 0.6516 - accuracy: 0.8180 - val_loss: 0.6080 - val_accuracy: 0.8449\n",
      "Epoch 48/1000\n",
      "1857/1857 [==============================] - 0s 193us/step - loss: 0.6511 - accuracy: 0.8180 - val_loss: 0.6076 - val_accuracy: 0.8449\n",
      "Epoch 49/1000\n",
      "1857/1857 [==============================] - 0s 192us/step - loss: 0.6506 - accuracy: 0.8180 - val_loss: 0.6075 - val_accuracy: 0.8449\n",
      "Epoch 50/1000\n",
      "1857/1857 [==============================] - 0s 194us/step - loss: 0.6501 - accuracy: 0.8180 - val_loss: 0.6072 - val_accuracy: 0.8449\n",
      "Epoch 51/1000\n",
      "1857/1857 [==============================] - 0s 197us/step - loss: 0.6497 - accuracy: 0.8180 - val_loss: 0.6076 - val_accuracy: 0.8449\n",
      "Epoch 52/1000\n",
      "1857/1857 [==============================] - 0s 194us/step - loss: 0.6494 - accuracy: 0.8180 - val_loss: 0.6074 - val_accuracy: 0.8449\n",
      "Epoch 53/1000\n",
      "1857/1857 [==============================] - 0s 193us/step - loss: 0.6490 - accuracy: 0.8180 - val_loss: 0.6078 - val_accuracy: 0.8449\n",
      "auc: 0.6311613738675216\n",
      "kappa: 0.0\n",
      "layers: 1, nodes: 4\n",
      "Train on 1854 samples, validate on 618 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 1s 531us/step - loss: 1.5235 - accuracy: 0.4213 - val_loss: 1.3326 - val_accuracy: 0.8495\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 0s 192us/step - loss: 1.3046 - accuracy: 0.8177 - val_loss: 1.2674 - val_accuracy: 0.8495\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 0s 192us/step - loss: 1.2461 - accuracy: 0.8177 - val_loss: 1.2081 - val_accuracy: 0.8495\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 0s 197us/step - loss: 1.1918 - accuracy: 0.8177 - val_loss: 1.1532 - val_accuracy: 0.8495\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 0s 196us/step - loss: 1.1416 - accuracy: 0.8177 - val_loss: 1.1016 - val_accuracy: 0.8495\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 0s 192us/step - loss: 1.0951 - accuracy: 0.8177 - val_loss: 1.0538 - val_accuracy: 0.8495\n",
      "Epoch 7/1000\n",
      "1854/1854 [==============================] - 0s 195us/step - loss: 1.0520 - accuracy: 0.8177 - val_loss: 1.0103 - val_accuracy: 0.8495\n",
      "Epoch 8/1000\n",
      "1854/1854 [==============================] - 0s 192us/step - loss: 1.0125 - accuracy: 0.8177 - val_loss: 0.9693 - val_accuracy: 0.8495\n",
      "Epoch 9/1000\n",
      "1854/1854 [==============================] - 0s 193us/step - loss: 0.9763 - accuracy: 0.8177 - val_loss: 0.9318 - val_accuracy: 0.8495\n",
      "Epoch 10/1000\n",
      "1854/1854 [==============================] - 0s 196us/step - loss: 0.9433 - accuracy: 0.8177 - val_loss: 0.8980 - val_accuracy: 0.8495\n",
      "Epoch 11/1000\n",
      "1854/1854 [==============================] - 0s 193us/step - loss: 0.9132 - accuracy: 0.8177 - val_loss: 0.8672 - val_accuracy: 0.8495\n",
      "Epoch 12/1000\n",
      "1854/1854 [==============================] - 0s 194us/step - loss: 0.8859 - accuracy: 0.8177 - val_loss: 0.8391 - val_accuracy: 0.8495\n",
      "Epoch 13/1000\n",
      "1854/1854 [==============================] - 0s 191us/step - loss: 0.8612 - accuracy: 0.8177 - val_loss: 0.8136 - val_accuracy: 0.8495\n",
      "Epoch 14/1000\n",
      "1854/1854 [==============================] - 0s 193us/step - loss: 0.8390 - accuracy: 0.8177 - val_loss: 0.7905 - val_accuracy: 0.8495\n",
      "Epoch 15/1000\n",
      "1854/1854 [==============================] - 0s 193us/step - loss: 0.8189 - accuracy: 0.8177 - val_loss: 0.7693 - val_accuracy: 0.8495\n",
      "Epoch 16/1000\n",
      "1854/1854 [==============================] - 0s 194us/step - loss: 0.8009 - accuracy: 0.8177 - val_loss: 0.7506 - val_accuracy: 0.8495\n",
      "Epoch 17/1000\n",
      "1854/1854 [==============================] - 0s 197us/step - loss: 0.7848 - accuracy: 0.8177 - val_loss: 0.7336 - val_accuracy: 0.8495\n",
      "Epoch 18/1000\n",
      "1854/1854 [==============================] - 0s 194us/step - loss: 0.7703 - accuracy: 0.8177 - val_loss: 0.7182 - val_accuracy: 0.8495\n",
      "Epoch 19/1000\n",
      "1854/1854 [==============================] - 0s 194us/step - loss: 0.7572 - accuracy: 0.8177 - val_loss: 0.7050 - val_accuracy: 0.8495\n",
      "Epoch 20/1000\n",
      "1854/1854 [==============================] - 0s 190us/step - loss: 0.7456 - accuracy: 0.8177 - val_loss: 0.6927 - val_accuracy: 0.8495\n",
      "Epoch 21/1000\n",
      "1854/1854 [==============================] - 0s 197us/step - loss: 0.7352 - accuracy: 0.8177 - val_loss: 0.6818 - val_accuracy: 0.8495\n",
      "Epoch 22/1000\n",
      "1854/1854 [==============================] - 0s 197us/step - loss: 0.7259 - accuracy: 0.8177 - val_loss: 0.6719 - val_accuracy: 0.8495\n",
      "Epoch 23/1000\n",
      "1854/1854 [==============================] - 0s 193us/step - loss: 0.7177 - accuracy: 0.8177 - val_loss: 0.6628 - val_accuracy: 0.8495\n",
      "Epoch 24/1000\n",
      "1854/1854 [==============================] - 0s 193us/step - loss: 0.7102 - accuracy: 0.8177 - val_loss: 0.6552 - val_accuracy: 0.8495\n",
      "Epoch 25/1000\n",
      "1854/1854 [==============================] - 0s 193us/step - loss: 0.7036 - accuracy: 0.8177 - val_loss: 0.6482 - val_accuracy: 0.8495\n",
      "Epoch 26/1000\n",
      "1854/1854 [==============================] - 0s 196us/step - loss: 0.6978 - accuracy: 0.8177 - val_loss: 0.6418 - val_accuracy: 0.8495\n",
      "Epoch 27/1000\n",
      "1854/1854 [==============================] - 0s 194us/step - loss: 0.6925 - accuracy: 0.8177 - val_loss: 0.6363 - val_accuracy: 0.8495\n",
      "Epoch 28/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1854/1854 [==============================] - 0s 197us/step - loss: 0.6878 - accuracy: 0.8177 - val_loss: 0.6312 - val_accuracy: 0.8495\n",
      "Epoch 29/1000\n",
      "1854/1854 [==============================] - 0s 192us/step - loss: 0.6836 - accuracy: 0.8177 - val_loss: 0.6267 - val_accuracy: 0.8495\n",
      "Epoch 30/1000\n",
      "1854/1854 [==============================] - 0s 192us/step - loss: 0.6798 - accuracy: 0.8177 - val_loss: 0.6228 - val_accuracy: 0.8495\n",
      "Epoch 31/1000\n",
      "1854/1854 [==============================] - 0s 190us/step - loss: 0.6764 - accuracy: 0.8177 - val_loss: 0.6194 - val_accuracy: 0.8495\n",
      "Epoch 32/1000\n",
      "1854/1854 [==============================] - 0s 192us/step - loss: 0.6734 - accuracy: 0.8177 - val_loss: 0.6160 - val_accuracy: 0.8495\n",
      "Epoch 33/1000\n",
      "1854/1854 [==============================] - 0s 195us/step - loss: 0.6707 - accuracy: 0.8177 - val_loss: 0.6133 - val_accuracy: 0.8495\n",
      "Epoch 34/1000\n",
      "1854/1854 [==============================] - 0s 193us/step - loss: 0.6683 - accuracy: 0.8177 - val_loss: 0.6110 - val_accuracy: 0.8495\n",
      "Epoch 35/1000\n",
      "1854/1854 [==============================] - 0s 192us/step - loss: 0.6662 - accuracy: 0.8177 - val_loss: 0.6086 - val_accuracy: 0.8495\n",
      "Epoch 36/1000\n",
      "1854/1854 [==============================] - 0s 192us/step - loss: 0.6642 - accuracy: 0.8177 - val_loss: 0.6067 - val_accuracy: 0.8495\n",
      "Epoch 37/1000\n",
      "1854/1854 [==============================] - 0s 194us/step - loss: 0.6624 - accuracy: 0.8177 - val_loss: 0.6051 - val_accuracy: 0.8495\n",
      "Epoch 38/1000\n",
      "1854/1854 [==============================] - 0s 193us/step - loss: 0.6609 - accuracy: 0.8177 - val_loss: 0.6035 - val_accuracy: 0.8495\n",
      "Epoch 39/1000\n",
      "1854/1854 [==============================] - 0s 195us/step - loss: 0.6595 - accuracy: 0.8177 - val_loss: 0.6021 - val_accuracy: 0.8495\n",
      "Epoch 40/1000\n",
      "1854/1854 [==============================] - 0s 193us/step - loss: 0.6582 - accuracy: 0.8177 - val_loss: 0.6013 - val_accuracy: 0.8495\n",
      "Epoch 41/1000\n",
      "1854/1854 [==============================] - 0s 192us/step - loss: 0.6571 - accuracy: 0.8177 - val_loss: 0.6002 - val_accuracy: 0.8495\n",
      "Epoch 42/1000\n",
      "1854/1854 [==============================] - 0s 194us/step - loss: 0.6560 - accuracy: 0.8177 - val_loss: 0.5994 - val_accuracy: 0.8495\n",
      "Epoch 43/1000\n",
      "1854/1854 [==============================] - 0s 195us/step - loss: 0.6551 - accuracy: 0.8177 - val_loss: 0.5985 - val_accuracy: 0.8495\n",
      "Epoch 44/1000\n",
      "1854/1854 [==============================] - 0s 194us/step - loss: 0.6543 - accuracy: 0.8177 - val_loss: 0.5979 - val_accuracy: 0.8495\n",
      "Epoch 45/1000\n",
      "1854/1854 [==============================] - 0s 196us/step - loss: 0.6535 - accuracy: 0.8177 - val_loss: 0.5973 - val_accuracy: 0.8495\n",
      "Epoch 46/1000\n",
      "1854/1854 [==============================] - 0s 192us/step - loss: 0.6528 - accuracy: 0.8177 - val_loss: 0.5968 - val_accuracy: 0.8495\n",
      "Epoch 47/1000\n",
      "1854/1854 [==============================] - 0s 194us/step - loss: 0.6522 - accuracy: 0.8177 - val_loss: 0.5965 - val_accuracy: 0.8495\n",
      "Epoch 48/1000\n",
      "1854/1854 [==============================] - 0s 192us/step - loss: 0.6517 - accuracy: 0.8177 - val_loss: 0.5960 - val_accuracy: 0.8495\n",
      "Epoch 49/1000\n",
      "1854/1854 [==============================] - 0s 193us/step - loss: 0.6512 - accuracy: 0.8177 - val_loss: 0.5959 - val_accuracy: 0.8495\n",
      "Epoch 50/1000\n",
      "1854/1854 [==============================] - 0s 194us/step - loss: 0.6508 - accuracy: 0.8177 - val_loss: 0.5956 - val_accuracy: 0.8495\n",
      "Epoch 51/1000\n",
      "1854/1854 [==============================] - 0s 203us/step - loss: 0.6504 - accuracy: 0.8177 - val_loss: 0.5956 - val_accuracy: 0.8495\n",
      "Epoch 52/1000\n",
      "1854/1854 [==============================] - 0s 195us/step - loss: 0.6500 - accuracy: 0.8177 - val_loss: 0.5953 - val_accuracy: 0.8495\n",
      "Epoch 53/1000\n",
      "1854/1854 [==============================] - 0s 194us/step - loss: 0.6497 - accuracy: 0.8177 - val_loss: 0.5954 - val_accuracy: 0.8495\n",
      "Epoch 54/1000\n",
      "1854/1854 [==============================] - 0s 196us/step - loss: 0.6494 - accuracy: 0.8177 - val_loss: 0.5954 - val_accuracy: 0.8495\n",
      "Epoch 55/1000\n",
      "1854/1854 [==============================] - 0s 198us/step - loss: 0.6491 - accuracy: 0.8177 - val_loss: 0.5953 - val_accuracy: 0.8495\n",
      "Train on 1854 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 1s 510us/step - loss: 0.7299 - accuracy: 0.8177 - val_loss: 0.6352 - val_accuracy: 0.8481\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 0s 197us/step - loss: 0.6747 - accuracy: 0.8177 - val_loss: 0.6106 - val_accuracy: 0.8481\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 0s 195us/step - loss: 0.6603 - accuracy: 0.8177 - val_loss: 0.6025 - val_accuracy: 0.8481\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 0s 197us/step - loss: 0.6538 - accuracy: 0.8177 - val_loss: 0.5996 - val_accuracy: 0.8481\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 0s 194us/step - loss: 0.6504 - accuracy: 0.8177 - val_loss: 0.6008 - val_accuracy: 0.8481\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 0s 194us/step - loss: 0.6485 - accuracy: 0.8177 - val_loss: 0.6007 - val_accuracy: 0.8481\n",
      "Epoch 7/1000\n",
      "1854/1854 [==============================] - 0s 197us/step - loss: 0.6468 - accuracy: 0.8177 - val_loss: 0.6023 - val_accuracy: 0.8481\n",
      "Train on 1856 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1856/1856 [==============================] - 1s 515us/step - loss: 0.8978 - accuracy: 0.8200 - val_loss: 0.7875 - val_accuracy: 0.8401\n",
      "Epoch 2/1000\n",
      "1856/1856 [==============================] - 0s 198us/step - loss: 0.7526 - accuracy: 0.8200 - val_loss: 0.7110 - val_accuracy: 0.8401\n",
      "Epoch 3/1000\n",
      "1856/1856 [==============================] - 0s 199us/step - loss: 0.7003 - accuracy: 0.8200 - val_loss: 0.6768 - val_accuracy: 0.8401\n",
      "Epoch 4/1000\n",
      "1856/1856 [==============================] - 0s 190us/step - loss: 0.6746 - accuracy: 0.8200 - val_loss: 0.6587 - val_accuracy: 0.8401\n",
      "Epoch 5/1000\n",
      "1856/1856 [==============================] - 0s 192us/step - loss: 0.6610 - accuracy: 0.8200 - val_loss: 0.6492 - val_accuracy: 0.8401\n",
      "Epoch 6/1000\n",
      "1856/1856 [==============================] - 0s 194us/step - loss: 0.6514 - accuracy: 0.8200 - val_loss: 0.6502 - val_accuracy: 0.8401\n",
      "Epoch 7/1000\n",
      "1856/1856 [==============================] - 0s 190us/step - loss: 0.6404 - accuracy: 0.8200 - val_loss: 0.6442 - val_accuracy: 0.8401\n",
      "Epoch 8/1000\n",
      "1856/1856 [==============================] - 0s 189us/step - loss: 0.6282 - accuracy: 0.8200 - val_loss: 0.6350 - val_accuracy: 0.8401\n",
      "Epoch 9/1000\n",
      "1856/1856 [==============================] - 0s 187us/step - loss: 0.6168 - accuracy: 0.8200 - val_loss: 0.6327 - val_accuracy: 0.8401\n",
      "Epoch 10/1000\n",
      "1856/1856 [==============================] - 0s 189us/step - loss: 0.6100 - accuracy: 0.8200 - val_loss: 0.6311 - val_accuracy: 0.8401\n",
      "Epoch 11/1000\n",
      "1856/1856 [==============================] - 0s 202us/step - loss: 0.6045 - accuracy: 0.8200 - val_loss: 0.6324 - val_accuracy: 0.8401\n",
      "Epoch 12/1000\n",
      "1856/1856 [==============================] - 0s 209us/step - loss: 0.5994 - accuracy: 0.8200 - val_loss: 0.6324 - val_accuracy: 0.8401\n",
      "Epoch 13/1000\n",
      "1856/1856 [==============================] - 0s 205us/step - loss: 0.5956 - accuracy: 0.8200 - val_loss: 0.6314 - val_accuracy: 0.8401\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 1s 534us/step - loss: 1.3170 - accuracy: 0.3899 - val_loss: 1.1938 - val_accuracy: 0.8336\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 0s 202us/step - loss: 1.1300 - accuracy: 0.8218 - val_loss: 1.0847 - val_accuracy: 0.8336\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 0s 208us/step - loss: 1.0357 - accuracy: 0.8218 - val_loss: 0.9989 - val_accuracy: 0.8336\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 0s 204us/step - loss: 0.9591 - accuracy: 0.8218 - val_loss: 0.9282 - val_accuracy: 0.8336\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 0s 201us/step - loss: 0.8945 - accuracy: 0.8218 - val_loss: 0.8681 - val_accuracy: 0.8336\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 0s 195us/step - loss: 0.8418 - accuracy: 0.8218 - val_loss: 0.8195 - val_accuracy: 0.8336\n",
      "Epoch 7/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1857/1857 [==============================] - 0s 200us/step - loss: 0.7998 - accuracy: 0.8218 - val_loss: 0.7805 - val_accuracy: 0.8336\n",
      "Epoch 8/1000\n",
      "1857/1857 [==============================] - 0s 195us/step - loss: 0.7662 - accuracy: 0.8218 - val_loss: 0.7503 - val_accuracy: 0.8336\n",
      "Epoch 9/1000\n",
      "1857/1857 [==============================] - 0s 202us/step - loss: 0.7397 - accuracy: 0.8218 - val_loss: 0.7264 - val_accuracy: 0.8336\n",
      "Epoch 10/1000\n",
      "1857/1857 [==============================] - 0s 199us/step - loss: 0.7188 - accuracy: 0.8218 - val_loss: 0.7074 - val_accuracy: 0.8336\n",
      "Epoch 11/1000\n",
      "1857/1857 [==============================] - 0s 197us/step - loss: 0.7021 - accuracy: 0.8218 - val_loss: 0.6928 - val_accuracy: 0.8336\n",
      "Epoch 12/1000\n",
      "1857/1857 [==============================] - 0s 209us/step - loss: 0.6891 - accuracy: 0.8218 - val_loss: 0.6812 - val_accuracy: 0.8336\n",
      "Epoch 13/1000\n",
      "1857/1857 [==============================] - 0s 204us/step - loss: 0.6787 - accuracy: 0.8218 - val_loss: 0.6721 - val_accuracy: 0.8336\n",
      "Epoch 14/1000\n",
      "1857/1857 [==============================] - 0s 197us/step - loss: 0.6705 - accuracy: 0.8218 - val_loss: 0.6652 - val_accuracy: 0.8336\n",
      "Epoch 15/1000\n",
      "1857/1857 [==============================] - 0s 198us/step - loss: 0.6640 - accuracy: 0.8218 - val_loss: 0.6597 - val_accuracy: 0.8336\n",
      "Epoch 16/1000\n",
      "1857/1857 [==============================] - 0s 201us/step - loss: 0.6589 - accuracy: 0.8218 - val_loss: 0.6555 - val_accuracy: 0.8336\n",
      "Epoch 17/1000\n",
      "1857/1857 [==============================] - 0s 197us/step - loss: 0.6547 - accuracy: 0.8218 - val_loss: 0.6523 - val_accuracy: 0.8336\n",
      "Epoch 18/1000\n",
      "1857/1857 [==============================] - 0s 195us/step - loss: 0.6512 - accuracy: 0.8218 - val_loss: 0.6501 - val_accuracy: 0.8336\n",
      "Epoch 19/1000\n",
      "1857/1857 [==============================] - 0s 196us/step - loss: 0.6485 - accuracy: 0.8218 - val_loss: 0.6479 - val_accuracy: 0.8336\n",
      "Epoch 20/1000\n",
      "1857/1857 [==============================] - 0s 208us/step - loss: 0.6462 - accuracy: 0.8218 - val_loss: 0.6466 - val_accuracy: 0.8336\n",
      "Epoch 21/1000\n",
      "1857/1857 [==============================] - 0s 205us/step - loss: 0.6443 - accuracy: 0.8218 - val_loss: 0.6458 - val_accuracy: 0.8336\n",
      "Epoch 22/1000\n",
      "1857/1857 [==============================] - 0s 196us/step - loss: 0.6428 - accuracy: 0.8218 - val_loss: 0.6448 - val_accuracy: 0.8336\n",
      "Epoch 23/1000\n",
      "1857/1857 [==============================] - 0s 204us/step - loss: 0.6415 - accuracy: 0.8218 - val_loss: 0.6442 - val_accuracy: 0.8336\n",
      "Epoch 24/1000\n",
      "1857/1857 [==============================] - 0s 203us/step - loss: 0.6404 - accuracy: 0.8218 - val_loss: 0.6438 - val_accuracy: 0.8336\n",
      "Epoch 25/1000\n",
      "1857/1857 [==============================] - 0s 205us/step - loss: 0.6396 - accuracy: 0.8218 - val_loss: 0.6437 - val_accuracy: 0.8336\n",
      "Epoch 26/1000\n",
      "1857/1857 [==============================] - 0s 206us/step - loss: 0.6388 - accuracy: 0.8218 - val_loss: 0.6444 - val_accuracy: 0.8336\n",
      "Epoch 27/1000\n",
      "1857/1857 [==============================] - 0s 204us/step - loss: 0.6382 - accuracy: 0.8218 - val_loss: 0.6440 - val_accuracy: 0.8336\n",
      "Epoch 28/1000\n",
      "1857/1857 [==============================] - 0s 200us/step - loss: 0.6377 - accuracy: 0.8218 - val_loss: 0.6441 - val_accuracy: 0.8336\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 1s 537us/step - loss: 1.4252 - accuracy: 0.4583 - val_loss: 1.3264 - val_accuracy: 0.8465\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 0s 201us/step - loss: 1.2983 - accuracy: 0.8174 - val_loss: 1.2609 - val_accuracy: 0.8465\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 0s 217us/step - loss: 1.2387 - accuracy: 0.8174 - val_loss: 1.2009 - val_accuracy: 0.8465\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 0s 205us/step - loss: 1.1840 - accuracy: 0.8174 - val_loss: 1.1449 - val_accuracy: 0.8465\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 0s 198us/step - loss: 1.1346 - accuracy: 0.8174 - val_loss: 1.0954 - val_accuracy: 0.8465\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 0s 198us/step - loss: 1.0881 - accuracy: 0.8174 - val_loss: 1.0474 - val_accuracy: 0.8465\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 0s 202us/step - loss: 1.0448 - accuracy: 0.8174 - val_loss: 1.0039 - val_accuracy: 0.8465\n",
      "Epoch 8/1000\n",
      "1857/1857 [==============================] - 0s 200us/step - loss: 1.0052 - accuracy: 0.8174 - val_loss: 0.9636 - val_accuracy: 0.8465\n",
      "Epoch 9/1000\n",
      "1857/1857 [==============================] - 0s 199us/step - loss: 0.9690 - accuracy: 0.8174 - val_loss: 0.9268 - val_accuracy: 0.8465\n",
      "Epoch 10/1000\n",
      "1857/1857 [==============================] - 0s 200us/step - loss: 0.9361 - accuracy: 0.8174 - val_loss: 0.8932 - val_accuracy: 0.8465\n",
      "Epoch 11/1000\n",
      "1857/1857 [==============================] - 0s 197us/step - loss: 0.9072 - accuracy: 0.8174 - val_loss: 0.8644 - val_accuracy: 0.8465\n",
      "Epoch 12/1000\n",
      "1857/1857 [==============================] - 0s 198us/step - loss: 0.8814 - accuracy: 0.8174 - val_loss: 0.8379 - val_accuracy: 0.8465\n",
      "Epoch 13/1000\n",
      "1857/1857 [==============================] - 0s 195us/step - loss: 0.8571 - accuracy: 0.8174 - val_loss: 0.8128 - val_accuracy: 0.8465\n",
      "Epoch 14/1000\n",
      "1857/1857 [==============================] - 0s 200us/step - loss: 0.8359 - accuracy: 0.8174 - val_loss: 0.7915 - val_accuracy: 0.8465\n",
      "Epoch 15/1000\n",
      "1857/1857 [==============================] - 0s 202us/step - loss: 0.8170 - accuracy: 0.8174 - val_loss: 0.7723 - val_accuracy: 0.8465\n",
      "Epoch 16/1000\n",
      "1857/1857 [==============================] - 0s 195us/step - loss: 0.7991 - accuracy: 0.8174 - val_loss: 0.7537 - val_accuracy: 0.8465\n",
      "Epoch 17/1000\n",
      "1857/1857 [==============================] - 0s 201us/step - loss: 0.7828 - accuracy: 0.8174 - val_loss: 0.7369 - val_accuracy: 0.8465\n",
      "Epoch 18/1000\n",
      "1857/1857 [==============================] - 0s 200us/step - loss: 0.7683 - accuracy: 0.8174 - val_loss: 0.7219 - val_accuracy: 0.8465\n",
      "Epoch 19/1000\n",
      "1857/1857 [==============================] - 0s 205us/step - loss: 0.7553 - accuracy: 0.8174 - val_loss: 0.7083 - val_accuracy: 0.8465\n",
      "Epoch 20/1000\n",
      "1857/1857 [==============================] - 0s 200us/step - loss: 0.7437 - accuracy: 0.8174 - val_loss: 0.6965 - val_accuracy: 0.8465\n",
      "Epoch 21/1000\n",
      "1857/1857 [==============================] - 0s 197us/step - loss: 0.7334 - accuracy: 0.8174 - val_loss: 0.6859 - val_accuracy: 0.8465\n",
      "Epoch 22/1000\n",
      "1857/1857 [==============================] - 0s 193us/step - loss: 0.7242 - accuracy: 0.8174 - val_loss: 0.6764 - val_accuracy: 0.8465\n",
      "Epoch 23/1000\n",
      "1857/1857 [==============================] - 0s 196us/step - loss: 0.7164 - accuracy: 0.8174 - val_loss: 0.6688 - val_accuracy: 0.8465\n",
      "Epoch 24/1000\n",
      "1857/1857 [==============================] - 0s 205us/step - loss: 0.7090 - accuracy: 0.8174 - val_loss: 0.6612 - val_accuracy: 0.8465\n",
      "Epoch 25/1000\n",
      "1857/1857 [==============================] - 0s 205us/step - loss: 0.7024 - accuracy: 0.8174 - val_loss: 0.6543 - val_accuracy: 0.8465\n",
      "Epoch 26/1000\n",
      "1857/1857 [==============================] - 0s 211us/step - loss: 0.6964 - accuracy: 0.8174 - val_loss: 0.6482 - val_accuracy: 0.8465\n",
      "Epoch 27/1000\n",
      "1857/1857 [==============================] - 0s 202us/step - loss: 0.6912 - accuracy: 0.8174 - val_loss: 0.6429 - val_accuracy: 0.8465\n",
      "Epoch 28/1000\n",
      "1857/1857 [==============================] - 0s 204us/step - loss: 0.6871 - accuracy: 0.8174 - val_loss: 0.6389 - val_accuracy: 0.8465\n",
      "Epoch 29/1000\n",
      "1857/1857 [==============================] - 0s 200us/step - loss: 0.6832 - accuracy: 0.8174 - val_loss: 0.6354 - val_accuracy: 0.8465\n",
      "Epoch 30/1000\n",
      "1857/1857 [==============================] - 0s 206us/step - loss: 0.6794 - accuracy: 0.8174 - val_loss: 0.6315 - val_accuracy: 0.8465\n",
      "Epoch 31/1000\n",
      "1857/1857 [==============================] - 0s 206us/step - loss: 0.6759 - accuracy: 0.8174 - val_loss: 0.6281 - val_accuracy: 0.8465\n",
      "Epoch 32/1000\n",
      "1857/1857 [==============================] - 0s 203us/step - loss: 0.6729 - accuracy: 0.8174 - val_loss: 0.6250 - val_accuracy: 0.8465\n",
      "Epoch 33/1000\n",
      "1857/1857 [==============================] - 0s 207us/step - loss: 0.6701 - accuracy: 0.8174 - val_loss: 0.6223 - val_accuracy: 0.8465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/1000\n",
      "1857/1857 [==============================] - 0s 206us/step - loss: 0.6676 - accuracy: 0.8174 - val_loss: 0.6200 - val_accuracy: 0.8465\n",
      "Epoch 35/1000\n",
      "1857/1857 [==============================] - 0s 212us/step - loss: 0.6654 - accuracy: 0.8174 - val_loss: 0.6179 - val_accuracy: 0.8465\n",
      "Epoch 36/1000\n",
      "1857/1857 [==============================] - 0s 216us/step - loss: 0.6634 - accuracy: 0.8174 - val_loss: 0.6160 - val_accuracy: 0.8465\n",
      "Epoch 37/1000\n",
      "1857/1857 [==============================] - 0s 197us/step - loss: 0.6617 - accuracy: 0.8174 - val_loss: 0.6142 - val_accuracy: 0.8465\n",
      "Epoch 38/1000\n",
      "1857/1857 [==============================] - 0s 201us/step - loss: 0.6600 - accuracy: 0.8174 - val_loss: 0.6130 - val_accuracy: 0.8465\n",
      "Epoch 39/1000\n",
      "1857/1857 [==============================] - 0s 209us/step - loss: 0.6586 - accuracy: 0.8174 - val_loss: 0.6118 - val_accuracy: 0.8465\n",
      "Epoch 40/1000\n",
      "1857/1857 [==============================] - 0s 208us/step - loss: 0.6573 - accuracy: 0.8174 - val_loss: 0.6108 - val_accuracy: 0.8465\n",
      "Epoch 41/1000\n",
      "1857/1857 [==============================] - 0s 211us/step - loss: 0.6562 - accuracy: 0.8174 - val_loss: 0.6099 - val_accuracy: 0.8465\n",
      "Epoch 42/1000\n",
      "1857/1857 [==============================] - 0s 209us/step - loss: 0.6552 - accuracy: 0.8174 - val_loss: 0.6091 - val_accuracy: 0.8465\n",
      "Epoch 43/1000\n",
      "1857/1857 [==============================] - 0s 203us/step - loss: 0.6542 - accuracy: 0.8174 - val_loss: 0.6085 - val_accuracy: 0.8465\n",
      "Epoch 44/1000\n",
      "1857/1857 [==============================] - 0s 199us/step - loss: 0.6534 - accuracy: 0.8174 - val_loss: 0.6080 - val_accuracy: 0.8465\n",
      "Epoch 45/1000\n",
      "1857/1857 [==============================] - 0s 198us/step - loss: 0.6526 - accuracy: 0.8174 - val_loss: 0.6078 - val_accuracy: 0.8465\n",
      "Epoch 46/1000\n",
      "1857/1857 [==============================] - 0s 207us/step - loss: 0.6520 - accuracy: 0.8174 - val_loss: 0.6082 - val_accuracy: 0.8465\n",
      "Epoch 47/1000\n",
      "1857/1857 [==============================] - 0s 199us/step - loss: 0.6514 - accuracy: 0.8174 - val_loss: 0.6076 - val_accuracy: 0.8465\n",
      "Epoch 48/1000\n",
      "1857/1857 [==============================] - 0s 202us/step - loss: 0.6508 - accuracy: 0.8174 - val_loss: 0.6074 - val_accuracy: 0.8465\n",
      "Epoch 49/1000\n",
      "1857/1857 [==============================] - 0s 199us/step - loss: 0.6503 - accuracy: 0.8174 - val_loss: 0.6072 - val_accuracy: 0.8465\n",
      "Epoch 50/1000\n",
      "1857/1857 [==============================] - 0s 203us/step - loss: 0.6498 - accuracy: 0.8174 - val_loss: 0.6070 - val_accuracy: 0.8465\n",
      "Epoch 51/1000\n",
      "1857/1857 [==============================] - 0s 208us/step - loss: 0.6494 - accuracy: 0.8174 - val_loss: 0.6068 - val_accuracy: 0.8465\n",
      "Epoch 52/1000\n",
      "1857/1857 [==============================] - 0s 209us/step - loss: 0.6491 - accuracy: 0.8174 - val_loss: 0.6068 - val_accuracy: 0.8465\n",
      "Epoch 53/1000\n",
      "1857/1857 [==============================] - 0s 197us/step - loss: 0.6488 - accuracy: 0.8174 - val_loss: 0.6068 - val_accuracy: 0.8465\n",
      "Epoch 54/1000\n",
      "1857/1857 [==============================] - 0s 201us/step - loss: 0.6485 - accuracy: 0.8174 - val_loss: 0.6068 - val_accuracy: 0.8465\n",
      "auc: 0.648989638063705\n",
      "kappa: 0.0\n",
      "layers: 1, nodes: 8\n",
      "Train on 1854 samples, validate on 618 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 1s 536us/step - loss: 0.7393 - accuracy: 0.8047 - val_loss: 0.6103 - val_accuracy: 0.8495\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 0s 208us/step - loss: 0.6748 - accuracy: 0.8177 - val_loss: 0.6123 - val_accuracy: 0.8495\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 0s 204us/step - loss: 0.6560 - accuracy: 0.8177 - val_loss: 0.6070 - val_accuracy: 0.8495\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 0s 205us/step - loss: 0.6481 - accuracy: 0.8177 - val_loss: 0.6011 - val_accuracy: 0.8495\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 0s 207us/step - loss: 0.6434 - accuracy: 0.8177 - val_loss: 0.5945 - val_accuracy: 0.8495\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 0s 201us/step - loss: 0.6389 - accuracy: 0.8177 - val_loss: 0.5976 - val_accuracy: 0.8495\n",
      "Epoch 7/1000\n",
      "1854/1854 [==============================] - 0s 200us/step - loss: 0.6347 - accuracy: 0.8177 - val_loss: 0.5934 - val_accuracy: 0.8495\n",
      "Epoch 8/1000\n",
      "1854/1854 [==============================] - 0s 208us/step - loss: 0.6298 - accuracy: 0.8177 - val_loss: 0.5914 - val_accuracy: 0.8495\n",
      "Epoch 9/1000\n",
      "1854/1854 [==============================] - 0s 203us/step - loss: 0.6238 - accuracy: 0.8177 - val_loss: 0.5958 - val_accuracy: 0.8495\n",
      "Epoch 10/1000\n",
      "1854/1854 [==============================] - 0s 195us/step - loss: 0.6191 - accuracy: 0.8177 - val_loss: 0.5976 - val_accuracy: 0.8495\n",
      "Epoch 11/1000\n",
      "1854/1854 [==============================] - 0s 198us/step - loss: 0.6146 - accuracy: 0.8177 - val_loss: 0.5977 - val_accuracy: 0.8495\n",
      "Train on 1854 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 1s 532us/step - loss: 0.8110 - accuracy: 0.8123 - val_loss: 0.7448 - val_accuracy: 0.8320\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 0s 201us/step - loss: 0.6961 - accuracy: 0.8231 - val_loss: 0.6805 - val_accuracy: 0.8320\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 0s 200us/step - loss: 0.6565 - accuracy: 0.8231 - val_loss: 0.6567 - val_accuracy: 0.8320\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 0s 198us/step - loss: 0.6415 - accuracy: 0.8231 - val_loss: 0.6491 - val_accuracy: 0.8320\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 0s 196us/step - loss: 0.6361 - accuracy: 0.8231 - val_loss: 0.6471 - val_accuracy: 0.8320\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 0s 195us/step - loss: 0.6335 - accuracy: 0.8231 - val_loss: 0.6464 - val_accuracy: 0.8320\n",
      "Epoch 7/1000\n",
      "1854/1854 [==============================] - 0s 199us/step - loss: 0.6326 - accuracy: 0.8231 - val_loss: 0.6474 - val_accuracy: 0.8320\n",
      "Epoch 8/1000\n",
      "1854/1854 [==============================] - 0s 200us/step - loss: 0.6319 - accuracy: 0.8231 - val_loss: 0.6486 - val_accuracy: 0.8320\n",
      "Epoch 9/1000\n",
      "1854/1854 [==============================] - 0s 201us/step - loss: 0.6317 - accuracy: 0.8231 - val_loss: 0.6501 - val_accuracy: 0.8320\n",
      "Train on 1856 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1856/1856 [==============================] - 1s 546us/step - loss: 1.0196 - accuracy: 0.7381 - val_loss: 0.9377 - val_accuracy: 0.8417\n",
      "Epoch 2/1000\n",
      "1856/1856 [==============================] - 0s 197us/step - loss: 0.8340 - accuracy: 0.8195 - val_loss: 0.8184 - val_accuracy: 0.8417\n",
      "Epoch 3/1000\n",
      "1856/1856 [==============================] - 0s 196us/step - loss: 0.7509 - accuracy: 0.8195 - val_loss: 0.7452 - val_accuracy: 0.8417\n",
      "Epoch 4/1000\n",
      "1856/1856 [==============================] - 0s 196us/step - loss: 0.7036 - accuracy: 0.8195 - val_loss: 0.7035 - val_accuracy: 0.8417\n",
      "Epoch 5/1000\n",
      "1856/1856 [==============================] - 0s 202us/step - loss: 0.6761 - accuracy: 0.8195 - val_loss: 0.6672 - val_accuracy: 0.8417\n",
      "Epoch 6/1000\n",
      "1856/1856 [==============================] - 0s 200us/step - loss: 0.6561 - accuracy: 0.8195 - val_loss: 0.6387 - val_accuracy: 0.8417\n",
      "Epoch 7/1000\n",
      "1856/1856 [==============================] - 0s 196us/step - loss: 0.6445 - accuracy: 0.8195 - val_loss: 0.6293 - val_accuracy: 0.8417\n",
      "Epoch 8/1000\n",
      "1856/1856 [==============================] - 0s 197us/step - loss: 0.6417 - accuracy: 0.8195 - val_loss: 0.6275 - val_accuracy: 0.8417\n",
      "Epoch 9/1000\n",
      "1856/1856 [==============================] - 0s 195us/step - loss: 0.6410 - accuracy: 0.8195 - val_loss: 0.6278 - val_accuracy: 0.8417\n",
      "Epoch 10/1000\n",
      "1856/1856 [==============================] - 0s 199us/step - loss: 0.6409 - accuracy: 0.8195 - val_loss: 0.6271 - val_accuracy: 0.8417\n",
      "Epoch 11/1000\n",
      "1856/1856 [==============================] - 0s 202us/step - loss: 0.6407 - accuracy: 0.8195 - val_loss: 0.6275 - val_accuracy: 0.8417\n",
      "Epoch 12/1000\n",
      "1856/1856 [==============================] - 0s 196us/step - loss: 0.6409 - accuracy: 0.8195 - val_loss: 0.6286 - val_accuracy: 0.8417\n",
      "Epoch 13/1000\n",
      "1856/1856 [==============================] - 0s 197us/step - loss: 0.6409 - accuracy: 0.8195 - val_loss: 0.6285 - val_accuracy: 0.8417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 1s 537us/step - loss: 0.6603 - accuracy: 0.8174 - val_loss: 0.6065 - val_accuracy: 0.8465\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 0s 205us/step - loss: 0.6506 - accuracy: 0.8174 - val_loss: 0.6242 - val_accuracy: 0.8465\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 0s 207us/step - loss: 0.6532 - accuracy: 0.8174 - val_loss: 0.6010 - val_accuracy: 0.8465\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 0s 198us/step - loss: 0.6445 - accuracy: 0.8174 - val_loss: 0.6028 - val_accuracy: 0.8465\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 0s 199us/step - loss: 0.6371 - accuracy: 0.8174 - val_loss: 0.6143 - val_accuracy: 0.8465\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 0s 198us/step - loss: 0.6284 - accuracy: 0.8174 - val_loss: 0.6033 - val_accuracy: 0.8465\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 1s 548us/step - loss: 1.0813 - accuracy: 0.7512 - val_loss: 0.9125 - val_accuracy: 0.8481\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 0s 213us/step - loss: 0.8796 - accuracy: 0.8169 - val_loss: 0.7832 - val_accuracy: 0.8481\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 0s 209us/step - loss: 0.7854 - accuracy: 0.8169 - val_loss: 0.7062 - val_accuracy: 0.8481\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 0s 199us/step - loss: 0.7297 - accuracy: 0.8169 - val_loss: 0.6624 - val_accuracy: 0.8481\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 0s 200us/step - loss: 0.6949 - accuracy: 0.8169 - val_loss: 0.6622 - val_accuracy: 0.8481\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 0s 200us/step - loss: 0.6702 - accuracy: 0.8169 - val_loss: 0.6228 - val_accuracy: 0.8481\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 0s 202us/step - loss: 0.6547 - accuracy: 0.8169 - val_loss: 0.6187 - val_accuracy: 0.8481\n",
      "Epoch 8/1000\n",
      "1857/1857 [==============================] - 0s 203us/step - loss: 0.6525 - accuracy: 0.8169 - val_loss: 0.6216 - val_accuracy: 0.8481\n",
      "Epoch 9/1000\n",
      "1857/1857 [==============================] - 0s 203us/step - loss: 0.6474 - accuracy: 0.8169 - val_loss: 0.6113 - val_accuracy: 0.8481\n",
      "Epoch 10/1000\n",
      "1857/1857 [==============================] - 0s 203us/step - loss: 0.6457 - accuracy: 0.8169 - val_loss: 0.6089 - val_accuracy: 0.8481\n",
      "Epoch 11/1000\n",
      "1857/1857 [==============================] - 0s 202us/step - loss: 0.6447 - accuracy: 0.8169 - val_loss: 0.6033 - val_accuracy: 0.8481\n",
      "Epoch 12/1000\n",
      "1857/1857 [==============================] - 0s 205us/step - loss: 0.6435 - accuracy: 0.8169 - val_loss: 0.5979 - val_accuracy: 0.8481\n",
      "Epoch 13/1000\n",
      "1857/1857 [==============================] - 0s 203us/step - loss: 0.6439 - accuracy: 0.8169 - val_loss: 0.6019 - val_accuracy: 0.8481\n",
      "Epoch 14/1000\n",
      "1857/1857 [==============================] - 0s 202us/step - loss: 0.6398 - accuracy: 0.8169 - val_loss: 0.6082 - val_accuracy: 0.8481\n",
      "Epoch 15/1000\n",
      "1857/1857 [==============================] - 0s 202us/step - loss: 0.6386 - accuracy: 0.8169 - val_loss: 0.5969 - val_accuracy: 0.8481\n",
      "Epoch 16/1000\n",
      "1857/1857 [==============================] - 0s 202us/step - loss: 0.6357 - accuracy: 0.8169 - val_loss: 0.5950 - val_accuracy: 0.8481\n",
      "Epoch 17/1000\n",
      "1857/1857 [==============================] - 0s 205us/step - loss: 0.6335 - accuracy: 0.8169 - val_loss: 0.5941 - val_accuracy: 0.8481\n",
      "Epoch 18/1000\n",
      "1857/1857 [==============================] - 0s 204us/step - loss: 0.6303 - accuracy: 0.8169 - val_loss: 0.5994 - val_accuracy: 0.8481\n",
      "Epoch 19/1000\n",
      "1857/1857 [==============================] - 0s 209us/step - loss: 0.6269 - accuracy: 0.8169 - val_loss: 0.5949 - val_accuracy: 0.8481\n",
      "Epoch 20/1000\n",
      "1857/1857 [==============================] - 0s 203us/step - loss: 0.6217 - accuracy: 0.8169 - val_loss: 0.5925 - val_accuracy: 0.8481\n",
      "Epoch 21/1000\n",
      "1857/1857 [==============================] - 0s 200us/step - loss: 0.6202 - accuracy: 0.8169 - val_loss: 0.5945 - val_accuracy: 0.8481\n",
      "Epoch 22/1000\n",
      "1857/1857 [==============================] - 0s 202us/step - loss: 0.6157 - accuracy: 0.8169 - val_loss: 0.5933 - val_accuracy: 0.8481\n",
      "Epoch 23/1000\n",
      "1857/1857 [==============================] - 0s 205us/step - loss: 0.6102 - accuracy: 0.8169 - val_loss: 0.6012 - val_accuracy: 0.8481\n",
      "auc: 0.6014218803224758\n",
      "kappa: 0.0\n",
      "layers: 1, nodes: 16\n",
      "Train on 1854 samples, validate on 618 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 1s 555us/step - loss: 0.7364 - accuracy: 0.8069 - val_loss: 0.6293 - val_accuracy: 0.8398\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 0s 202us/step - loss: 0.6691 - accuracy: 0.8209 - val_loss: 0.6178 - val_accuracy: 0.8398\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 0s 202us/step - loss: 0.6533 - accuracy: 0.8209 - val_loss: 0.6171 - val_accuracy: 0.8398\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 0s 197us/step - loss: 0.6448 - accuracy: 0.8209 - val_loss: 0.6307 - val_accuracy: 0.8398\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 0s 202us/step - loss: 0.6389 - accuracy: 0.8209 - val_loss: 0.6207 - val_accuracy: 0.8398\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 0s 203us/step - loss: 0.6389 - accuracy: 0.8209 - val_loss: 0.6248 - val_accuracy: 0.8398\n",
      "Train on 1854 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 1s 552us/step - loss: 0.7483 - accuracy: 0.7869 - val_loss: 0.5803 - val_accuracy: 0.8546\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 0s 198us/step - loss: 0.6610 - accuracy: 0.8155 - val_loss: 0.5770 - val_accuracy: 0.8546\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 0s 202us/step - loss: 0.6562 - accuracy: 0.8155 - val_loss: 0.5774 - val_accuracy: 0.8546\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 0s 207us/step - loss: 0.6546 - accuracy: 0.8155 - val_loss: 0.5802 - val_accuracy: 0.8546\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 0s 200us/step - loss: 0.6539 - accuracy: 0.8155 - val_loss: 0.5821 - val_accuracy: 0.8546\n",
      "Train on 1856 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1856/1856 [==============================] - 1s 554us/step - loss: 0.7167 - accuracy: 0.8060 - val_loss: 0.6324 - val_accuracy: 0.8336\n",
      "Epoch 2/1000\n",
      "1856/1856 [==============================] - 0s 203us/step - loss: 0.6520 - accuracy: 0.8222 - val_loss: 0.6297 - val_accuracy: 0.8336\n",
      "Epoch 3/1000\n",
      "1856/1856 [==============================] - 0s 202us/step - loss: 0.6413 - accuracy: 0.8222 - val_loss: 0.6307 - val_accuracy: 0.8336\n",
      "Epoch 4/1000\n",
      "1856/1856 [==============================] - 0s 203us/step - loss: 0.6383 - accuracy: 0.8222 - val_loss: 0.6329 - val_accuracy: 0.8336\n",
      "Epoch 5/1000\n",
      "1856/1856 [==============================] - 0s 199us/step - loss: 0.6366 - accuracy: 0.8222 - val_loss: 0.6409 - val_accuracy: 0.8336\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 1s 574us/step - loss: 0.6841 - accuracy: 0.8040 - val_loss: 0.6160 - val_accuracy: 0.8433\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 0s 205us/step - loss: 0.6494 - accuracy: 0.8185 - val_loss: 0.6177 - val_accuracy: 0.8433\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 0s 205us/step - loss: 0.6464 - accuracy: 0.8185 - val_loss: 0.6176 - val_accuracy: 0.8433\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 0s 202us/step - loss: 0.6430 - accuracy: 0.8185 - val_loss: 0.6222 - val_accuracy: 0.8433\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 1s 563us/step - loss: 0.7426 - accuracy: 0.8040 - val_loss: 0.6266 - val_accuracy: 0.8465\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 0s 205us/step - loss: 0.6574 - accuracy: 0.8174 - val_loss: 0.6085 - val_accuracy: 0.8465\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 0s 204us/step - loss: 0.6493 - accuracy: 0.8174 - val_loss: 0.6086 - val_accuracy: 0.8465\n",
      "Epoch 4/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1857/1857 [==============================] - 0s 202us/step - loss: 0.6478 - accuracy: 0.8174 - val_loss: 0.6081 - val_accuracy: 0.8465\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 0s 204us/step - loss: 0.6473 - accuracy: 0.8174 - val_loss: 0.6125 - val_accuracy: 0.8465\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 0s 204us/step - loss: 0.6470 - accuracy: 0.8174 - val_loss: 0.6105 - val_accuracy: 0.8465\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 0s 207us/step - loss: 0.6469 - accuracy: 0.8174 - val_loss: 0.6115 - val_accuracy: 0.8465\n",
      "auc: 0.6464831473914365\n",
      "kappa: 0.0\n",
      "layers: 1, nodes: 32\n",
      "Train on 1854 samples, validate on 618 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 1s 576us/step - loss: 0.7115 - accuracy: 0.8064 - val_loss: 0.6351 - val_accuracy: 0.8414\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 0s 205us/step - loss: 0.6418 - accuracy: 0.8204 - val_loss: 0.6242 - val_accuracy: 0.8414\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 0s 203us/step - loss: 0.6361 - accuracy: 0.8204 - val_loss: 0.6265 - val_accuracy: 0.8414\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 0s 207us/step - loss: 0.6256 - accuracy: 0.8204 - val_loss: 0.6244 - val_accuracy: 0.8414\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 0s 206us/step - loss: 0.6143 - accuracy: 0.8204 - val_loss: 0.6268 - val_accuracy: 0.8414\n",
      "Train on 1854 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 1s 579us/step - loss: 0.6715 - accuracy: 0.8037 - val_loss: 0.5877 - val_accuracy: 0.8562\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 0s 209us/step - loss: 0.6548 - accuracy: 0.8150 - val_loss: 0.5857 - val_accuracy: 0.8562\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 0s 202us/step - loss: 0.6559 - accuracy: 0.8150 - val_loss: 0.5844 - val_accuracy: 0.8562\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 0s 203us/step - loss: 0.6547 - accuracy: 0.8150 - val_loss: 0.5844 - val_accuracy: 0.8562\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 0s 203us/step - loss: 0.6549 - accuracy: 0.8150 - val_loss: 0.5856 - val_accuracy: 0.8562\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 0s 201us/step - loss: 0.6550 - accuracy: 0.8150 - val_loss: 0.5837 - val_accuracy: 0.8562\n",
      "Epoch 7/1000\n",
      "1854/1854 [==============================] - 0s 210us/step - loss: 0.6559 - accuracy: 0.8150 - val_loss: 0.5858 - val_accuracy: 0.8562\n",
      "Epoch 8/1000\n",
      "1854/1854 [==============================] - 0s 205us/step - loss: 0.6550 - accuracy: 0.8150 - val_loss: 0.5838 - val_accuracy: 0.8562\n",
      "Epoch 9/1000\n",
      "1854/1854 [==============================] - 0s 203us/step - loss: 0.6548 - accuracy: 0.8150 - val_loss: 0.5847 - val_accuracy: 0.8562\n",
      "Train on 1856 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1856/1856 [==============================] - 1s 579us/step - loss: 0.6560 - accuracy: 0.8120 - val_loss: 0.6365 - val_accuracy: 0.8320\n",
      "Epoch 2/1000\n",
      "1856/1856 [==============================] - 0s 206us/step - loss: 0.6352 - accuracy: 0.8227 - val_loss: 0.6462 - val_accuracy: 0.8320\n",
      "Epoch 3/1000\n",
      "1856/1856 [==============================] - 0s 203us/step - loss: 0.6351 - accuracy: 0.8227 - val_loss: 0.6439 - val_accuracy: 0.8320\n",
      "Epoch 4/1000\n",
      "1856/1856 [==============================] - 0s 205us/step - loss: 0.6351 - accuracy: 0.8227 - val_loss: 0.6449 - val_accuracy: 0.8320\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 1s 585us/step - loss: 0.6848 - accuracy: 0.8040 - val_loss: 0.5909 - val_accuracy: 0.8481\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 0s 207us/step - loss: 0.6529 - accuracy: 0.8169 - val_loss: 0.5976 - val_accuracy: 0.8481\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 0s 206us/step - loss: 0.6501 - accuracy: 0.8169 - val_loss: 0.5982 - val_accuracy: 0.8481\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 0s 205us/step - loss: 0.6484 - accuracy: 0.8169 - val_loss: 0.5980 - val_accuracy: 0.8481\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 1s 613us/step - loss: 0.7168 - accuracy: 0.8056 - val_loss: 0.6367 - val_accuracy: 0.8401\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 0s 223us/step - loss: 0.6410 - accuracy: 0.8196 - val_loss: 0.6329 - val_accuracy: 0.8401\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 0s 219us/step - loss: 0.6393 - accuracy: 0.8196 - val_loss: 0.6363 - val_accuracy: 0.8401\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 0s 214us/step - loss: 0.6386 - accuracy: 0.8196 - val_loss: 0.6405 - val_accuracy: 0.8401\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 0s 219us/step - loss: 0.6397 - accuracy: 0.8196 - val_loss: 0.6409 - val_accuracy: 0.8401\n",
      "auc: 0.5749338611089073\n",
      "kappa: 0.0\n",
      "layers: 1, nodes: 64\n",
      "Train on 1854 samples, validate on 618 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 1s 612us/step - loss: 0.7453 - accuracy: 0.8053 - val_loss: 0.6224 - val_accuracy: 0.8463\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 0s 227us/step - loss: 0.6643 - accuracy: 0.8188 - val_loss: 0.6128 - val_accuracy: 0.8463\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 0s 227us/step - loss: 0.6460 - accuracy: 0.8188 - val_loss: 0.6228 - val_accuracy: 0.8463\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 0s 229us/step - loss: 0.6434 - accuracy: 0.8188 - val_loss: 0.6258 - val_accuracy: 0.8463\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 0s 223us/step - loss: 0.6420 - accuracy: 0.8188 - val_loss: 0.6218 - val_accuracy: 0.8463\n",
      "Train on 1854 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 1s 622us/step - loss: 0.7435 - accuracy: 0.8091 - val_loss: 0.6432 - val_accuracy: 0.8384\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 0s 220us/step - loss: 0.6397 - accuracy: 0.8209 - val_loss: 0.6356 - val_accuracy: 0.8384\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 0s 226us/step - loss: 0.6388 - accuracy: 0.8209 - val_loss: 0.6382 - val_accuracy: 0.8384\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 0s 218us/step - loss: 0.6396 - accuracy: 0.8209 - val_loss: 0.6340 - val_accuracy: 0.8384\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 0s 220us/step - loss: 0.6395 - accuracy: 0.8209 - val_loss: 0.6287 - val_accuracy: 0.8384\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 0s 217us/step - loss: 0.6385 - accuracy: 0.8209 - val_loss: 0.6382 - val_accuracy: 0.8384\n",
      "Epoch 7/1000\n",
      "1854/1854 [==============================] - 0s 223us/step - loss: 0.6399 - accuracy: 0.8209 - val_loss: 0.6356 - val_accuracy: 0.8384\n",
      "Epoch 8/1000\n",
      "1854/1854 [==============================] - 0s 222us/step - loss: 0.6391 - accuracy: 0.8209 - val_loss: 0.6299 - val_accuracy: 0.8384\n",
      "Train on 1856 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1856/1856 [==============================] - 1s 617us/step - loss: 0.7979 - accuracy: 0.8039 - val_loss: 0.5886 - val_accuracy: 0.8498\n",
      "Epoch 2/1000\n",
      "1856/1856 [==============================] - 0s 220us/step - loss: 0.6559 - accuracy: 0.8168 - val_loss: 0.5980 - val_accuracy: 0.8498\n",
      "Epoch 3/1000\n",
      "1856/1856 [==============================] - 0s 220us/step - loss: 0.6522 - accuracy: 0.8168 - val_loss: 0.5946 - val_accuracy: 0.8498\n",
      "Epoch 4/1000\n",
      "1856/1856 [==============================] - 0s 217us/step - loss: 0.6517 - accuracy: 0.8168 - val_loss: 0.5993 - val_accuracy: 0.8498\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 1s 629us/step - loss: 0.7079 - accuracy: 0.8201 - val_loss: 0.6661 - val_accuracy: 0.8336\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 0s 218us/step - loss: 0.6464 - accuracy: 0.8218 - val_loss: 0.6447 - val_accuracy: 0.8336\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 0s 221us/step - loss: 0.6370 - accuracy: 0.8218 - val_loss: 0.6489 - val_accuracy: 0.8336\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 0s 221us/step - loss: 0.6362 - accuracy: 0.8218 - val_loss: 0.6469 - val_accuracy: 0.8336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 0s 222us/step - loss: 0.6372 - accuracy: 0.8218 - val_loss: 0.6496 - val_accuracy: 0.8336\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 1s 631us/step - loss: 0.7427 - accuracy: 0.8040 - val_loss: 0.6291 - val_accuracy: 0.8498\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 0s 221us/step - loss: 0.6528 - accuracy: 0.8164 - val_loss: 0.6031 - val_accuracy: 0.8498\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 0s 219us/step - loss: 0.6516 - accuracy: 0.8164 - val_loss: 0.6027 - val_accuracy: 0.8498\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 0s 223us/step - loss: 0.6511 - accuracy: 0.8164 - val_loss: 0.5956 - val_accuracy: 0.8498\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 0s 221us/step - loss: 0.6509 - accuracy: 0.8164 - val_loss: 0.6193 - val_accuracy: 0.8498\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 0s 223us/step - loss: 0.6552 - accuracy: 0.8164 - val_loss: 0.6016 - val_accuracy: 0.8498\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 0s 221us/step - loss: 0.6512 - accuracy: 0.8164 - val_loss: 0.5974 - val_accuracy: 0.8498\n",
      "auc: 0.5307065188300318\n",
      "kappa: 0.0\n"
     ]
    }
   ],
   "source": [
    "FOLDS = 5\n",
    "PADDING = 100\n",
    "LAYERS = 1\n",
    "MAX_POWER = 6\n",
    "KERNEL_SIZE = 3\n",
    "POOL_SIZE = 2\n",
    "DROPOUT = 0.25\n",
    "ACTIVATION = 'sigmoid'\n",
    "LAST_ACTIVATION = 'softmax'\n",
    "\n",
    "# Prepare training batches\n",
    "input_data = pk.load(open('input_data3.pkl', 'rb'))\n",
    "target_data = pk.load(open('target_data3.pkl', 'rb'))\n",
    "model_input = []\n",
    "model_target = []\n",
    "for i, t in zip(input_data, target_data):\n",
    "    model_input.append(np.concatenate([np.zeros((PADDING - 1, i.shape[1])), i])[:PADDING,:])\n",
    "    model_target.append(np.argmax(t))\n",
    "model_input = np.array(model_input)\n",
    "model_target = np.array(model_target)\n",
    "\n",
    "#keys, values = np.unique(model_target, return_counts=True)\n",
    "#values = (1 / values) / max((1 / values))\n",
    "#class_weight = dict(zip(keys, values))\n",
    "class_weight = dict(zip(np.arange(target_data[0].size), np.ones((target_data[0].size,))))\n",
    "\n",
    "skf = StratifiedKFold(n_splits=FOLDS, shuffle=True)\n",
    "mms = MinMaxScaler()\n",
    "\n",
    "layers = []\n",
    "dimention = []\n",
    "auc = []\n",
    "kappa = []\n",
    "for lay in range(1,LAYERS+1):\n",
    "    for dim in np.power(2, np.arange(MAX_POWER+1)):\n",
    "        print(f'layers: {lay}, nodes: {dim}')\n",
    "        aucs = []\n",
    "        kappas = []\n",
    "        \n",
    "        # Prepare k-fold training and test sets\n",
    "        for train_index, test_index in skf.split(model_input, model_target):\n",
    "            model_target[train_index.astype(int)]\n",
    "            X_train_raw, X_test_raw = model_input[train_index], model_input[test_index]\n",
    "            y_train_raw, y_test_raw = model_target[train_index], model_target[test_index]\n",
    "            \n",
    "            X_train = np.stack(X_train_raw)\n",
    "            X_test = np.stack(X_test_raw)\n",
    "            \n",
    "            y_train = np.zeros((y_train_raw.size, y_train_raw.max() + 1))\n",
    "            y_train[np.arange(y_train_raw.size),y_train_raw] = 1\n",
    "            y_test = np.zeros((y_test_raw.size, y_test_raw.max() + 1))\n",
    "            y_test[np.arange(y_test_raw.size),y_test_raw] = 1\n",
    "            \n",
    "            # Make the LSTM\n",
    "            model = Sequential()\n",
    "            model.add(Conv1D(filters=dim, kernel_size=KERNEL_SIZE, activation=ACTIVATION, padding='same', input_shape=(PADDING, model_input[0].shape[1])))\n",
    "            for l in range(lay-1):\n",
    "                model.add(Conv1D(filters=dim, kernel_size=KERNEL_SIZE, activation=ACTIVATION, padding='same'))\n",
    "                model.add(Dropout(DROPOUT))\n",
    "                model.add(MaxPooling1D(pool_size=POOL_SIZE))\n",
    "            model.add(Flatten())\n",
    "            model.add(Dense(dim, activation=ACTIVATION))\n",
    "            model.add(Dense(target_data[0].size, activation=LAST_ACTIVATION))\n",
    "            model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "            es = [EarlyStopping(monitor='val_loss', patience=3, min_delta=0, restore_best_weights=True)]\n",
    "            model.fit(X_train, y_train, epochs=1000, validation_split=0.25, callbacks=es, verbose=True)\n",
    "            \n",
    "            # Get the average auc and kappa for all affects and folds\n",
    "            y_pred = model.predict(X_test, batch_size=1)\n",
    "            for y_t, y_p in zip(y_test.T, y_pred.T):\n",
    "                #y_p = mms.fit_transform(y_p.reshape(-1, 1))\n",
    "                aucs.append(roc_auc_score(y_t, y_p))\n",
    "                kappas.append(cohen_kappa_score(y_t, np.around(y_p)))\n",
    "        \n",
    "        layers.append(lay)\n",
    "        dimention.append(dim)\n",
    "        auc.append(np.mean(aucs))\n",
    "        kappa.append(np.mean(kappas))\n",
    "        print(f'auc: {auc[-1]}')\n",
    "        print(f'kappa: {kappa[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "for i in range(LAYERS):\n",
    "    start = int(i*(MAX_POWER+1))\n",
    "    end = int(i*(MAX_POWER+1)+MAX_POWER+1)\n",
    "    plt.plot(dimention[start:end], auc[start:end], marker='.', label=f'{i} Layer LSTM')\n",
    "plt.xlabel('Projected Dimensions')\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.title('1dCNN')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "for i in range(LAYERS):\n",
    "    start = int(i*(MAX_POWER+1))\n",
    "    end = int(i*(MAX_POWER+1)+MAX_POWER+1)\n",
    "    plt.plot(dimention[start:end], kappa[start:end], marker='.', label=f'{i} Layer LSTM')\n",
    "plt.xlabel('1dCNN w/ scaled softmax output')\n",
    "plt.ylabel('Cohen\\'s Kappa')\n",
    "plt.title('1dCNN')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers: 1, nodes: 1\n",
      "Train on 1854 samples, validate on 618 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 1s 617us/step - loss: 1.2635 - accuracy: 0.1230 - val_loss: 1.1997 - val_accuracy: 0.8382\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 0s 204us/step - loss: 1.1365 - accuracy: 0.8215 - val_loss: 1.0835 - val_accuracy: 0.8382\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 0s 208us/step - loss: 1.0353 - accuracy: 0.8215 - val_loss: 0.9881 - val_accuracy: 0.8382\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - ETA: 0s - loss: 0.9558 - accuracy: 0.82 - 0s 213us/step - loss: 0.9526 - accuracy: 0.8215 - val_loss: 0.9115 - val_accuracy: 0.8382\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 0s 204us/step - loss: 0.8856 - accuracy: 0.8215 - val_loss: 0.8494 - val_accuracy: 0.8382\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 0s 204us/step - loss: 0.8320 - accuracy: 0.8215 - val_loss: 0.7989 - val_accuracy: 0.8382\n",
      "Epoch 7/1000\n",
      "1854/1854 [==============================] - 0s 207us/step - loss: 0.7893 - accuracy: 0.8215 - val_loss: 0.7591 - val_accuracy: 0.8382\n",
      "Epoch 8/1000\n",
      "1854/1854 [==============================] - 0s 205us/step - loss: 0.7556 - accuracy: 0.8215 - val_loss: 0.7276 - val_accuracy: 0.8382\n",
      "Epoch 9/1000\n",
      "1854/1854 [==============================] - 0s 209us/step - loss: 0.7293 - accuracy: 0.8215 - val_loss: 0.7031 - val_accuracy: 0.8382\n",
      "Epoch 10/1000\n",
      "1854/1854 [==============================] - 0s 209us/step - loss: 0.7089 - accuracy: 0.8215 - val_loss: 0.6838 - val_accuracy: 0.8382\n",
      "Epoch 11/1000\n",
      "1854/1854 [==============================] - 0s 203us/step - loss: 0.6930 - accuracy: 0.8215 - val_loss: 0.6687 - val_accuracy: 0.8382\n",
      "Epoch 12/1000\n",
      "1854/1854 [==============================] - 0s 207us/step - loss: 0.6808 - accuracy: 0.8215 - val_loss: 0.6573 - val_accuracy: 0.8382\n",
      "Epoch 13/1000\n",
      "1854/1854 [==============================] - 0s 205us/step - loss: 0.6712 - accuracy: 0.8215 - val_loss: 0.6489 - val_accuracy: 0.8382\n",
      "Epoch 14/1000\n",
      "1854/1854 [==============================] - 0s 214us/step - loss: 0.6639 - accuracy: 0.8215 - val_loss: 0.6420 - val_accuracy: 0.8382\n",
      "Epoch 15/1000\n",
      "1854/1854 [==============================] - 0s 209us/step - loss: 0.6581 - accuracy: 0.8215 - val_loss: 0.6368 - val_accuracy: 0.8382\n",
      "Epoch 16/1000\n",
      "1854/1854 [==============================] - 0s 212us/step - loss: 0.6537 - accuracy: 0.8215 - val_loss: 0.6328 - val_accuracy: 0.8382\n",
      "Epoch 17/1000\n",
      "1854/1854 [==============================] - 0s 206us/step - loss: 0.6502 - accuracy: 0.8215 - val_loss: 0.6298 - val_accuracy: 0.8382\n",
      "Epoch 18/1000\n",
      "1854/1854 [==============================] - 0s 205us/step - loss: 0.6475 - accuracy: 0.8215 - val_loss: 0.6278 - val_accuracy: 0.8382\n",
      "Epoch 19/1000\n",
      "1854/1854 [==============================] - 0s 210us/step - loss: 0.6454 - accuracy: 0.8215 - val_loss: 0.6261 - val_accuracy: 0.8382\n",
      "Epoch 20/1000\n",
      "1854/1854 [==============================] - 0s 207us/step - loss: 0.6436 - accuracy: 0.8215 - val_loss: 0.6250 - val_accuracy: 0.8382\n",
      "Epoch 21/1000\n",
      "1854/1854 [==============================] - 0s 205us/step - loss: 0.6423 - accuracy: 0.8215 - val_loss: 0.6243 - val_accuracy: 0.8382\n",
      "Epoch 22/1000\n",
      "1854/1854 [==============================] - 0s 207us/step - loss: 0.6412 - accuracy: 0.8215 - val_loss: 0.6239 - val_accuracy: 0.8382\n",
      "Epoch 23/1000\n",
      "1854/1854 [==============================] - 0s 205us/step - loss: 0.6404 - accuracy: 0.8215 - val_loss: 0.6236 - val_accuracy: 0.8382\n",
      "Epoch 24/1000\n",
      "1854/1854 [==============================] - 0s 205us/step - loss: 0.6396 - accuracy: 0.8215 - val_loss: 0.6236 - val_accuracy: 0.8382\n",
      "Epoch 25/1000\n",
      "1854/1854 [==============================] - 0s 213us/step - loss: 0.6391 - accuracy: 0.8215 - val_loss: 0.6234 - val_accuracy: 0.8382\n",
      "Epoch 26/1000\n",
      "1854/1854 [==============================] - 0s 204us/step - loss: 0.6386 - accuracy: 0.8215 - val_loss: 0.6237 - val_accuracy: 0.8382\n",
      "Epoch 27/1000\n",
      "1854/1854 [==============================] - 0s 205us/step - loss: 0.6381 - accuracy: 0.8215 - val_loss: 0.6240 - val_accuracy: 0.8382\n",
      "Epoch 28/1000\n",
      "1854/1854 [==============================] - 0s 206us/step - loss: 0.6379 - accuracy: 0.8215 - val_loss: 0.6241 - val_accuracy: 0.8382\n",
      "Train on 1854 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 1s 619us/step - loss: 1.3647 - accuracy: 0.0302 - val_loss: 1.2997 - val_accuracy: 0.0662\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 0s 203us/step - loss: 1.2821 - accuracy: 0.7125 - val_loss: 1.2235 - val_accuracy: 0.8368\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 0s 213us/step - loss: 1.2088 - accuracy: 0.8215 - val_loss: 1.1331 - val_accuracy: 0.8368\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 0s 210us/step - loss: 1.1238 - accuracy: 0.8215 - val_loss: 1.0274 - val_accuracy: 0.8368\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 0s 206us/step - loss: 1.0304 - accuracy: 0.8215 - val_loss: 0.9256 - val_accuracy: 0.8368\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 0s 208us/step - loss: 0.9440 - accuracy: 0.8215 - val_loss: 0.8487 - val_accuracy: 0.8368\n",
      "Epoch 7/1000\n",
      "1854/1854 [==============================] - 0s 208us/step - loss: 0.8769 - accuracy: 0.8215 - val_loss: 0.7923 - val_accuracy: 0.8368\n",
      "Epoch 8/1000\n",
      "1854/1854 [==============================] - 0s 206us/step - loss: 0.8264 - accuracy: 0.8215 - val_loss: 0.7514 - val_accuracy: 0.8368\n",
      "Epoch 9/1000\n",
      "1854/1854 [==============================] - 0s 209us/step - loss: 0.7882 - accuracy: 0.8215 - val_loss: 0.7203 - val_accuracy: 0.8368\n",
      "Epoch 10/1000\n",
      "1854/1854 [==============================] - 0s 210us/step - loss: 0.7588 - accuracy: 0.8215 - val_loss: 0.6970 - val_accuracy: 0.8368\n",
      "Epoch 11/1000\n",
      "1854/1854 [==============================] - 0s 204us/step - loss: 0.7358 - accuracy: 0.8215 - val_loss: 0.6792 - val_accuracy: 0.8368\n",
      "Epoch 12/1000\n",
      "1854/1854 [==============================] - 0s 205us/step - loss: 0.7176 - accuracy: 0.8215 - val_loss: 0.6652 - val_accuracy: 0.8368\n",
      "Epoch 13/1000\n",
      "1854/1854 [==============================] - 0s 207us/step - loss: 0.7032 - accuracy: 0.8215 - val_loss: 0.6552 - val_accuracy: 0.8368\n",
      "Epoch 14/1000\n",
      "1854/1854 [==============================] - 0s 208us/step - loss: 0.6916 - accuracy: 0.8215 - val_loss: 0.6466 - val_accuracy: 0.8368\n",
      "Epoch 15/1000\n",
      "1854/1854 [==============================] - 0s 208us/step - loss: 0.6822 - accuracy: 0.8215 - val_loss: 0.6405 - val_accuracy: 0.8368\n",
      "Epoch 16/1000\n",
      "1854/1854 [==============================] - 0s 205us/step - loss: 0.6745 - accuracy: 0.8215 - val_loss: 0.6358 - val_accuracy: 0.8368\n",
      "Epoch 17/1000\n",
      "1854/1854 [==============================] - 0s 203us/step - loss: 0.6683 - accuracy: 0.8215 - val_loss: 0.6321 - val_accuracy: 0.8368\n",
      "Epoch 18/1000\n",
      "1854/1854 [==============================] - 0s 207us/step - loss: 0.6631 - accuracy: 0.8215 - val_loss: 0.6294 - val_accuracy: 0.8368\n",
      "Epoch 19/1000\n",
      "1854/1854 [==============================] - 0s 207us/step - loss: 0.6588 - accuracy: 0.8215 - val_loss: 0.6274 - val_accuracy: 0.8368\n",
      "Epoch 20/1000\n",
      "1854/1854 [==============================] - 0s 208us/step - loss: 0.6552 - accuracy: 0.8215 - val_loss: 0.6261 - val_accuracy: 0.8368\n",
      "Epoch 21/1000\n",
      "1854/1854 [==============================] - 0s 207us/step - loss: 0.6523 - accuracy: 0.8215 - val_loss: 0.6251 - val_accuracy: 0.8368\n",
      "Epoch 22/1000\n",
      "1854/1854 [==============================] - 0s 205us/step - loss: 0.6498 - accuracy: 0.8215 - val_loss: 0.6244 - val_accuracy: 0.8368\n",
      "Epoch 23/1000\n",
      "1854/1854 [==============================] - 0s 204us/step - loss: 0.6476 - accuracy: 0.8215 - val_loss: 0.6240 - val_accuracy: 0.8368\n",
      "Epoch 24/1000\n",
      "1854/1854 [==============================] - 0s 207us/step - loss: 0.6459 - accuracy: 0.8215 - val_loss: 0.6240 - val_accuracy: 0.8368\n",
      "Epoch 25/1000\n",
      "1854/1854 [==============================] - 0s 206us/step - loss: 0.6444 - accuracy: 0.8215 - val_loss: 0.6240 - val_accuracy: 0.8368\n",
      "Epoch 26/1000\n",
      "1854/1854 [==============================] - 0s 204us/step - loss: 0.6431 - accuracy: 0.8215 - val_loss: 0.6245 - val_accuracy: 0.8368\n",
      "Epoch 27/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1854/1854 [==============================] - 0s 204us/step - loss: 0.6420 - accuracy: 0.8215 - val_loss: 0.6248 - val_accuracy: 0.8368\n",
      "Train on 1856 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1856/1856 [==============================] - 1s 623us/step - loss: 1.4418 - accuracy: 0.0566 - val_loss: 1.3495 - val_accuracy: 0.8094\n",
      "Epoch 2/1000\n",
      "1856/1856 [==============================] - 0s 206us/step - loss: 1.3075 - accuracy: 0.8157 - val_loss: 1.2674 - val_accuracy: 0.8514\n",
      "Epoch 3/1000\n",
      "1856/1856 [==============================] - 0s 206us/step - loss: 1.2431 - accuracy: 0.8163 - val_loss: 1.2043 - val_accuracy: 0.8514\n",
      "Epoch 4/1000\n",
      "1856/1856 [==============================] - 0s 210us/step - loss: 1.1876 - accuracy: 0.8163 - val_loss: 1.1485 - val_accuracy: 0.8514\n",
      "Epoch 5/1000\n",
      "1856/1856 [==============================] - 0s 211us/step - loss: 1.1371 - accuracy: 0.8163 - val_loss: 1.0968 - val_accuracy: 0.8514\n",
      "Epoch 6/1000\n",
      "1856/1856 [==============================] - 0s 206us/step - loss: 1.0906 - accuracy: 0.8163 - val_loss: 1.0488 - val_accuracy: 0.8514\n",
      "Epoch 7/1000\n",
      "1856/1856 [==============================] - 0s 206us/step - loss: 1.0480 - accuracy: 0.8163 - val_loss: 1.0044 - val_accuracy: 0.8514\n",
      "Epoch 8/1000\n",
      "1856/1856 [==============================] - 0s 208us/step - loss: 1.0087 - accuracy: 0.8163 - val_loss: 0.9643 - val_accuracy: 0.8514\n",
      "Epoch 9/1000\n",
      "1856/1856 [==============================] - 0s 206us/step - loss: 0.9730 - accuracy: 0.8163 - val_loss: 0.9270 - val_accuracy: 0.8514\n",
      "Epoch 10/1000\n",
      "1856/1856 [==============================] - 0s 211us/step - loss: 0.9403 - accuracy: 0.8163 - val_loss: 0.8934 - val_accuracy: 0.8514\n",
      "Epoch 11/1000\n",
      "1856/1856 [==============================] - 0s 206us/step - loss: 0.9106 - accuracy: 0.8163 - val_loss: 0.8630 - val_accuracy: 0.8514\n",
      "Epoch 12/1000\n",
      "1856/1856 [==============================] - 0s 204us/step - loss: 0.8838 - accuracy: 0.8163 - val_loss: 0.8347 - val_accuracy: 0.8514\n",
      "Epoch 13/1000\n",
      "1856/1856 [==============================] - 0s 209us/step - loss: 0.8595 - accuracy: 0.8163 - val_loss: 0.8091 - val_accuracy: 0.8514\n",
      "Epoch 14/1000\n",
      "1856/1856 [==============================] - 0s 205us/step - loss: 0.8375 - accuracy: 0.8163 - val_loss: 0.7868 - val_accuracy: 0.8514\n",
      "Epoch 15/1000\n",
      "1856/1856 [==============================] - 0s 210us/step - loss: 0.8179 - accuracy: 0.8163 - val_loss: 0.7660 - val_accuracy: 0.8514\n",
      "Epoch 16/1000\n",
      "1856/1856 [==============================] - 0s 208us/step - loss: 0.8002 - accuracy: 0.8163 - val_loss: 0.7471 - val_accuracy: 0.8514\n",
      "Epoch 17/1000\n",
      "1856/1856 [==============================] - 0s 205us/step - loss: 0.7843 - accuracy: 0.8163 - val_loss: 0.7304 - val_accuracy: 0.8514\n",
      "Epoch 18/1000\n",
      "1856/1856 [==============================] - 0s 206us/step - loss: 0.7700 - accuracy: 0.8163 - val_loss: 0.7152 - val_accuracy: 0.8514\n",
      "Epoch 19/1000\n",
      "1856/1856 [==============================] - ETA: 0s - loss: 0.7544 - accuracy: 0.81 - 0s 205us/step - loss: 0.7573 - accuracy: 0.8163 - val_loss: 0.7017 - val_accuracy: 0.8514\n",
      "Epoch 20/1000\n",
      "1856/1856 [==============================] - 0s 212us/step - loss: 0.7460 - accuracy: 0.8163 - val_loss: 0.6896 - val_accuracy: 0.8514\n",
      "Epoch 21/1000\n",
      "1856/1856 [==============================] - 0s 213us/step - loss: 0.7358 - accuracy: 0.8163 - val_loss: 0.6789 - val_accuracy: 0.8514\n",
      "Epoch 22/1000\n",
      "1856/1856 [==============================] - 0s 204us/step - loss: 0.7268 - accuracy: 0.8163 - val_loss: 0.6690 - val_accuracy: 0.8514\n",
      "Epoch 23/1000\n",
      "1856/1856 [==============================] - 0s 206us/step - loss: 0.7186 - accuracy: 0.8163 - val_loss: 0.6604 - val_accuracy: 0.8514\n",
      "Epoch 24/1000\n",
      "1856/1856 [==============================] - 0s 207us/step - loss: 0.7114 - accuracy: 0.8163 - val_loss: 0.6526 - val_accuracy: 0.8514\n",
      "Epoch 25/1000\n",
      "1856/1856 [==============================] - 0s 210us/step - loss: 0.7050 - accuracy: 0.8163 - val_loss: 0.6456 - val_accuracy: 0.8514\n",
      "Epoch 26/1000\n",
      "1856/1856 [==============================] - 0s 207us/step - loss: 0.6992 - accuracy: 0.8163 - val_loss: 0.6395 - val_accuracy: 0.8514\n",
      "Epoch 27/1000\n",
      "1856/1856 [==============================] - 0s 204us/step - loss: 0.6941 - accuracy: 0.8163 - val_loss: 0.6340 - val_accuracy: 0.8514\n",
      "Epoch 28/1000\n",
      "1856/1856 [==============================] - 0s 208us/step - loss: 0.6895 - accuracy: 0.8163 - val_loss: 0.6291 - val_accuracy: 0.8514\n",
      "Epoch 29/1000\n",
      "1856/1856 [==============================] - 0s 208us/step - loss: 0.6855 - accuracy: 0.8163 - val_loss: 0.6247 - val_accuracy: 0.8514\n",
      "Epoch 30/1000\n",
      "1856/1856 [==============================] - 0s 207us/step - loss: 0.6818 - accuracy: 0.8163 - val_loss: 0.6207 - val_accuracy: 0.8514\n",
      "Epoch 31/1000\n",
      "1856/1856 [==============================] - 0s 216us/step - loss: 0.6785 - accuracy: 0.8163 - val_loss: 0.6171 - val_accuracy: 0.8514\n",
      "Epoch 32/1000\n",
      "1856/1856 [==============================] - 0s 205us/step - loss: 0.6756 - accuracy: 0.8163 - val_loss: 0.6143 - val_accuracy: 0.8514\n",
      "Epoch 33/1000\n",
      "1856/1856 [==============================] - 0s 206us/step - loss: 0.6730 - accuracy: 0.8163 - val_loss: 0.6115 - val_accuracy: 0.8514\n",
      "Epoch 34/1000\n",
      "1856/1856 [==============================] - 0s 207us/step - loss: 0.6706 - accuracy: 0.8163 - val_loss: 0.6091 - val_accuracy: 0.8514\n",
      "Epoch 35/1000\n",
      "1856/1856 [==============================] - 0s 206us/step - loss: 0.6685 - accuracy: 0.8163 - val_loss: 0.6070 - val_accuracy: 0.8514\n",
      "Epoch 36/1000\n",
      "1856/1856 [==============================] - 0s 213us/step - loss: 0.6666 - accuracy: 0.8163 - val_loss: 0.6053 - val_accuracy: 0.8514\n",
      "Epoch 37/1000\n",
      "1856/1856 [==============================] - 0s 211us/step - loss: 0.6650 - accuracy: 0.8163 - val_loss: 0.6035 - val_accuracy: 0.8514\n",
      "Epoch 38/1000\n",
      "1856/1856 [==============================] - 0s 205us/step - loss: 0.6635 - accuracy: 0.8163 - val_loss: 0.6019 - val_accuracy: 0.8514\n",
      "Epoch 39/1000\n",
      "1856/1856 [==============================] - 0s 207us/step - loss: 0.6621 - accuracy: 0.8163 - val_loss: 0.6007 - val_accuracy: 0.8514\n",
      "Epoch 40/1000\n",
      "1856/1856 [==============================] - 0s 206us/step - loss: 0.6609 - accuracy: 0.8163 - val_loss: 0.5996 - val_accuracy: 0.8514\n",
      "Epoch 41/1000\n",
      "1856/1856 [==============================] - 0s 211us/step - loss: 0.6598 - accuracy: 0.8163 - val_loss: 0.5989 - val_accuracy: 0.8514\n",
      "Epoch 42/1000\n",
      "1856/1856 [==============================] - 0s 208us/step - loss: 0.6588 - accuracy: 0.8163 - val_loss: 0.5980 - val_accuracy: 0.8514\n",
      "Epoch 43/1000\n",
      "1856/1856 [==============================] - 0s 207us/step - loss: 0.6579 - accuracy: 0.8163 - val_loss: 0.5970 - val_accuracy: 0.8514\n",
      "Epoch 44/1000\n",
      "1856/1856 [==============================] - 0s 210us/step - loss: 0.6571 - accuracy: 0.8163 - val_loss: 0.5967 - val_accuracy: 0.8514\n",
      "Epoch 45/1000\n",
      "1856/1856 [==============================] - 0s 205us/step - loss: 0.6564 - accuracy: 0.8163 - val_loss: 0.5958 - val_accuracy: 0.8514\n",
      "Epoch 46/1000\n",
      "1856/1856 [==============================] - 0s 214us/step - loss: 0.6557 - accuracy: 0.8163 - val_loss: 0.5956 - val_accuracy: 0.8514\n",
      "Epoch 47/1000\n",
      "1856/1856 [==============================] - 0s 208us/step - loss: 0.6552 - accuracy: 0.8163 - val_loss: 0.5953 - val_accuracy: 0.8514\n",
      "Epoch 48/1000\n",
      "1856/1856 [==============================] - 0s 207us/step - loss: 0.6546 - accuracy: 0.8163 - val_loss: 0.5948 - val_accuracy: 0.8514\n",
      "Epoch 49/1000\n",
      "1856/1856 [==============================] - 0s 206us/step - loss: 0.6542 - accuracy: 0.8163 - val_loss: 0.5949 - val_accuracy: 0.8514\n",
      "Epoch 50/1000\n",
      "1856/1856 [==============================] - 0s 206us/step - loss: 0.6537 - accuracy: 0.8163 - val_loss: 0.5944 - val_accuracy: 0.8514\n",
      "Epoch 51/1000\n",
      "1856/1856 [==============================] - 0s 206us/step - loss: 0.6534 - accuracy: 0.8163 - val_loss: 0.5943 - val_accuracy: 0.8514\n",
      "Epoch 52/1000\n",
      "1856/1856 [==============================] - 0s 214us/step - loss: 0.6530 - accuracy: 0.8163 - val_loss: 0.5942 - val_accuracy: 0.8514\n",
      "Epoch 53/1000\n",
      "1856/1856 [==============================] - 0s 206us/step - loss: 0.6527 - accuracy: 0.8163 - val_loss: 0.5943 - val_accuracy: 0.8514\n",
      "Epoch 54/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1856/1856 [==============================] - 0s 206us/step - loss: 0.6524 - accuracy: 0.8163 - val_loss: 0.5942 - val_accuracy: 0.8514\n",
      "Epoch 55/1000\n",
      "1856/1856 [==============================] - 0s 204us/step - loss: 0.6522 - accuracy: 0.8163 - val_loss: 0.5942 - val_accuracy: 0.8514\n",
      "Epoch 56/1000\n",
      "1856/1856 [==============================] - 0s 205us/step - loss: 0.6520 - accuracy: 0.8163 - val_loss: 0.5941 - val_accuracy: 0.8514\n",
      "Epoch 57/1000\n",
      "1856/1856 [==============================] - 0s 207us/step - loss: 0.6518 - accuracy: 0.8163 - val_loss: 0.5942 - val_accuracy: 0.8514\n",
      "Epoch 58/1000\n",
      "1856/1856 [==============================] - 0s 208us/step - loss: 0.6516 - accuracy: 0.8163 - val_loss: 0.5945 - val_accuracy: 0.8514\n",
      "Epoch 59/1000\n",
      "1856/1856 [==============================] - 0s 209us/step - loss: 0.6514 - accuracy: 0.8163 - val_loss: 0.5945 - val_accuracy: 0.8514\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 1s 650us/step - loss: 0.9816 - accuracy: 0.8164 - val_loss: 0.8406 - val_accuracy: 0.8498\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 0s 210us/step - loss: 0.8411 - accuracy: 0.8164 - val_loss: 0.7633 - val_accuracy: 0.8498\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 0s 211us/step - loss: 0.7884 - accuracy: 0.8164 - val_loss: 0.7203 - val_accuracy: 0.8498\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 0s 212us/step - loss: 0.7522 - accuracy: 0.8164 - val_loss: 0.6868 - val_accuracy: 0.8498\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 0s 212us/step - loss: 0.7259 - accuracy: 0.8164 - val_loss: 0.6630 - val_accuracy: 0.8498\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 0s 210us/step - loss: 0.7067 - accuracy: 0.8164 - val_loss: 0.6457 - val_accuracy: 0.8498\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 0s 207us/step - loss: 0.6926 - accuracy: 0.8164 - val_loss: 0.6325 - val_accuracy: 0.8498\n",
      "Epoch 8/1000\n",
      "1857/1857 [==============================] - 0s 208us/step - loss: 0.6820 - accuracy: 0.8164 - val_loss: 0.6231 - val_accuracy: 0.8498\n",
      "Epoch 9/1000\n",
      "1857/1857 [==============================] - 0s 212us/step - loss: 0.6743 - accuracy: 0.8164 - val_loss: 0.6166 - val_accuracy: 0.8498\n",
      "Epoch 10/1000\n",
      "1857/1857 [==============================] - 0s 212us/step - loss: 0.6683 - accuracy: 0.8164 - val_loss: 0.6113 - val_accuracy: 0.8498\n",
      "Epoch 11/1000\n",
      "1857/1857 [==============================] - 0s 215us/step - loss: 0.6639 - accuracy: 0.8164 - val_loss: 0.6079 - val_accuracy: 0.8498\n",
      "Epoch 12/1000\n",
      "1857/1857 [==============================] - 0s 209us/step - loss: 0.6613 - accuracy: 0.8164 - val_loss: 0.6073 - val_accuracy: 0.8498\n",
      "Epoch 13/1000\n",
      "1857/1857 [==============================] - 0s 209us/step - loss: 0.6588 - accuracy: 0.8164 - val_loss: 0.6065 - val_accuracy: 0.8498\n",
      "Epoch 14/1000\n",
      "1857/1857 [==============================] - 0s 209us/step - loss: 0.6566 - accuracy: 0.8164 - val_loss: 0.6049 - val_accuracy: 0.8498\n",
      "Epoch 15/1000\n",
      "1857/1857 [==============================] - 0s 216us/step - loss: 0.6549 - accuracy: 0.8164 - val_loss: 0.6036 - val_accuracy: 0.8498\n",
      "Epoch 16/1000\n",
      "1857/1857 [==============================] - 0s 210us/step - loss: 0.6534 - accuracy: 0.8164 - val_loss: 0.6030 - val_accuracy: 0.8498\n",
      "Epoch 17/1000\n",
      "1857/1857 [==============================] - 0s 209us/step - loss: 0.6524 - accuracy: 0.8164 - val_loss: 0.6027 - val_accuracy: 0.8498\n",
      "Epoch 18/1000\n",
      "1857/1857 [==============================] - 0s 209us/step - loss: 0.6515 - accuracy: 0.8164 - val_loss: 0.6025 - val_accuracy: 0.8498\n",
      "Epoch 19/1000\n",
      "1857/1857 [==============================] - 0s 209us/step - loss: 0.6509 - accuracy: 0.8164 - val_loss: 0.6023 - val_accuracy: 0.8498\n",
      "Epoch 20/1000\n",
      "1857/1857 [==============================] - 0s 220us/step - loss: 0.6504 - accuracy: 0.8164 - val_loss: 0.6021 - val_accuracy: 0.8498\n",
      "Epoch 21/1000\n",
      "1857/1857 [==============================] - 0s 215us/step - loss: 0.6500 - accuracy: 0.8164 - val_loss: 0.6027 - val_accuracy: 0.8498\n",
      "Epoch 22/1000\n",
      "1857/1857 [==============================] - 0s 213us/step - loss: 0.6496 - accuracy: 0.8164 - val_loss: 0.6025 - val_accuracy: 0.8498\n",
      "Epoch 23/1000\n",
      "1857/1857 [==============================] - 0s 218us/step - loss: 0.6493 - accuracy: 0.8164 - val_loss: 0.6031 - val_accuracy: 0.8498\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 1s 639us/step - loss: 1.3910 - accuracy: 0.2838 - val_loss: 1.3279 - val_accuracy: 0.8417\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 0s 214us/step - loss: 1.2977 - accuracy: 0.8191 - val_loss: 1.2593 - val_accuracy: 0.8417\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 0s 209us/step - loss: 1.2365 - accuracy: 0.8191 - val_loss: 1.1994 - val_accuracy: 0.8417\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 0s 211us/step - loss: 1.1811 - accuracy: 0.8191 - val_loss: 1.1443 - val_accuracy: 0.8417\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 0s 211us/step - loss: 1.1301 - accuracy: 0.8191 - val_loss: 1.0928 - val_accuracy: 0.8417\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 0s 211us/step - loss: 1.0831 - accuracy: 0.8191 - val_loss: 1.0457 - val_accuracy: 0.8417\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 0s 216us/step - loss: 1.0412 - accuracy: 0.8191 - val_loss: 1.0042 - val_accuracy: 0.8417\n",
      "Epoch 8/1000\n",
      "1857/1857 [==============================] - 0s 217us/step - loss: 1.0017 - accuracy: 0.8191 - val_loss: 0.9646 - val_accuracy: 0.8417\n",
      "Epoch 9/1000\n",
      "1857/1857 [==============================] - 0s 213us/step - loss: 0.9656 - accuracy: 0.8191 - val_loss: 0.9280 - val_accuracy: 0.8417\n",
      "Epoch 10/1000\n",
      "1857/1857 [==============================] - 0s 212us/step - loss: 0.9325 - accuracy: 0.8191 - val_loss: 0.8948 - val_accuracy: 0.8417\n",
      "Epoch 11/1000\n",
      "1857/1857 [==============================] - 0s 210us/step - loss: 0.9026 - accuracy: 0.8191 - val_loss: 0.8646 - val_accuracy: 0.8417\n",
      "Epoch 12/1000\n",
      "1857/1857 [==============================] - 0s 213us/step - loss: 0.8755 - accuracy: 0.8191 - val_loss: 0.8373 - val_accuracy: 0.8417\n",
      "Epoch 13/1000\n",
      "1857/1857 [==============================] - 0s 216us/step - loss: 0.8510 - accuracy: 0.8191 - val_loss: 0.8129 - val_accuracy: 0.8417\n",
      "Epoch 14/1000\n",
      "1857/1857 [==============================] - 0s 209us/step - loss: 0.8290 - accuracy: 0.8191 - val_loss: 0.7910 - val_accuracy: 0.8417\n",
      "Epoch 15/1000\n",
      "1857/1857 [==============================] - 0s 208us/step - loss: 0.8101 - accuracy: 0.8191 - val_loss: 0.7724 - val_accuracy: 0.8417\n",
      "Epoch 16/1000\n",
      "1857/1857 [==============================] - 0s 209us/step - loss: 0.7932 - accuracy: 0.8191 - val_loss: 0.7555 - val_accuracy: 0.8417\n",
      "Epoch 17/1000\n",
      "1857/1857 [==============================] - 0s 209us/step - loss: 0.7773 - accuracy: 0.8191 - val_loss: 0.7391 - val_accuracy: 0.8417\n",
      "Epoch 18/1000\n",
      "1857/1857 [==============================] - 0s 215us/step - loss: 0.7629 - accuracy: 0.8191 - val_loss: 0.7246 - val_accuracy: 0.8417\n",
      "Epoch 19/1000\n",
      "1857/1857 [==============================] - 0s 207us/step - loss: 0.7501 - accuracy: 0.8191 - val_loss: 0.7118 - val_accuracy: 0.8417\n",
      "Epoch 20/1000\n",
      "1857/1857 [==============================] - 0s 210us/step - loss: 0.7386 - accuracy: 0.8191 - val_loss: 0.7003 - val_accuracy: 0.8417\n",
      "Epoch 21/1000\n",
      "1857/1857 [==============================] - 0s 209us/step - loss: 0.7290 - accuracy: 0.8191 - val_loss: 0.6906 - val_accuracy: 0.8417\n",
      "Epoch 22/1000\n",
      "1857/1857 [==============================] - 0s 208us/step - loss: 0.7199 - accuracy: 0.8191 - val_loss: 0.6815 - val_accuracy: 0.8417\n",
      "Epoch 23/1000\n",
      "1857/1857 [==============================] - 0s 214us/step - loss: 0.7117 - accuracy: 0.8191 - val_loss: 0.6731 - val_accuracy: 0.8417\n",
      "Epoch 24/1000\n",
      "1857/1857 [==============================] - 0s 221us/step - loss: 0.7044 - accuracy: 0.8191 - val_loss: 0.6654 - val_accuracy: 0.8417\n",
      "Epoch 25/1000\n",
      "1857/1857 [==============================] - 0s 216us/step - loss: 0.6978 - accuracy: 0.8191 - val_loss: 0.6590 - val_accuracy: 0.8417\n",
      "Epoch 26/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1857/1857 [==============================] - 0s 213us/step - loss: 0.6921 - accuracy: 0.8191 - val_loss: 0.6528 - val_accuracy: 0.8417\n",
      "Epoch 27/1000\n",
      "1857/1857 [==============================] - 0s 227us/step - loss: 0.6869 - accuracy: 0.8191 - val_loss: 0.6477 - val_accuracy: 0.8417\n",
      "Epoch 28/1000\n",
      "1857/1857 [==============================] - 0s 226us/step - loss: 0.6822 - accuracy: 0.8191 - val_loss: 0.6429 - val_accuracy: 0.8417\n",
      "Epoch 29/1000\n",
      "1857/1857 [==============================] - 0s 216us/step - loss: 0.6780 - accuracy: 0.8191 - val_loss: 0.6384 - val_accuracy: 0.8417\n",
      "Epoch 30/1000\n",
      "1857/1857 [==============================] - 0s 213us/step - loss: 0.6742 - accuracy: 0.8191 - val_loss: 0.6337 - val_accuracy: 0.8417\n",
      "Epoch 31/1000\n",
      "1857/1857 [==============================] - 0s 212us/step - loss: 0.6698 - accuracy: 0.8191 - val_loss: 0.6257 - val_accuracy: 0.8417\n",
      "Epoch 32/1000\n",
      "1857/1857 [==============================] - 0s 211us/step - loss: 0.6617 - accuracy: 0.8191 - val_loss: 0.6109 - val_accuracy: 0.8417\n",
      "Epoch 33/1000\n",
      "1857/1857 [==============================] - 0s 222us/step - loss: 0.6549 - accuracy: 0.8191 - val_loss: 0.6065 - val_accuracy: 0.8417\n",
      "Epoch 34/1000\n",
      "1857/1857 [==============================] - 0s 214us/step - loss: 0.6502 - accuracy: 0.8191 - val_loss: 0.6071 - val_accuracy: 0.8417\n",
      "Epoch 35/1000\n",
      "1857/1857 [==============================] - 0s 216us/step - loss: 0.6478 - accuracy: 0.8191 - val_loss: 0.6070 - val_accuracy: 0.8417\n",
      "Epoch 36/1000\n",
      "1857/1857 [==============================] - 0s 212us/step - loss: 0.6463 - accuracy: 0.8191 - val_loss: 0.6085 - val_accuracy: 0.8417\n",
      "auc: 0.5927865968158643\n",
      "kappa: 0.0\n",
      "layers: 1, nodes: 2\n",
      "Train on 1854 samples, validate on 618 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 1s 657us/step - loss: 1.4285 - accuracy: 0.3209 - val_loss: 1.3305 - val_accuracy: 0.8463\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 0s 221us/step - loss: 1.3014 - accuracy: 0.8188 - val_loss: 1.2643 - val_accuracy: 0.8463\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 0s 222us/step - loss: 1.2417 - accuracy: 0.8188 - val_loss: 1.2050 - val_accuracy: 0.8463\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 0s 213us/step - loss: 1.1872 - accuracy: 0.8188 - val_loss: 1.1496 - val_accuracy: 0.8463\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 0s 211us/step - loss: 1.1368 - accuracy: 0.8188 - val_loss: 1.0985 - val_accuracy: 0.8463\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 0s 214us/step - loss: 1.0901 - accuracy: 0.8188 - val_loss: 1.0517 - val_accuracy: 0.8463\n",
      "Epoch 7/1000\n",
      "1854/1854 [==============================] - 0s 218us/step - loss: 1.0473 - accuracy: 0.8188 - val_loss: 1.0075 - val_accuracy: 0.8463\n",
      "Epoch 8/1000\n",
      "1854/1854 [==============================] - 0s 214us/step - loss: 1.0076 - accuracy: 0.8188 - val_loss: 0.9677 - val_accuracy: 0.8463\n",
      "Epoch 9/1000\n",
      "1854/1854 [==============================] - 0s 217us/step - loss: 0.9714 - accuracy: 0.8188 - val_loss: 0.9313 - val_accuracy: 0.8463\n",
      "Epoch 10/1000\n",
      "1854/1854 [==============================] - 0s 216us/step - loss: 0.9385 - accuracy: 0.8188 - val_loss: 0.8975 - val_accuracy: 0.8463\n",
      "Epoch 11/1000\n",
      "1854/1854 [==============================] - 0s 211us/step - loss: 0.9084 - accuracy: 0.8188 - val_loss: 0.8673 - val_accuracy: 0.8463\n",
      "Epoch 12/1000\n",
      "1854/1854 [==============================] - 0s 214us/step - loss: 0.8811 - accuracy: 0.8188 - val_loss: 0.8398 - val_accuracy: 0.8463\n",
      "Epoch 13/1000\n",
      "1854/1854 [==============================] - 0s 213us/step - loss: 0.8566 - accuracy: 0.8188 - val_loss: 0.8141 - val_accuracy: 0.8463\n",
      "Epoch 14/1000\n",
      "1854/1854 [==============================] - 0s 208us/step - loss: 0.8343 - accuracy: 0.8188 - val_loss: 0.7917 - val_accuracy: 0.8463\n",
      "Epoch 15/1000\n",
      "1854/1854 [==============================] - 0s 208us/step - loss: 0.8142 - accuracy: 0.8188 - val_loss: 0.7716 - val_accuracy: 0.8463\n",
      "Epoch 16/1000\n",
      "1854/1854 [==============================] - 0s 212us/step - loss: 0.7963 - accuracy: 0.8188 - val_loss: 0.7531 - val_accuracy: 0.8463\n",
      "Epoch 17/1000\n",
      "1854/1854 [==============================] - 0s 211us/step - loss: 0.7801 - accuracy: 0.8188 - val_loss: 0.7367 - val_accuracy: 0.8463\n",
      "Epoch 18/1000\n",
      "1854/1854 [==============================] - 0s 213us/step - loss: 0.7657 - accuracy: 0.8188 - val_loss: 0.7219 - val_accuracy: 0.8463\n",
      "Epoch 19/1000\n",
      "1854/1854 [==============================] - 0s 214us/step - loss: 0.7527 - accuracy: 0.8188 - val_loss: 0.7089 - val_accuracy: 0.8463\n",
      "Epoch 20/1000\n",
      "1854/1854 [==============================] - 0s 217us/step - loss: 0.7412 - accuracy: 0.8188 - val_loss: 0.6972 - val_accuracy: 0.8463\n",
      "Epoch 21/1000\n",
      "1854/1854 [==============================] - 0s 214us/step - loss: 0.7308 - accuracy: 0.8188 - val_loss: 0.6866 - val_accuracy: 0.8463\n",
      "Epoch 22/1000\n",
      "1854/1854 [==============================] - 0s 211us/step - loss: 0.7216 - accuracy: 0.8188 - val_loss: 0.6771 - val_accuracy: 0.8463\n",
      "Epoch 23/1000\n",
      "1854/1854 [==============================] - 0s 214us/step - loss: 0.7133 - accuracy: 0.8188 - val_loss: 0.6686 - val_accuracy: 0.8463\n",
      "Epoch 24/1000\n",
      "1854/1854 [==============================] - 0s 212us/step - loss: 0.7058 - accuracy: 0.8188 - val_loss: 0.6615 - val_accuracy: 0.8463\n",
      "Epoch 25/1000\n",
      "1854/1854 [==============================] - 0s 211us/step - loss: 0.6992 - accuracy: 0.8188 - val_loss: 0.6548 - val_accuracy: 0.8463\n",
      "Epoch 26/1000\n",
      "1854/1854 [==============================] - 0s 211us/step - loss: 0.6933 - accuracy: 0.8188 - val_loss: 0.6491 - val_accuracy: 0.8463\n",
      "Epoch 27/1000\n",
      "1854/1854 [==============================] - 0s 210us/step - loss: 0.6880 - accuracy: 0.8188 - val_loss: 0.6438 - val_accuracy: 0.8463\n",
      "Epoch 28/1000\n",
      "1854/1854 [==============================] - ETA: 0s - loss: 0.6808 - accuracy: 0.82 - 0s 212us/step - loss: 0.6833 - accuracy: 0.8188 - val_loss: 0.6393 - val_accuracy: 0.8463\n",
      "Epoch 29/1000\n",
      "1854/1854 [==============================] - 0s 216us/step - loss: 0.6790 - accuracy: 0.8188 - val_loss: 0.6353 - val_accuracy: 0.8463\n",
      "Epoch 30/1000\n",
      "1854/1854 [==============================] - 0s 209us/step - loss: 0.6753 - accuracy: 0.8188 - val_loss: 0.6315 - val_accuracy: 0.8463\n",
      "Epoch 31/1000\n",
      "1854/1854 [==============================] - 0s 210us/step - loss: 0.6718 - accuracy: 0.8188 - val_loss: 0.6285 - val_accuracy: 0.8463\n",
      "Epoch 32/1000\n",
      "1854/1854 [==============================] - 0s 213us/step - loss: 0.6688 - accuracy: 0.8188 - val_loss: 0.6257 - val_accuracy: 0.8463\n",
      "Epoch 33/1000\n",
      "1854/1854 [==============================] - 0s 214us/step - loss: 0.6660 - accuracy: 0.8188 - val_loss: 0.6231 - val_accuracy: 0.8463\n",
      "Epoch 34/1000\n",
      "1854/1854 [==============================] - 0s 219us/step - loss: 0.6635 - accuracy: 0.8188 - val_loss: 0.6212 - val_accuracy: 0.8463\n",
      "Epoch 35/1000\n",
      "1854/1854 [==============================] - 0s 209us/step - loss: 0.6613 - accuracy: 0.8188 - val_loss: 0.6193 - val_accuracy: 0.8463\n",
      "Epoch 36/1000\n",
      "1854/1854 [==============================] - 0s 214us/step - loss: 0.6593 - accuracy: 0.8188 - val_loss: 0.6176 - val_accuracy: 0.8463\n",
      "Epoch 37/1000\n",
      "1854/1854 [==============================] - 0s 211us/step - loss: 0.6575 - accuracy: 0.8188 - val_loss: 0.6164 - val_accuracy: 0.8463\n",
      "Epoch 38/1000\n",
      "1854/1854 [==============================] - 0s 210us/step - loss: 0.6559 - accuracy: 0.8188 - val_loss: 0.6153 - val_accuracy: 0.8463\n",
      "Epoch 39/1000\n",
      "1854/1854 [==============================] - 0s 215us/step - loss: 0.6544 - accuracy: 0.8188 - val_loss: 0.6141 - val_accuracy: 0.8463\n",
      "Epoch 40/1000\n",
      "1854/1854 [==============================] - 0s 215us/step - loss: 0.6531 - accuracy: 0.8188 - val_loss: 0.6133 - val_accuracy: 0.8463\n",
      "Epoch 41/1000\n",
      "1854/1854 [==============================] - 0s 223us/step - loss: 0.6519 - accuracy: 0.8188 - val_loss: 0.6124 - val_accuracy: 0.8463\n",
      "Epoch 42/1000\n",
      "1854/1854 [==============================] - 0s 219us/step - loss: 0.6508 - accuracy: 0.8188 - val_loss: 0.6121 - val_accuracy: 0.8463\n",
      "Epoch 43/1000\n",
      "1854/1854 [==============================] - 0s 221us/step - loss: 0.6499 - accuracy: 0.8188 - val_loss: 0.6116 - val_accuracy: 0.8463\n",
      "Epoch 44/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1854/1854 [==============================] - 0s 225us/step - loss: 0.6490 - accuracy: 0.8188 - val_loss: 0.6111 - val_accuracy: 0.8463\n",
      "Epoch 45/1000\n",
      "1854/1854 [==============================] - 0s 216us/step - loss: 0.6482 - accuracy: 0.8188 - val_loss: 0.6109 - val_accuracy: 0.8463\n",
      "Epoch 46/1000\n",
      "1854/1854 [==============================] - 0s 219us/step - loss: 0.6475 - accuracy: 0.8188 - val_loss: 0.6107 - val_accuracy: 0.8463\n",
      "Epoch 47/1000\n",
      "1854/1854 [==============================] - 0s 221us/step - loss: 0.6468 - accuracy: 0.8188 - val_loss: 0.6105 - val_accuracy: 0.8463\n",
      "Epoch 48/1000\n",
      "1854/1854 [==============================] - 0s 217us/step - loss: 0.6462 - accuracy: 0.8188 - val_loss: 0.6107 - val_accuracy: 0.8463\n",
      "Epoch 49/1000\n",
      "1854/1854 [==============================] - 0s 221us/step - loss: 0.6457 - accuracy: 0.8188 - val_loss: 0.6104 - val_accuracy: 0.8463\n",
      "Epoch 50/1000\n",
      "1854/1854 [==============================] - 0s 217us/step - loss: 0.6452 - accuracy: 0.8188 - val_loss: 0.6104 - val_accuracy: 0.8463\n",
      "Epoch 51/1000\n",
      "1854/1854 [==============================] - 0s 221us/step - loss: 0.6448 - accuracy: 0.8188 - val_loss: 0.6106 - val_accuracy: 0.8463\n",
      "Epoch 52/1000\n",
      "1854/1854 [==============================] - 0s 223us/step - loss: 0.6444 - accuracy: 0.8188 - val_loss: 0.6107 - val_accuracy: 0.8463\n",
      "Epoch 53/1000\n",
      "1854/1854 [==============================] - 0s 225us/step - loss: 0.6441 - accuracy: 0.8188 - val_loss: 0.6108 - val_accuracy: 0.8463\n",
      "Train on 1854 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 1s 661us/step - loss: 1.3672 - accuracy: 0.5297 - val_loss: 1.3207 - val_accuracy: 0.8465\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 0s 217us/step - loss: 1.2944 - accuracy: 0.8182 - val_loss: 1.2569 - val_accuracy: 0.8465\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 0s 223us/step - loss: 1.2362 - accuracy: 0.8182 - val_loss: 1.1978 - val_accuracy: 0.8465\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 0s 218us/step - loss: 1.1808 - accuracy: 0.8182 - val_loss: 1.1312 - val_accuracy: 0.8465\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 0s 225us/step - loss: 1.0644 - accuracy: 0.8182 - val_loss: 0.9312 - val_accuracy: 0.8465\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 0s 218us/step - loss: 0.9291 - accuracy: 0.8182 - val_loss: 0.8305 - val_accuracy: 0.8465\n",
      "Epoch 7/1000\n",
      "1854/1854 [==============================] - 0s 216us/step - loss: 0.8532 - accuracy: 0.8182 - val_loss: 0.7681 - val_accuracy: 0.8465\n",
      "Epoch 8/1000\n",
      "1854/1854 [==============================] - 0s 230us/step - loss: 0.8029 - accuracy: 0.8182 - val_loss: 0.7254 - val_accuracy: 0.8465\n",
      "Epoch 9/1000\n",
      "1854/1854 [==============================] - 0s 217us/step - loss: 0.7671 - accuracy: 0.8182 - val_loss: 0.6945 - val_accuracy: 0.8465\n",
      "Epoch 10/1000\n",
      "1854/1854 [==============================] - 0s 214us/step - loss: 0.7408 - accuracy: 0.8182 - val_loss: 0.6705 - val_accuracy: 0.8465\n",
      "Epoch 11/1000\n",
      "1854/1854 [==============================] - 0s 212us/step - loss: 0.7210 - accuracy: 0.8182 - val_loss: 0.6528 - val_accuracy: 0.8465\n",
      "Epoch 12/1000\n",
      "1854/1854 [==============================] - 0s 211us/step - loss: 0.7060 - accuracy: 0.8182 - val_loss: 0.6398 - val_accuracy: 0.8465\n",
      "Epoch 13/1000\n",
      "1854/1854 [==============================] - 0s 218us/step - loss: 0.6944 - accuracy: 0.8182 - val_loss: 0.6290 - val_accuracy: 0.8465\n",
      "Epoch 14/1000\n",
      "1854/1854 [==============================] - 0s 216us/step - loss: 0.6853 - accuracy: 0.8182 - val_loss: 0.6217 - val_accuracy: 0.8465\n",
      "Epoch 15/1000\n",
      "1854/1854 [==============================] - 0s 214us/step - loss: 0.6782 - accuracy: 0.8182 - val_loss: 0.6154 - val_accuracy: 0.8465\n",
      "Epoch 16/1000\n",
      "1854/1854 [==============================] - 0s 215us/step - loss: 0.6724 - accuracy: 0.8182 - val_loss: 0.6110 - val_accuracy: 0.8465\n",
      "Epoch 17/1000\n",
      "1854/1854 [==============================] - 0s 211us/step - loss: 0.6677 - accuracy: 0.8182 - val_loss: 0.6075 - val_accuracy: 0.8465\n",
      "Epoch 18/1000\n",
      "1854/1854 [==============================] - 0s 216us/step - loss: 0.6640 - accuracy: 0.8182 - val_loss: 0.6048 - val_accuracy: 0.8465\n",
      "Epoch 19/1000\n",
      "1854/1854 [==============================] - 0s 226us/step - loss: 0.6610 - accuracy: 0.8182 - val_loss: 0.6028 - val_accuracy: 0.8465\n",
      "Epoch 20/1000\n",
      "1854/1854 [==============================] - 0s 215us/step - loss: 0.6585 - accuracy: 0.8182 - val_loss: 0.6009 - val_accuracy: 0.8465\n",
      "Epoch 21/1000\n",
      "1854/1854 [==============================] - 0s 214us/step - loss: 0.6565 - accuracy: 0.8182 - val_loss: 0.5999 - val_accuracy: 0.8465\n",
      "Epoch 22/1000\n",
      "1854/1854 [==============================] - 0s 217us/step - loss: 0.6548 - accuracy: 0.8182 - val_loss: 0.5990 - val_accuracy: 0.8465\n",
      "Epoch 23/1000\n",
      "1854/1854 [==============================] - 0s 215us/step - loss: 0.6534 - accuracy: 0.8182 - val_loss: 0.5986 - val_accuracy: 0.8465\n",
      "Epoch 24/1000\n",
      "1854/1854 [==============================] - 0s 219us/step - loss: 0.6523 - accuracy: 0.8182 - val_loss: 0.5984 - val_accuracy: 0.8465\n",
      "Epoch 25/1000\n",
      "1854/1854 [==============================] - 0s 218us/step - loss: 0.6512 - accuracy: 0.8182 - val_loss: 0.5979 - val_accuracy: 0.8465\n",
      "Epoch 26/1000\n",
      "1854/1854 [==============================] - 0s 215us/step - loss: 0.6505 - accuracy: 0.8182 - val_loss: 0.5980 - val_accuracy: 0.8465\n",
      "Epoch 27/1000\n",
      "1854/1854 [==============================] - 0s 215us/step - loss: 0.6498 - accuracy: 0.8182 - val_loss: 0.5980 - val_accuracy: 0.8465\n",
      "Epoch 28/1000\n",
      "1854/1854 [==============================] - 0s 211us/step - loss: 0.6492 - accuracy: 0.8182 - val_loss: 0.5983 - val_accuracy: 0.8465\n",
      "Train on 1856 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1856/1856 [==============================] - 1s 675us/step - loss: 1.4907 - accuracy: 0.1374 - val_loss: 1.3378 - val_accuracy: 0.8336\n",
      "Epoch 2/1000\n",
      "1856/1856 [==============================] - 0s 225us/step - loss: 1.3062 - accuracy: 0.8222 - val_loss: 1.2683 - val_accuracy: 0.8336\n",
      "Epoch 3/1000\n",
      "1856/1856 [==============================] - 0s 223us/step - loss: 1.2440 - accuracy: 0.8222 - val_loss: 1.2087 - val_accuracy: 0.8336\n",
      "Epoch 4/1000\n",
      "1856/1856 [==============================] - 0s 222us/step - loss: 1.1885 - accuracy: 0.8222 - val_loss: 1.1552 - val_accuracy: 0.8336\n",
      "Epoch 5/1000\n",
      "1856/1856 [==============================] - 0s 222us/step - loss: 1.1377 - accuracy: 0.8222 - val_loss: 1.1053 - val_accuracy: 0.8336\n",
      "Epoch 6/1000\n",
      "1856/1856 [==============================] - 0s 220us/step - loss: 1.0908 - accuracy: 0.8222 - val_loss: 1.0589 - val_accuracy: 0.8336\n",
      "Epoch 7/1000\n",
      "1856/1856 [==============================] - 0s 211us/step - loss: 1.0475 - accuracy: 0.8222 - val_loss: 1.0169 - val_accuracy: 0.8336\n",
      "Epoch 8/1000\n",
      "1856/1856 [==============================] - 0s 221us/step - loss: 1.0078 - accuracy: 0.8222 - val_loss: 0.9780 - val_accuracy: 0.8336\n",
      "Epoch 9/1000\n",
      "1856/1856 [==============================] - 0s 229us/step - loss: 0.9713 - accuracy: 0.8222 - val_loss: 0.9424 - val_accuracy: 0.8336\n",
      "Epoch 10/1000\n",
      "1856/1856 [==============================] - 0s 232us/step - loss: 0.9381 - accuracy: 0.8222 - val_loss: 0.9097 - val_accuracy: 0.8336\n",
      "Epoch 11/1000\n",
      "1856/1856 [==============================] - 0s 220us/step - loss: 0.9077 - accuracy: 0.8222 - val_loss: 0.8806 - val_accuracy: 0.8336\n",
      "Epoch 12/1000\n",
      "1856/1856 [==============================] - 0s 229us/step - loss: 0.8803 - accuracy: 0.8222 - val_loss: 0.8535 - val_accuracy: 0.8336\n",
      "Epoch 13/1000\n",
      "1856/1856 [==============================] - 0s 242us/step - loss: 0.8554 - accuracy: 0.8222 - val_loss: 0.8297 - val_accuracy: 0.8336\n",
      "Epoch 14/1000\n",
      "1856/1856 [==============================] - 0s 222us/step - loss: 0.8329 - accuracy: 0.8222 - val_loss: 0.8079 - val_accuracy: 0.8336\n",
      "Epoch 15/1000\n",
      "1856/1856 [==============================] - 0s 226us/step - loss: 0.8127 - accuracy: 0.8222 - val_loss: 0.7880 - val_accuracy: 0.8336\n",
      "Epoch 16/1000\n",
      "1856/1856 [==============================] - 0s 222us/step - loss: 0.7944 - accuracy: 0.8222 - val_loss: 0.7705 - val_accuracy: 0.8336\n",
      "Epoch 17/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1856/1856 [==============================] - 0s 232us/step - loss: 0.7780 - accuracy: 0.8222 - val_loss: 0.7548 - val_accuracy: 0.8336\n",
      "Epoch 18/1000\n",
      "1856/1856 [==============================] - 0s 218us/step - loss: 0.7633 - accuracy: 0.8222 - val_loss: 0.7408 - val_accuracy: 0.8336\n",
      "Epoch 19/1000\n",
      "1856/1856 [==============================] - 0s 212us/step - loss: 0.7501 - accuracy: 0.8222 - val_loss: 0.7281 - val_accuracy: 0.8336\n",
      "Epoch 20/1000\n",
      "1856/1856 [==============================] - 0s 215us/step - loss: 0.7383 - accuracy: 0.8222 - val_loss: 0.7168 - val_accuracy: 0.8336\n",
      "Epoch 21/1000\n",
      "1856/1856 [==============================] - 0s 212us/step - loss: 0.7277 - accuracy: 0.8222 - val_loss: 0.7069 - val_accuracy: 0.8336\n",
      "Epoch 22/1000\n",
      "1856/1856 [==============================] - 0s 211us/step - loss: 0.7182 - accuracy: 0.8222 - val_loss: 0.6978 - val_accuracy: 0.8336\n",
      "Epoch 23/1000\n",
      "1856/1856 [==============================] - 0s 212us/step - loss: 0.7097 - accuracy: 0.8222 - val_loss: 0.6901 - val_accuracy: 0.8336\n",
      "Epoch 24/1000\n",
      "1856/1856 [==============================] - 0s 210us/step - loss: 0.7022 - accuracy: 0.8222 - val_loss: 0.6829 - val_accuracy: 0.8336\n",
      "Epoch 25/1000\n",
      "1856/1856 [==============================] - 0s 213us/step - loss: 0.6953 - accuracy: 0.8222 - val_loss: 0.6767 - val_accuracy: 0.8336\n",
      "Epoch 26/1000\n",
      "1856/1856 [==============================] - 0s 211us/step - loss: 0.6892 - accuracy: 0.8222 - val_loss: 0.6714 - val_accuracy: 0.8336\n",
      "Epoch 27/1000\n",
      "1856/1856 [==============================] - 0s 211us/step - loss: 0.6838 - accuracy: 0.8222 - val_loss: 0.6662 - val_accuracy: 0.8336\n",
      "Epoch 28/1000\n",
      "1856/1856 [==============================] - 0s 212us/step - loss: 0.6789 - accuracy: 0.8222 - val_loss: 0.6619 - val_accuracy: 0.8336\n",
      "Epoch 29/1000\n",
      "1856/1856 [==============================] - 0s 211us/step - loss: 0.6745 - accuracy: 0.8222 - val_loss: 0.6582 - val_accuracy: 0.8336\n",
      "Epoch 30/1000\n",
      "1856/1856 [==============================] - 0s 215us/step - loss: 0.6706 - accuracy: 0.8222 - val_loss: 0.6548 - val_accuracy: 0.8336\n",
      "Epoch 31/1000\n",
      "1856/1856 [==============================] - 0s 211us/step - loss: 0.6670 - accuracy: 0.8222 - val_loss: 0.6517 - val_accuracy: 0.8336\n",
      "Epoch 32/1000\n",
      "1856/1856 [==============================] - 0s 211us/step - loss: 0.6638 - accuracy: 0.8222 - val_loss: 0.6492 - val_accuracy: 0.8336\n",
      "Epoch 33/1000\n",
      "1856/1856 [==============================] - 0s 212us/step - loss: 0.6610 - accuracy: 0.8222 - val_loss: 0.6472 - val_accuracy: 0.8336\n",
      "Epoch 34/1000\n",
      "1856/1856 [==============================] - 0s 210us/step - loss: 0.6584 - accuracy: 0.8222 - val_loss: 0.6449 - val_accuracy: 0.8336\n",
      "Epoch 35/1000\n",
      "1856/1856 [==============================] - 0s 214us/step - loss: 0.6561 - accuracy: 0.8222 - val_loss: 0.6434 - val_accuracy: 0.8336\n",
      "Epoch 36/1000\n",
      "1856/1856 [==============================] - 0s 212us/step - loss: 0.6540 - accuracy: 0.8222 - val_loss: 0.6419 - val_accuracy: 0.8336\n",
      "Epoch 37/1000\n",
      "1856/1856 [==============================] - 0s 210us/step - loss: 0.6521 - accuracy: 0.8222 - val_loss: 0.6406 - val_accuracy: 0.8336\n",
      "Epoch 38/1000\n",
      "1856/1856 [==============================] - 0s 212us/step - loss: 0.6504 - accuracy: 0.8222 - val_loss: 0.6395 - val_accuracy: 0.8336\n",
      "Epoch 39/1000\n",
      "1856/1856 [==============================] - 0s 212us/step - loss: 0.6489 - accuracy: 0.8222 - val_loss: 0.6387 - val_accuracy: 0.8336\n",
      "Epoch 40/1000\n",
      "1856/1856 [==============================] - 0s 214us/step - loss: 0.6475 - accuracy: 0.8222 - val_loss: 0.6378 - val_accuracy: 0.8336\n",
      "Epoch 41/1000\n",
      "1856/1856 [==============================] - 0s 213us/step - loss: 0.6463 - accuracy: 0.8222 - val_loss: 0.6371 - val_accuracy: 0.8336\n",
      "Epoch 42/1000\n",
      "1856/1856 [==============================] - 0s 211us/step - loss: 0.6451 - accuracy: 0.8222 - val_loss: 0.6366 - val_accuracy: 0.8336\n",
      "Epoch 43/1000\n",
      "1856/1856 [==============================] - 0s 212us/step - loss: 0.6442 - accuracy: 0.8222 - val_loss: 0.6363 - val_accuracy: 0.8336\n",
      "Epoch 44/1000\n",
      "1856/1856 [==============================] - 0s 211us/step - loss: 0.6432 - accuracy: 0.8222 - val_loss: 0.6359 - val_accuracy: 0.8336\n",
      "Epoch 45/1000\n",
      "1856/1856 [==============================] - 0s 213us/step - loss: 0.6424 - accuracy: 0.8222 - val_loss: 0.6356 - val_accuracy: 0.8336\n",
      "Epoch 46/1000\n",
      "1856/1856 [==============================] - 0s 216us/step - loss: 0.6416 - accuracy: 0.8222 - val_loss: 0.6354 - val_accuracy: 0.8336\n",
      "Epoch 47/1000\n",
      "1856/1856 [==============================] - 0s 210us/step - loss: 0.6409 - accuracy: 0.8222 - val_loss: 0.6352 - val_accuracy: 0.8336\n",
      "Epoch 48/1000\n",
      "1856/1856 [==============================] - 0s 212us/step - loss: 0.6403 - accuracy: 0.8222 - val_loss: 0.6353 - val_accuracy: 0.8336\n",
      "Epoch 49/1000\n",
      "1856/1856 [==============================] - 0s 213us/step - loss: 0.6397 - accuracy: 0.8222 - val_loss: 0.6353 - val_accuracy: 0.8336\n",
      "Epoch 50/1000\n",
      "1856/1856 [==============================] - 0s 212us/step - loss: 0.6392 - accuracy: 0.8222 - val_loss: 0.6354 - val_accuracy: 0.8336\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 1s 656us/step - loss: 1.4317 - accuracy: 0.2881 - val_loss: 1.3326 - val_accuracy: 0.8498\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 0s 217us/step - loss: 1.3026 - accuracy: 0.8164 - val_loss: 1.2621 - val_accuracy: 0.8498\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 0s 213us/step - loss: 1.2410 - accuracy: 0.8164 - val_loss: 1.2005 - val_accuracy: 0.8498\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 0s 214us/step - loss: 1.1855 - accuracy: 0.8164 - val_loss: 1.1441 - val_accuracy: 0.8498\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 0s 215us/step - loss: 1.1346 - accuracy: 0.8164 - val_loss: 1.0919 - val_accuracy: 0.8498\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 0s 216us/step - loss: 1.0876 - accuracy: 0.8164 - val_loss: 1.0439 - val_accuracy: 0.8498\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 0s 219us/step - loss: 1.0458 - accuracy: 0.8164 - val_loss: 1.0012 - val_accuracy: 0.8498\n",
      "Epoch 8/1000\n",
      "1857/1857 [==============================] - 0s 216us/step - loss: 1.0064 - accuracy: 0.8164 - val_loss: 0.9605 - val_accuracy: 0.8498\n",
      "Epoch 9/1000\n",
      "1857/1857 [==============================] - 0s 214us/step - loss: 0.9703 - accuracy: 0.8164 - val_loss: 0.9235 - val_accuracy: 0.8498\n",
      "Epoch 10/1000\n",
      "1857/1857 [==============================] - 0s 216us/step - loss: 0.9386 - accuracy: 0.8164 - val_loss: 0.8910 - val_accuracy: 0.8498\n",
      "Epoch 11/1000\n",
      "1857/1857 [==============================] - 0s 215us/step - loss: 0.9090 - accuracy: 0.8164 - val_loss: 0.8599 - val_accuracy: 0.8498\n",
      "Epoch 12/1000\n",
      "1857/1857 [==============================] - 0s 220us/step - loss: 0.8819 - accuracy: 0.8164 - val_loss: 0.8321 - val_accuracy: 0.8498\n",
      "Epoch 13/1000\n",
      "1857/1857 [==============================] - 0s 213us/step - loss: 0.8575 - accuracy: 0.8164 - val_loss: 0.8064 - val_accuracy: 0.8498\n",
      "Epoch 14/1000\n",
      "1857/1857 [==============================] - 0s 218us/step - loss: 0.8363 - accuracy: 0.8164 - val_loss: 0.7851 - val_accuracy: 0.8498\n",
      "Epoch 15/1000\n",
      "1857/1857 [==============================] - 0s 216us/step - loss: 0.8166 - accuracy: 0.8164 - val_loss: 0.7642 - val_accuracy: 0.8498\n",
      "Epoch 16/1000\n",
      "1857/1857 [==============================] - 0s 218us/step - loss: 0.7996 - accuracy: 0.8164 - val_loss: 0.7465 - val_accuracy: 0.8498\n",
      "Epoch 17/1000\n",
      "1857/1857 [==============================] - 0s 218us/step - loss: 0.7836 - accuracy: 0.8164 - val_loss: 0.7298 - val_accuracy: 0.8498\n",
      "Epoch 18/1000\n",
      "1857/1857 [==============================] - 0s 212us/step - loss: 0.7693 - accuracy: 0.8164 - val_loss: 0.7146 - val_accuracy: 0.8498\n",
      "Epoch 19/1000\n",
      "1857/1857 [==============================] - 0s 214us/step - loss: 0.7565 - accuracy: 0.8164 - val_loss: 0.7010 - val_accuracy: 0.8498\n",
      "Epoch 20/1000\n",
      "1857/1857 [==============================] - 0s 215us/step - loss: 0.7450 - accuracy: 0.8164 - val_loss: 0.6889 - val_accuracy: 0.8498\n",
      "Epoch 21/1000\n",
      "1857/1857 [==============================] - 0s 217us/step - loss: 0.7348 - accuracy: 0.8164 - val_loss: 0.6779 - val_accuracy: 0.8498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/1000\n",
      "1857/1857 [==============================] - 0s 215us/step - loss: 0.7257 - accuracy: 0.8164 - val_loss: 0.6683 - val_accuracy: 0.8498\n",
      "Epoch 23/1000\n",
      "1857/1857 [==============================] - 0s 213us/step - loss: 0.7176 - accuracy: 0.8164 - val_loss: 0.6596 - val_accuracy: 0.8498\n",
      "Epoch 24/1000\n",
      "1857/1857 [==============================] - 0s 216us/step - loss: 0.7108 - accuracy: 0.8164 - val_loss: 0.6527 - val_accuracy: 0.8498\n",
      "Epoch 25/1000\n",
      "1857/1857 [==============================] - 0s 213us/step - loss: 0.7044 - accuracy: 0.8164 - val_loss: 0.6455 - val_accuracy: 0.8498\n",
      "Epoch 26/1000\n",
      "1857/1857 [==============================] - 0s 215us/step - loss: 0.6986 - accuracy: 0.8164 - val_loss: 0.6391 - val_accuracy: 0.8498\n",
      "Epoch 27/1000\n",
      "1857/1857 [==============================] - 0s 218us/step - loss: 0.6934 - accuracy: 0.8164 - val_loss: 0.6336 - val_accuracy: 0.8498\n",
      "Epoch 28/1000\n",
      "1857/1857 [==============================] - 0s 212us/step - loss: 0.6888 - accuracy: 0.8164 - val_loss: 0.6286 - val_accuracy: 0.8498\n",
      "Epoch 29/1000\n",
      "1857/1857 [==============================] - 0s 215us/step - loss: 0.6848 - accuracy: 0.8164 - val_loss: 0.6240 - val_accuracy: 0.8498\n",
      "Epoch 30/1000\n",
      "1857/1857 [==============================] - 0s 215us/step - loss: 0.6811 - accuracy: 0.8164 - val_loss: 0.6201 - val_accuracy: 0.8498\n",
      "Epoch 31/1000\n",
      "1857/1857 [==============================] - 0s 221us/step - loss: 0.6779 - accuracy: 0.8164 - val_loss: 0.6165 - val_accuracy: 0.8498\n",
      "Epoch 32/1000\n",
      "1857/1857 [==============================] - 0s 219us/step - loss: 0.6753 - accuracy: 0.8164 - val_loss: 0.6144 - val_accuracy: 0.8498\n",
      "Epoch 33/1000\n",
      "1857/1857 [==============================] - 0s 214us/step - loss: 0.6731 - accuracy: 0.8164 - val_loss: 0.6122 - val_accuracy: 0.8498\n",
      "Epoch 34/1000\n",
      "1857/1857 [==============================] - 0s 215us/step - loss: 0.6708 - accuracy: 0.8164 - val_loss: 0.6096 - val_accuracy: 0.8498\n",
      "Epoch 35/1000\n",
      "1857/1857 [==============================] - 0s 213us/step - loss: 0.6687 - accuracy: 0.8164 - val_loss: 0.6073 - val_accuracy: 0.8498\n",
      "Epoch 36/1000\n",
      "1857/1857 [==============================] - 0s 218us/step - loss: 0.6668 - accuracy: 0.8164 - val_loss: 0.6054 - val_accuracy: 0.8498\n",
      "Epoch 37/1000\n",
      "1857/1857 [==============================] - 0s 219us/step - loss: 0.6651 - accuracy: 0.8164 - val_loss: 0.6035 - val_accuracy: 0.8498\n",
      "Epoch 38/1000\n",
      "1857/1857 [==============================] - 0s 214us/step - loss: 0.6636 - accuracy: 0.8164 - val_loss: 0.6019 - val_accuracy: 0.8498\n",
      "Epoch 39/1000\n",
      "1857/1857 [==============================] - 0s 216us/step - loss: 0.6623 - accuracy: 0.8164 - val_loss: 0.6006 - val_accuracy: 0.8498\n",
      "Epoch 40/1000\n",
      "1857/1857 [==============================] - 0s 214us/step - loss: 0.6611 - accuracy: 0.8164 - val_loss: 0.5995 - val_accuracy: 0.8498\n",
      "Epoch 41/1000\n",
      "1857/1857 [==============================] - 0s 217us/step - loss: 0.6601 - accuracy: 0.8164 - val_loss: 0.5992 - val_accuracy: 0.8498\n",
      "Epoch 42/1000\n",
      "1857/1857 [==============================] - 0s 220us/step - loss: 0.6592 - accuracy: 0.8164 - val_loss: 0.5988 - val_accuracy: 0.8498\n",
      "Epoch 43/1000\n",
      "1857/1857 [==============================] - 0s 214us/step - loss: 0.6583 - accuracy: 0.8164 - val_loss: 0.5978 - val_accuracy: 0.8498\n",
      "Epoch 44/1000\n",
      "1857/1857 [==============================] - 0s 216us/step - loss: 0.6574 - accuracy: 0.8164 - val_loss: 0.5969 - val_accuracy: 0.8498\n",
      "Epoch 45/1000\n",
      "1857/1857 [==============================] - 0s 214us/step - loss: 0.6567 - accuracy: 0.8164 - val_loss: 0.5962 - val_accuracy: 0.8498\n",
      "Epoch 46/1000\n",
      "1857/1857 [==============================] - 0s 220us/step - loss: 0.6561 - accuracy: 0.8164 - val_loss: 0.5957 - val_accuracy: 0.8498\n",
      "Epoch 47/1000\n",
      "1857/1857 [==============================] - 0s 219us/step - loss: 0.6555 - accuracy: 0.8164 - val_loss: 0.5952 - val_accuracy: 0.8498\n",
      "Epoch 48/1000\n",
      "1857/1857 [==============================] - 0s 213us/step - loss: 0.6550 - accuracy: 0.8164 - val_loss: 0.5948 - val_accuracy: 0.8498\n",
      "Epoch 49/1000\n",
      "1857/1857 [==============================] - 0s 215us/step - loss: 0.6545 - accuracy: 0.8164 - val_loss: 0.5945 - val_accuracy: 0.8498\n",
      "Epoch 50/1000\n",
      "1857/1857 [==============================] - 0s 214us/step - loss: 0.6543 - accuracy: 0.8164 - val_loss: 0.5947 - val_accuracy: 0.8498\n",
      "Epoch 51/1000\n",
      "1857/1857 [==============================] - 0s 221us/step - loss: 0.6540 - accuracy: 0.8164 - val_loss: 0.5950 - val_accuracy: 0.8498\n",
      "Epoch 52/1000\n",
      "1857/1857 [==============================] - 0s 218us/step - loss: 0.6536 - accuracy: 0.8164 - val_loss: 0.5949 - val_accuracy: 0.8498\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 1s 664us/step - loss: 1.4969 - accuracy: 0.1826 - val_loss: 1.3438 - val_accuracy: 0.8417\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 0s 213us/step - loss: 1.3065 - accuracy: 0.8191 - val_loss: 1.2697 - val_accuracy: 0.8417\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 0s 216us/step - loss: 1.2430 - accuracy: 0.8191 - val_loss: 1.2080 - val_accuracy: 0.8417\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 0s 216us/step - loss: 1.1866 - accuracy: 0.8191 - val_loss: 1.1527 - val_accuracy: 0.8417\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 0s 214us/step - loss: 1.1351 - accuracy: 0.8191 - val_loss: 1.1011 - val_accuracy: 0.8417\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 0s 214us/step - loss: 1.0876 - accuracy: 0.8191 - val_loss: 1.0537 - val_accuracy: 0.8417\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 0s 211us/step - loss: 1.0439 - accuracy: 0.8191 - val_loss: 1.0097 - val_accuracy: 0.8417\n",
      "Epoch 8/1000\n",
      "1857/1857 [==============================] - 0s 214us/step - loss: 1.0038 - accuracy: 0.8191 - val_loss: 0.9696 - val_accuracy: 0.8417\n",
      "Epoch 9/1000\n",
      "1857/1857 [==============================] - 0s 218us/step - loss: 0.9671 - accuracy: 0.8191 - val_loss: 0.9333 - val_accuracy: 0.8417\n",
      "Epoch 10/1000\n",
      "1857/1857 [==============================] - 0s 217us/step - loss: 0.9338 - accuracy: 0.8191 - val_loss: 0.8998 - val_accuracy: 0.8417\n",
      "Epoch 11/1000\n",
      "1857/1857 [==============================] - 0s 218us/step - loss: 0.9035 - accuracy: 0.8191 - val_loss: 0.8695 - val_accuracy: 0.8417\n",
      "Epoch 12/1000\n",
      "1857/1857 [==============================] - 0s 214us/step - loss: 0.8760 - accuracy: 0.8191 - val_loss: 0.8420 - val_accuracy: 0.8417\n",
      "Epoch 13/1000\n",
      "1857/1857 [==============================] - 0s 214us/step - loss: 0.8513 - accuracy: 0.8191 - val_loss: 0.8171 - val_accuracy: 0.8417\n",
      "Epoch 14/1000\n",
      "1857/1857 [==============================] - 0s 219us/step - loss: 0.8290 - accuracy: 0.8191 - val_loss: 0.7949 - val_accuracy: 0.8417\n",
      "Epoch 15/1000\n",
      "1857/1857 [==============================] - 0s 217us/step - loss: 0.8089 - accuracy: 0.8191 - val_loss: 0.7748 - val_accuracy: 0.8417\n",
      "Epoch 16/1000\n",
      "1857/1857 [==============================] - 0s 214us/step - loss: 0.7910 - accuracy: 0.8191 - val_loss: 0.7567 - val_accuracy: 0.8417\n",
      "Epoch 17/1000\n",
      "1857/1857 [==============================] - 0s 213us/step - loss: 0.7756 - accuracy: 0.8191 - val_loss: 0.7421 - val_accuracy: 0.8417\n",
      "Epoch 18/1000\n",
      "1857/1857 [==============================] - 0s 214us/step - loss: 0.7613 - accuracy: 0.8191 - val_loss: 0.7276 - val_accuracy: 0.8417\n",
      "Epoch 19/1000\n",
      "1857/1857 [==============================] - 0s 219us/step - loss: 0.7484 - accuracy: 0.8191 - val_loss: 0.7145 - val_accuracy: 0.8417\n",
      "Epoch 20/1000\n",
      "1857/1857 [==============================] - 0s 216us/step - loss: 0.7376 - accuracy: 0.8191 - val_loss: 0.7040 - val_accuracy: 0.8417\n",
      "Epoch 21/1000\n",
      "1857/1857 [==============================] - 0s 214us/step - loss: 0.7279 - accuracy: 0.8191 - val_loss: 0.6949 - val_accuracy: 0.8417\n",
      "Epoch 22/1000\n",
      "1857/1857 [==============================] - 0s 215us/step - loss: 0.7188 - accuracy: 0.8191 - val_loss: 0.6853 - val_accuracy: 0.8417\n",
      "Epoch 23/1000\n",
      "1857/1857 [==============================] - 0s 213us/step - loss: 0.7104 - accuracy: 0.8191 - val_loss: 0.6772 - val_accuracy: 0.8417\n",
      "Epoch 24/1000\n",
      "1857/1857 [==============================] - 0s 218us/step - loss: 0.7030 - accuracy: 0.8191 - val_loss: 0.6699 - val_accuracy: 0.8417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/1000\n",
      "1857/1857 [==============================] - 0s 216us/step - loss: 0.6963 - accuracy: 0.8191 - val_loss: 0.6633 - val_accuracy: 0.8417\n",
      "Epoch 26/1000\n",
      "1857/1857 [==============================] - 0s 216us/step - loss: 0.6905 - accuracy: 0.8191 - val_loss: 0.6575 - val_accuracy: 0.8417\n",
      "Epoch 27/1000\n",
      "1857/1857 [==============================] - 0s 213us/step - loss: 0.6852 - accuracy: 0.8191 - val_loss: 0.6522 - val_accuracy: 0.8417\n",
      "Epoch 28/1000\n",
      "1857/1857 [==============================] - 0s 214us/step - loss: 0.6811 - accuracy: 0.8191 - val_loss: 0.6484 - val_accuracy: 0.8417\n",
      "Epoch 29/1000\n",
      "1857/1857 [==============================] - 0s 214us/step - loss: 0.6771 - accuracy: 0.8191 - val_loss: 0.6442 - val_accuracy: 0.8417\n",
      "Epoch 30/1000\n",
      "1857/1857 [==============================] - 0s 221us/step - loss: 0.6733 - accuracy: 0.8191 - val_loss: 0.6407 - val_accuracy: 0.8417\n",
      "Epoch 31/1000\n",
      "1857/1857 [==============================] - 0s 214us/step - loss: 0.6699 - accuracy: 0.8191 - val_loss: 0.6375 - val_accuracy: 0.8417\n",
      "Epoch 32/1000\n",
      "1857/1857 [==============================] - 0s 213us/step - loss: 0.6671 - accuracy: 0.8191 - val_loss: 0.6356 - val_accuracy: 0.8417\n",
      "Epoch 33/1000\n",
      "1857/1857 [==============================] - 0s 215us/step - loss: 0.6645 - accuracy: 0.8191 - val_loss: 0.6330 - val_accuracy: 0.8417\n",
      "Epoch 34/1000\n",
      "1857/1857 [==============================] - 0s 217us/step - loss: 0.6621 - accuracy: 0.8191 - val_loss: 0.6308 - val_accuracy: 0.8417\n",
      "Epoch 35/1000\n",
      "1857/1857 [==============================] - 0s 218us/step - loss: 0.6599 - accuracy: 0.8191 - val_loss: 0.6290 - val_accuracy: 0.8417\n",
      "Epoch 36/1000\n",
      "1857/1857 [==============================] - 0s 214us/step - loss: 0.6579 - accuracy: 0.8191 - val_loss: 0.6273 - val_accuracy: 0.8417\n",
      "Epoch 37/1000\n",
      "1857/1857 [==============================] - 0s 212us/step - loss: 0.6562 - accuracy: 0.8191 - val_loss: 0.6259 - val_accuracy: 0.8417\n",
      "Epoch 38/1000\n",
      "1857/1857 [==============================] - 0s 213us/step - loss: 0.6546 - accuracy: 0.8191 - val_loss: 0.6247 - val_accuracy: 0.8417\n",
      "Epoch 39/1000\n",
      "1857/1857 [==============================] - 0s 213us/step - loss: 0.6532 - accuracy: 0.8191 - val_loss: 0.6237 - val_accuracy: 0.8417\n",
      "Epoch 40/1000\n",
      "1857/1857 [==============================] - 0s 222us/step - loss: 0.6520 - accuracy: 0.8191 - val_loss: 0.6236 - val_accuracy: 0.8417\n",
      "Epoch 41/1000\n",
      "1857/1857 [==============================] - 0s 213us/step - loss: 0.6513 - accuracy: 0.8191 - val_loss: 0.6228 - val_accuracy: 0.8417\n",
      "Epoch 42/1000\n",
      "1857/1857 [==============================] - 0s 212us/step - loss: 0.6504 - accuracy: 0.8191 - val_loss: 0.6228 - val_accuracy: 0.8417\n",
      "Epoch 43/1000\n",
      "1857/1857 [==============================] - 0s 213us/step - loss: 0.6495 - accuracy: 0.8191 - val_loss: 0.6221 - val_accuracy: 0.8417\n",
      "Epoch 44/1000\n",
      "1857/1857 [==============================] - 0s 214us/step - loss: 0.6486 - accuracy: 0.8191 - val_loss: 0.6215 - val_accuracy: 0.8417\n",
      "Epoch 45/1000\n",
      "1857/1857 [==============================] - 0s 215us/step - loss: 0.6478 - accuracy: 0.8191 - val_loss: 0.6212 - val_accuracy: 0.8417\n",
      "Epoch 46/1000\n",
      "1857/1857 [==============================] - 0s 216us/step - loss: 0.6471 - accuracy: 0.8191 - val_loss: 0.6207 - val_accuracy: 0.8417\n",
      "Epoch 47/1000\n",
      "1857/1857 [==============================] - 0s 214us/step - loss: 0.6465 - accuracy: 0.8191 - val_loss: 0.6206 - val_accuracy: 0.8417\n",
      "Epoch 48/1000\n",
      "1857/1857 [==============================] - 0s 215us/step - loss: 0.6459 - accuracy: 0.8191 - val_loss: 0.6209 - val_accuracy: 0.8417\n",
      "Epoch 49/1000\n",
      "1857/1857 [==============================] - 0s 214us/step - loss: 0.6454 - accuracy: 0.8191 - val_loss: 0.6208 - val_accuracy: 0.8417\n",
      "Epoch 50/1000\n",
      "1857/1857 [==============================] - 0s 215us/step - loss: 0.6452 - accuracy: 0.8191 - val_loss: 0.6211 - val_accuracy: 0.8417\n",
      "auc: 0.5519982096654641\n",
      "kappa: 0.0\n",
      "layers: 1, nodes: 4\n",
      "Train on 1854 samples, validate on 618 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 1s 667us/step - loss: 1.1716 - accuracy: 0.4768 - val_loss: 1.0625 - val_accuracy: 0.8350\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 0s 211us/step - loss: 1.0276 - accuracy: 0.8225 - val_loss: 0.9765 - val_accuracy: 0.8350\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 0s 212us/step - loss: 0.9104 - accuracy: 0.8225 - val_loss: 0.8315 - val_accuracy: 0.8350\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 0s 211us/step - loss: 0.8029 - accuracy: 0.8225 - val_loss: 0.7582 - val_accuracy: 0.8350\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 0s 216us/step - loss: 0.7458 - accuracy: 0.8225 - val_loss: 0.7157 - val_accuracy: 0.8350\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 0s 214us/step - loss: 0.7105 - accuracy: 0.8225 - val_loss: 0.6897 - val_accuracy: 0.8350\n",
      "Epoch 7/1000\n",
      "1854/1854 [==============================] - 0s 215us/step - loss: 0.6873 - accuracy: 0.8225 - val_loss: 0.6738 - val_accuracy: 0.8350\n",
      "Epoch 8/1000\n",
      "1854/1854 [==============================] - 0s 214us/step - loss: 0.6719 - accuracy: 0.8225 - val_loss: 0.6629 - val_accuracy: 0.8350\n",
      "Epoch 9/1000\n",
      "1854/1854 [==============================] - 0s 211us/step - loss: 0.6611 - accuracy: 0.8225 - val_loss: 0.6560 - val_accuracy: 0.8350\n",
      "Epoch 10/1000\n",
      "1854/1854 [==============================] - 0s 216us/step - loss: 0.6535 - accuracy: 0.8225 - val_loss: 0.6513 - val_accuracy: 0.8350\n",
      "Epoch 11/1000\n",
      "1854/1854 [==============================] - 0s 213us/step - loss: 0.6480 - accuracy: 0.8225 - val_loss: 0.6487 - val_accuracy: 0.8350\n",
      "Epoch 12/1000\n",
      "1854/1854 [==============================] - 0s 213us/step - loss: 0.6442 - accuracy: 0.8225 - val_loss: 0.6464 - val_accuracy: 0.8350\n",
      "Epoch 13/1000\n",
      "1854/1854 [==============================] - 0s 212us/step - loss: 0.6411 - accuracy: 0.8225 - val_loss: 0.6460 - val_accuracy: 0.8350\n",
      "Epoch 14/1000\n",
      "1854/1854 [==============================] - 0s 211us/step - loss: 0.6390 - accuracy: 0.8225 - val_loss: 0.6455 - val_accuracy: 0.8350\n",
      "Epoch 15/1000\n",
      "1854/1854 [==============================] - 0s 215us/step - loss: 0.6373 - accuracy: 0.8225 - val_loss: 0.6447 - val_accuracy: 0.8350\n",
      "Epoch 16/1000\n",
      "1854/1854 [==============================] - 0s 216us/step - loss: 0.6361 - accuracy: 0.8225 - val_loss: 0.6449 - val_accuracy: 0.8350\n",
      "Epoch 17/1000\n",
      "1854/1854 [==============================] - 0s 213us/step - loss: 0.6352 - accuracy: 0.8225 - val_loss: 0.6445 - val_accuracy: 0.8350\n",
      "Epoch 18/1000\n",
      "1854/1854 [==============================] - 0s 215us/step - loss: 0.6344 - accuracy: 0.8225 - val_loss: 0.6450 - val_accuracy: 0.8350\n",
      "Epoch 19/1000\n",
      "1854/1854 [==============================] - 0s 212us/step - loss: 0.6340 - accuracy: 0.8225 - val_loss: 0.6448 - val_accuracy: 0.8350\n",
      "Epoch 20/1000\n",
      "1854/1854 [==============================] - 0s 220us/step - loss: 0.6336 - accuracy: 0.8225 - val_loss: 0.6456 - val_accuracy: 0.8350\n",
      "Train on 1854 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 1s 668us/step - loss: 1.1290 - accuracy: 0.7314 - val_loss: 0.9692 - val_accuracy: 0.8514\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 0s 215us/step - loss: 0.9322 - accuracy: 0.8166 - val_loss: 0.8472 - val_accuracy: 0.8514\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 0s 213us/step - loss: 0.8373 - accuracy: 0.8166 - val_loss: 0.7605 - val_accuracy: 0.8514\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 0s 214us/step - loss: 0.7737 - accuracy: 0.8166 - val_loss: 0.7030 - val_accuracy: 0.8514\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 0s 223us/step - loss: 0.7318 - accuracy: 0.8166 - val_loss: 0.6646 - val_accuracy: 0.8514\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 0s 212us/step - loss: 0.7046 - accuracy: 0.8166 - val_loss: 0.6386 - val_accuracy: 0.8514\n",
      "Epoch 7/1000\n",
      "1854/1854 [==============================] - 0s 214us/step - loss: 0.6867 - accuracy: 0.8166 - val_loss: 0.6223 - val_accuracy: 0.8514\n",
      "Epoch 8/1000\n",
      "1854/1854 [==============================] - 0s 214us/step - loss: 0.6749 - accuracy: 0.8166 - val_loss: 0.6110 - val_accuracy: 0.8514\n",
      "Epoch 9/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1854/1854 [==============================] - 0s 215us/step - loss: 0.6671 - accuracy: 0.8166 - val_loss: 0.6036 - val_accuracy: 0.8514\n",
      "Epoch 10/1000\n",
      "1854/1854 [==============================] - 0s 219us/step - loss: 0.6619 - accuracy: 0.8166 - val_loss: 0.5983 - val_accuracy: 0.8514\n",
      "Epoch 11/1000\n",
      "1854/1854 [==============================] - 0s 217us/step - loss: 0.6582 - accuracy: 0.8166 - val_loss: 0.5955 - val_accuracy: 0.8514\n",
      "Epoch 12/1000\n",
      "1854/1854 [==============================] - 0s 214us/step - loss: 0.6557 - accuracy: 0.8166 - val_loss: 0.5938 - val_accuracy: 0.8514\n",
      "Epoch 13/1000\n",
      "1854/1854 [==============================] - 0s 211us/step - loss: 0.6539 - accuracy: 0.8166 - val_loss: 0.5925 - val_accuracy: 0.8514\n",
      "Epoch 14/1000\n",
      "1854/1854 [==============================] - 0s 215us/step - loss: 0.6526 - accuracy: 0.8166 - val_loss: 0.5924 - val_accuracy: 0.8514\n",
      "Epoch 15/1000\n",
      "1854/1854 [==============================] - 0s 215us/step - loss: 0.6517 - accuracy: 0.8166 - val_loss: 0.5922 - val_accuracy: 0.8514\n",
      "Epoch 16/1000\n",
      "1854/1854 [==============================] - 0s 216us/step - loss: 0.6510 - accuracy: 0.8166 - val_loss: 0.5921 - val_accuracy: 0.8514\n",
      "Epoch 17/1000\n",
      "1854/1854 [==============================] - 0s 212us/step - loss: 0.6504 - accuracy: 0.8166 - val_loss: 0.5923 - val_accuracy: 0.8514\n",
      "Epoch 18/1000\n",
      "1854/1854 [==============================] - 0s 214us/step - loss: 0.6500 - accuracy: 0.8166 - val_loss: 0.5932 - val_accuracy: 0.8514\n",
      "Epoch 19/1000\n",
      "1854/1854 [==============================] - 0s 214us/step - loss: 0.6497 - accuracy: 0.8166 - val_loss: 0.5933 - val_accuracy: 0.8514\n",
      "Train on 1856 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1856/1856 [==============================] - 1s 681us/step - loss: 1.4100 - accuracy: 0.5162 - val_loss: 1.3238 - val_accuracy: 0.8530\n",
      "Epoch 2/1000\n",
      "1856/1856 [==============================] - 0s 213us/step - loss: 1.2972 - accuracy: 0.8157 - val_loss: 1.2594 - val_accuracy: 0.8530\n",
      "Epoch 3/1000\n",
      "1856/1856 [==============================] - 0s 213us/step - loss: 1.2392 - accuracy: 0.8157 - val_loss: 1.2003 - val_accuracy: 0.8530\n",
      "Epoch 4/1000\n",
      "1856/1856 [==============================] - 0s 214us/step - loss: 1.1855 - accuracy: 0.8157 - val_loss: 1.1445 - val_accuracy: 0.8530\n",
      "Epoch 5/1000\n",
      "1856/1856 [==============================] - 0s 217us/step - loss: 1.1357 - accuracy: 0.8157 - val_loss: 1.0929 - val_accuracy: 0.8530\n",
      "Epoch 6/1000\n",
      "1856/1856 [==============================] - 0s 219us/step - loss: 1.0894 - accuracy: 0.8157 - val_loss: 1.0456 - val_accuracy: 0.8530\n",
      "Epoch 7/1000\n",
      "1856/1856 [==============================] - 0s 215us/step - loss: 1.0470 - accuracy: 0.8157 - val_loss: 1.0012 - val_accuracy: 0.8530\n",
      "Epoch 8/1000\n",
      "1856/1856 [==============================] - 0s 214us/step - loss: 1.0078 - accuracy: 0.8157 - val_loss: 0.9607 - val_accuracy: 0.8530\n",
      "Epoch 9/1000\n",
      "1856/1856 [==============================] - 0s 213us/step - loss: 0.9721 - accuracy: 0.8157 - val_loss: 0.9234 - val_accuracy: 0.8530\n",
      "Epoch 10/1000\n",
      "1856/1856 [==============================] - 0s 216us/step - loss: 0.9394 - accuracy: 0.8157 - val_loss: 0.8898 - val_accuracy: 0.8530\n",
      "Epoch 11/1000\n",
      "1856/1856 [==============================] - 0s 219us/step - loss: 0.9098 - accuracy: 0.8157 - val_loss: 0.8586 - val_accuracy: 0.8530\n",
      "Epoch 12/1000\n",
      "1856/1856 [==============================] - 0s 213us/step - loss: 0.8830 - accuracy: 0.8157 - val_loss: 0.8305 - val_accuracy: 0.8530\n",
      "Epoch 13/1000\n",
      "1856/1856 [==============================] - 0s 217us/step - loss: 0.8587 - accuracy: 0.8157 - val_loss: 0.8056 - val_accuracy: 0.8530\n",
      "Epoch 14/1000\n",
      "1856/1856 [==============================] - 0s 214us/step - loss: 0.8370 - accuracy: 0.8157 - val_loss: 0.7824 - val_accuracy: 0.8530\n",
      "Epoch 15/1000\n",
      "1856/1856 [==============================] - 0s 218us/step - loss: 0.8173 - accuracy: 0.8157 - val_loss: 0.7618 - val_accuracy: 0.8530\n",
      "Epoch 16/1000\n",
      "1856/1856 [==============================] - 0s 222us/step - loss: 0.7997 - accuracy: 0.8157 - val_loss: 0.7428 - val_accuracy: 0.8530\n",
      "Epoch 17/1000\n",
      "1856/1856 [==============================] - 0s 212us/step - loss: 0.7838 - accuracy: 0.8157 - val_loss: 0.7262 - val_accuracy: 0.8530\n",
      "Epoch 18/1000\n",
      "1856/1856 [==============================] - 0s 215us/step - loss: 0.7697 - accuracy: 0.8157 - val_loss: 0.7110 - val_accuracy: 0.8530\n",
      "Epoch 19/1000\n",
      "1856/1856 [==============================] - 0s 213us/step - loss: 0.7570 - accuracy: 0.8157 - val_loss: 0.6978 - val_accuracy: 0.8530\n",
      "Epoch 20/1000\n",
      "1856/1856 [==============================] - 0s 214us/step - loss: 0.7458 - accuracy: 0.8157 - val_loss: 0.6854 - val_accuracy: 0.8530\n",
      "Epoch 21/1000\n",
      "1856/1856 [==============================] - 0s 217us/step - loss: 0.7357 - accuracy: 0.8157 - val_loss: 0.6746 - val_accuracy: 0.8530\n",
      "Epoch 22/1000\n",
      "1856/1856 [==============================] - 0s 214us/step - loss: 0.7267 - accuracy: 0.8157 - val_loss: 0.6647 - val_accuracy: 0.8530\n",
      "Epoch 23/1000\n",
      "1856/1856 [==============================] - 0s 217us/step - loss: 0.7187 - accuracy: 0.8157 - val_loss: 0.6562 - val_accuracy: 0.8530\n",
      "Epoch 24/1000\n",
      "1856/1856 [==============================] - 0s 213us/step - loss: 0.7115 - accuracy: 0.8157 - val_loss: 0.6485 - val_accuracy: 0.8530\n",
      "Epoch 25/1000\n",
      "1856/1856 [==============================] - 0s 217us/step - loss: 0.7052 - accuracy: 0.8157 - val_loss: 0.6417 - val_accuracy: 0.8530\n",
      "Epoch 26/1000\n",
      "1856/1856 [==============================] - 0s 215us/step - loss: 0.6995 - accuracy: 0.8157 - val_loss: 0.6353 - val_accuracy: 0.8530\n",
      "Epoch 27/1000\n",
      "1856/1856 [==============================] - 0s 214us/step - loss: 0.6944 - accuracy: 0.8157 - val_loss: 0.6301 - val_accuracy: 0.8530\n",
      "Epoch 28/1000\n",
      "1856/1856 [==============================] - 0s 216us/step - loss: 0.6898 - accuracy: 0.8157 - val_loss: 0.6251 - val_accuracy: 0.8530\n",
      "Epoch 29/1000\n",
      "1856/1856 [==============================] - 0s 215us/step - loss: 0.6858 - accuracy: 0.8157 - val_loss: 0.6207 - val_accuracy: 0.8530\n",
      "Epoch 30/1000\n",
      "1856/1856 [==============================] - 0s 219us/step - loss: 0.6822 - accuracy: 0.8157 - val_loss: 0.6167 - val_accuracy: 0.8530\n",
      "Epoch 31/1000\n",
      "1856/1856 [==============================] - 0s 223us/step - loss: 0.6789 - accuracy: 0.8157 - val_loss: 0.6132 - val_accuracy: 0.8530\n",
      "Epoch 32/1000\n",
      "1856/1856 [==============================] - 0s 213us/step - loss: 0.6761 - accuracy: 0.8157 - val_loss: 0.6104 - val_accuracy: 0.8530\n",
      "Epoch 33/1000\n",
      "1856/1856 [==============================] - 0s 216us/step - loss: 0.6735 - accuracy: 0.8157 - val_loss: 0.6078 - val_accuracy: 0.8530\n",
      "Epoch 34/1000\n",
      "1856/1856 [==============================] - 0s 214us/step - loss: 0.6711 - accuracy: 0.8157 - val_loss: 0.6054 - val_accuracy: 0.8530\n",
      "Epoch 35/1000\n",
      "1856/1856 [==============================] - 0s 215us/step - loss: 0.6691 - accuracy: 0.8157 - val_loss: 0.6031 - val_accuracy: 0.8530\n",
      "Epoch 36/1000\n",
      "1856/1856 [==============================] - 0s 215us/step - loss: 0.6672 - accuracy: 0.8157 - val_loss: 0.6014 - val_accuracy: 0.8530\n",
      "Epoch 37/1000\n",
      "1856/1856 [==============================] - 0s 215us/step - loss: 0.6656 - accuracy: 0.8157 - val_loss: 0.5995 - val_accuracy: 0.8530\n",
      "Epoch 38/1000\n",
      "1856/1856 [==============================] - 0s 218us/step - loss: 0.6640 - accuracy: 0.8157 - val_loss: 0.5984 - val_accuracy: 0.8530\n",
      "Epoch 39/1000\n",
      "1856/1856 [==============================] - 0s 214us/step - loss: 0.6627 - accuracy: 0.8157 - val_loss: 0.5971 - val_accuracy: 0.8530\n",
      "Epoch 40/1000\n",
      "1856/1856 [==============================] - 0s 220us/step - loss: 0.6615 - accuracy: 0.8157 - val_loss: 0.5959 - val_accuracy: 0.8530\n",
      "Epoch 41/1000\n",
      "1856/1856 [==============================] - 0s 221us/step - loss: 0.6604 - accuracy: 0.8157 - val_loss: 0.5953 - val_accuracy: 0.8530\n",
      "Epoch 42/1000\n",
      "1856/1856 [==============================] - ETA: 0s - loss: 0.6554 - accuracy: 0.81 - 0s 214us/step - loss: 0.6594 - accuracy: 0.8157 - val_loss: 0.5944 - val_accuracy: 0.8530\n",
      "Epoch 43/1000\n",
      "1856/1856 [==============================] - 0s 213us/step - loss: 0.6585 - accuracy: 0.8157 - val_loss: 0.5937 - val_accuracy: 0.8530\n",
      "Epoch 44/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1856/1856 [==============================] - 0s 215us/step - loss: 0.6577 - accuracy: 0.8157 - val_loss: 0.5931 - val_accuracy: 0.8530\n",
      "Epoch 45/1000\n",
      "1856/1856 [==============================] - 0s 216us/step - loss: 0.6570 - accuracy: 0.8157 - val_loss: 0.5925 - val_accuracy: 0.8530\n",
      "Epoch 46/1000\n",
      "1856/1856 [==============================] - 0s 217us/step - loss: 0.6564 - accuracy: 0.8157 - val_loss: 0.5920 - val_accuracy: 0.8530\n",
      "Epoch 47/1000\n",
      "1856/1856 [==============================] - 0s 213us/step - loss: 0.6558 - accuracy: 0.8157 - val_loss: 0.5921 - val_accuracy: 0.8530\n",
      "Epoch 48/1000\n",
      "1856/1856 [==============================] - 0s 216us/step - loss: 0.6553 - accuracy: 0.8157 - val_loss: 0.5916 - val_accuracy: 0.8530\n",
      "Epoch 49/1000\n",
      "1856/1856 [==============================] - 0s 213us/step - loss: 0.6548 - accuracy: 0.8157 - val_loss: 0.5917 - val_accuracy: 0.8530\n",
      "Epoch 50/1000\n",
      "1856/1856 [==============================] - 0s 218us/step - loss: 0.6544 - accuracy: 0.8157 - val_loss: 0.5913 - val_accuracy: 0.8530\n",
      "Epoch 51/1000\n",
      "1856/1856 [==============================] - 0s 218us/step - loss: 0.6540 - accuracy: 0.8157 - val_loss: 0.5913 - val_accuracy: 0.8530\n",
      "Epoch 52/1000\n",
      "1856/1856 [==============================] - 0s 215us/step - loss: 0.6537 - accuracy: 0.8157 - val_loss: 0.5911 - val_accuracy: 0.8530\n",
      "Epoch 53/1000\n",
      "1856/1856 [==============================] - 0s 215us/step - loss: 0.6534 - accuracy: 0.8157 - val_loss: 0.5912 - val_accuracy: 0.8530\n",
      "Epoch 54/1000\n",
      "1856/1856 [==============================] - 0s 215us/step - loss: 0.6531 - accuracy: 0.8157 - val_loss: 0.5911 - val_accuracy: 0.8530\n",
      "Epoch 55/1000\n",
      "1856/1856 [==============================] - 0s 215us/step - loss: 0.6529 - accuracy: 0.8157 - val_loss: 0.5913 - val_accuracy: 0.8530\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 1s 685us/step - loss: 0.8751 - accuracy: 0.7798 - val_loss: 0.7658 - val_accuracy: 0.8336\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 0s 216us/step - loss: 0.7452 - accuracy: 0.8218 - val_loss: 0.7070 - val_accuracy: 0.8336\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 0s 216us/step - loss: 0.7013 - accuracy: 0.8218 - val_loss: 0.6722 - val_accuracy: 0.8336\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 0s 222us/step - loss: 0.6754 - accuracy: 0.8218 - val_loss: 0.6529 - val_accuracy: 0.8336\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 0s 218us/step - loss: 0.6605 - accuracy: 0.8218 - val_loss: 0.6421 - val_accuracy: 0.8336\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 0s 219us/step - loss: 0.6527 - accuracy: 0.8218 - val_loss: 0.6380 - val_accuracy: 0.8336\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 0s 218us/step - loss: 0.6469 - accuracy: 0.8218 - val_loss: 0.6343 - val_accuracy: 0.8336\n",
      "Epoch 8/1000\n",
      "1857/1857 [==============================] - 0s 216us/step - loss: 0.6433 - accuracy: 0.8218 - val_loss: 0.6329 - val_accuracy: 0.8336\n",
      "Epoch 9/1000\n",
      "1857/1857 [==============================] - 0s 222us/step - loss: 0.6414 - accuracy: 0.8218 - val_loss: 0.6336 - val_accuracy: 0.8336\n",
      "Epoch 10/1000\n",
      "1857/1857 [==============================] - 0s 220us/step - loss: 0.6398 - accuracy: 0.8218 - val_loss: 0.6337 - val_accuracy: 0.8336\n",
      "Epoch 11/1000\n",
      "1857/1857 [==============================] - 0s 218us/step - loss: 0.6386 - accuracy: 0.8218 - val_loss: 0.6338 - val_accuracy: 0.8336\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 1s 690us/step - loss: 1.1367 - accuracy: 0.6607 - val_loss: 0.9988 - val_accuracy: 0.8449\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 0s 221us/step - loss: 0.9926 - accuracy: 0.8180 - val_loss: 0.8617 - val_accuracy: 0.8449\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 0s 226us/step - loss: 0.8884 - accuracy: 0.8180 - val_loss: 0.7683 - val_accuracy: 0.8449\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 0s 216us/step - loss: 0.8154 - accuracy: 0.8180 - val_loss: 0.7100 - val_accuracy: 0.8449\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 0s 217us/step - loss: 0.7684 - accuracy: 0.8180 - val_loss: 0.6741 - val_accuracy: 0.8449\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 0s 216us/step - loss: 0.7376 - accuracy: 0.8180 - val_loss: 0.6506 - val_accuracy: 0.8449\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 0s 218us/step - loss: 0.7148 - accuracy: 0.8180 - val_loss: 0.6326 - val_accuracy: 0.8449\n",
      "Epoch 8/1000\n",
      "1857/1857 [==============================] - 0s 220us/step - loss: 0.6984 - accuracy: 0.8180 - val_loss: 0.6206 - val_accuracy: 0.8449\n",
      "Epoch 9/1000\n",
      "1857/1857 [==============================] - 0s 218us/step - loss: 0.6867 - accuracy: 0.8180 - val_loss: 0.6126 - val_accuracy: 0.8449\n",
      "Epoch 10/1000\n",
      "1857/1857 [==============================] - 0s 220us/step - loss: 0.6779 - accuracy: 0.8180 - val_loss: 0.6067 - val_accuracy: 0.8449\n",
      "Epoch 11/1000\n",
      "1857/1857 [==============================] - 0s 220us/step - loss: 0.6713 - accuracy: 0.8180 - val_loss: 0.6032 - val_accuracy: 0.8449\n",
      "Epoch 12/1000\n",
      "1857/1857 [==============================] - 0s 220us/step - loss: 0.6663 - accuracy: 0.8180 - val_loss: 0.6008 - val_accuracy: 0.8449\n",
      "Epoch 13/1000\n",
      "1857/1857 [==============================] - 0s 219us/step - loss: 0.6624 - accuracy: 0.8180 - val_loss: 0.5995 - val_accuracy: 0.8449\n",
      "Epoch 14/1000\n",
      "1857/1857 [==============================] - 0s 217us/step - loss: 0.6594 - accuracy: 0.8180 - val_loss: 0.5987 - val_accuracy: 0.8449\n",
      "Epoch 15/1000\n",
      "1857/1857 [==============================] - 0s 218us/step - loss: 0.6569 - accuracy: 0.8180 - val_loss: 0.5986 - val_accuracy: 0.8449\n",
      "Epoch 16/1000\n",
      "1857/1857 [==============================] - 0s 218us/step - loss: 0.6549 - accuracy: 0.8180 - val_loss: 0.5984 - val_accuracy: 0.8449\n",
      "Epoch 17/1000\n",
      "1857/1857 [==============================] - 0s 220us/step - loss: 0.6534 - accuracy: 0.8180 - val_loss: 0.5991 - val_accuracy: 0.8449\n",
      "Epoch 18/1000\n",
      "1857/1857 [==============================] - 0s 220us/step - loss: 0.6521 - accuracy: 0.8180 - val_loss: 0.5994 - val_accuracy: 0.8449\n",
      "Epoch 19/1000\n",
      "1857/1857 [==============================] - 0s 216us/step - loss: 0.6510 - accuracy: 0.8180 - val_loss: 0.6002 - val_accuracy: 0.8449\n",
      "auc: 0.6145645910488068\n",
      "kappa: 0.0\n",
      "layers: 1, nodes: 8\n",
      "Train on 1854 samples, validate on 618 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 1s 697us/step - loss: 0.6821 - accuracy: 0.8145 - val_loss: 0.6009 - val_accuracy: 0.8592\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 0s 216us/step - loss: 0.6617 - accuracy: 0.8145 - val_loss: 0.5916 - val_accuracy: 0.8592\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 0s 214us/step - loss: 0.6577 - accuracy: 0.8145 - val_loss: 0.5803 - val_accuracy: 0.8592\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 0s 217us/step - loss: 0.6568 - accuracy: 0.8145 - val_loss: 0.5776 - val_accuracy: 0.8592\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 0s 217us/step - loss: 0.6525 - accuracy: 0.8145 - val_loss: 0.5852 - val_accuracy: 0.8592\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 0s 217us/step - loss: 0.6536 - accuracy: 0.8145 - val_loss: 0.5785 - val_accuracy: 0.8592\n",
      "Epoch 7/1000\n",
      "1854/1854 [==============================] - 0s 222us/step - loss: 0.6506 - accuracy: 0.8145 - val_loss: 0.5783 - val_accuracy: 0.8592\n",
      "Train on 1854 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 1s 707us/step - loss: 1.1133 - accuracy: 0.7357 - val_loss: 0.8877 - val_accuracy: 0.8417\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 0s 216us/step - loss: 0.8598 - accuracy: 0.8198 - val_loss: 0.7398 - val_accuracy: 0.8417\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 0s 224us/step - loss: 0.7520 - accuracy: 0.8198 - val_loss: 0.6711 - val_accuracy: 0.8417\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 0s 218us/step - loss: 0.6994 - accuracy: 0.8198 - val_loss: 0.6400 - val_accuracy: 0.8417\n",
      "Epoch 5/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1854/1854 [==============================] - 0s 217us/step - loss: 0.6729 - accuracy: 0.8198 - val_loss: 0.6254 - val_accuracy: 0.8417\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 0s 216us/step - loss: 0.6588 - accuracy: 0.8198 - val_loss: 0.6192 - val_accuracy: 0.8417\n",
      "Epoch 7/1000\n",
      "1854/1854 [==============================] - 0s 220us/step - loss: 0.6509 - accuracy: 0.8198 - val_loss: 0.6170 - val_accuracy: 0.8417\n",
      "Epoch 8/1000\n",
      "1854/1854 [==============================] - 0s 228us/step - loss: 0.6469 - accuracy: 0.8198 - val_loss: 0.6166 - val_accuracy: 0.8417\n",
      "Epoch 9/1000\n",
      "1854/1854 [==============================] - 0s 217us/step - loss: 0.6440 - accuracy: 0.8198 - val_loss: 0.6176 - val_accuracy: 0.8417\n",
      "Epoch 10/1000\n",
      "1854/1854 [==============================] - 0s 218us/step - loss: 0.6427 - accuracy: 0.8198 - val_loss: 0.6181 - val_accuracy: 0.8417\n",
      "Epoch 11/1000\n",
      "1854/1854 [==============================] - 0s 216us/step - loss: 0.6418 - accuracy: 0.8198 - val_loss: 0.6188 - val_accuracy: 0.8417\n",
      "Train on 1856 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1856/1856 [==============================] - 1s 701us/step - loss: 0.7577 - accuracy: 0.8211 - val_loss: 0.6828 - val_accuracy: 0.8368\n",
      "Epoch 2/1000\n",
      "1856/1856 [==============================] - 0s 217us/step - loss: 0.6823 - accuracy: 0.8211 - val_loss: 0.6495 - val_accuracy: 0.8368\n",
      "Epoch 3/1000\n",
      "1856/1856 [==============================] - 0s 219us/step - loss: 0.6569 - accuracy: 0.8211 - val_loss: 0.6481 - val_accuracy: 0.8368\n",
      "Epoch 4/1000\n",
      "1856/1856 [==============================] - 0s 219us/step - loss: 0.6488 - accuracy: 0.8211 - val_loss: 0.6470 - val_accuracy: 0.8368\n",
      "Epoch 5/1000\n",
      "1856/1856 [==============================] - 0s 222us/step - loss: 0.6382 - accuracy: 0.8211 - val_loss: 0.6363 - val_accuracy: 0.8368\n",
      "Epoch 6/1000\n",
      "1856/1856 [==============================] - 0s 219us/step - loss: 0.6341 - accuracy: 0.8211 - val_loss: 0.6348 - val_accuracy: 0.8368\n",
      "Epoch 7/1000\n",
      "1856/1856 [==============================] - 0s 218us/step - loss: 0.6303 - accuracy: 0.8211 - val_loss: 0.6319 - val_accuracy: 0.8368\n",
      "Epoch 8/1000\n",
      "1856/1856 [==============================] - 0s 219us/step - loss: 0.6268 - accuracy: 0.8211 - val_loss: 0.6356 - val_accuracy: 0.8368\n",
      "Epoch 9/1000\n",
      "1856/1856 [==============================] - 0s 224us/step - loss: 0.6255 - accuracy: 0.8211 - val_loss: 0.6324 - val_accuracy: 0.8368\n",
      "Epoch 10/1000\n",
      "1856/1856 [==============================] - 0s 223us/step - loss: 0.6224 - accuracy: 0.8211 - val_loss: 0.6401 - val_accuracy: 0.8368\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 1s 713us/step - loss: 0.6860 - accuracy: 0.8078 - val_loss: 0.6516 - val_accuracy: 0.8368\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 0s 224us/step - loss: 0.6426 - accuracy: 0.8207 - val_loss: 0.6425 - val_accuracy: 0.8368\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 0s 220us/step - loss: 0.6409 - accuracy: 0.8207 - val_loss: 0.6377 - val_accuracy: 0.8368\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 0s 219us/step - loss: 0.6404 - accuracy: 0.8207 - val_loss: 0.6358 - val_accuracy: 0.8368\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 0s 223us/step - loss: 0.6404 - accuracy: 0.8207 - val_loss: 0.6343 - val_accuracy: 0.8368\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 0s 221us/step - loss: 0.6403 - accuracy: 0.8207 - val_loss: 0.6345 - val_accuracy: 0.8368\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 0s 225us/step - loss: 0.6402 - accuracy: 0.8207 - val_loss: 0.6340 - val_accuracy: 0.8368\n",
      "Epoch 8/1000\n",
      "1857/1857 [==============================] - 0s 225us/step - loss: 0.6401 - accuracy: 0.8207 - val_loss: 0.6321 - val_accuracy: 0.8368\n",
      "Epoch 9/1000\n",
      "1857/1857 [==============================] - 0s 219us/step - loss: 0.6400 - accuracy: 0.8207 - val_loss: 0.6320 - val_accuracy: 0.8368\n",
      "Epoch 10/1000\n",
      "1857/1857 [==============================] - 0s 223us/step - loss: 0.6399 - accuracy: 0.8207 - val_loss: 0.6321 - val_accuracy: 0.8368\n",
      "Epoch 11/1000\n",
      "1857/1857 [==============================] - 0s 219us/step - loss: 0.6398 - accuracy: 0.8207 - val_loss: 0.6313 - val_accuracy: 0.8368\n",
      "Epoch 12/1000\n",
      "1857/1857 [==============================] - 0s 221us/step - loss: 0.6394 - accuracy: 0.8207 - val_loss: 0.6319 - val_accuracy: 0.8368\n",
      "Epoch 13/1000\n",
      "1857/1857 [==============================] - 0s 219us/step - loss: 0.6391 - accuracy: 0.8207 - val_loss: 0.6311 - val_accuracy: 0.8368\n",
      "Epoch 14/1000\n",
      "1857/1857 [==============================] - 0s 220us/step - loss: 0.6400 - accuracy: 0.8207 - val_loss: 0.6317 - val_accuracy: 0.8368\n",
      "Epoch 15/1000\n",
      "1857/1857 [==============================] - 0s 220us/step - loss: 0.6392 - accuracy: 0.8207 - val_loss: 0.6312 - val_accuracy: 0.8368\n",
      "Epoch 16/1000\n",
      "1857/1857 [==============================] - 0s 219us/step - loss: 0.6399 - accuracy: 0.8207 - val_loss: 0.6322 - val_accuracy: 0.8368\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 1s 720us/step - loss: 1.0385 - accuracy: 0.6214 - val_loss: 0.9306 - val_accuracy: 0.8433\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 0s 218us/step - loss: 0.8453 - accuracy: 0.8185 - val_loss: 0.8045 - val_accuracy: 0.8433\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 0s 226us/step - loss: 0.7541 - accuracy: 0.8185 - val_loss: 0.7271 - val_accuracy: 0.8433\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 0s 222us/step - loss: 0.7019 - accuracy: 0.8185 - val_loss: 0.6832 - val_accuracy: 0.8433\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 0s 220us/step - loss: 0.6737 - accuracy: 0.8185 - val_loss: 0.6565 - val_accuracy: 0.8433\n",
      "Epoch 6/1000\n",
      "1857/1857 [==============================] - 0s 219us/step - loss: 0.6582 - accuracy: 0.8185 - val_loss: 0.6431 - val_accuracy: 0.8433\n",
      "Epoch 7/1000\n",
      "1857/1857 [==============================] - 0s 222us/step - loss: 0.6505 - accuracy: 0.8185 - val_loss: 0.6341 - val_accuracy: 0.8433\n",
      "Epoch 8/1000\n",
      "1857/1857 [==============================] - 0s 224us/step - loss: 0.6466 - accuracy: 0.8185 - val_loss: 0.6293 - val_accuracy: 0.8433\n",
      "Epoch 9/1000\n",
      "1857/1857 [==============================] - 0s 220us/step - loss: 0.6445 - accuracy: 0.8185 - val_loss: 0.6268 - val_accuracy: 0.8433\n",
      "Epoch 10/1000\n",
      "1857/1857 [==============================] - 0s 220us/step - loss: 0.6438 - accuracy: 0.8185 - val_loss: 0.6248 - val_accuracy: 0.8433\n",
      "Epoch 11/1000\n",
      "1857/1857 [==============================] - 0s 220us/step - loss: 0.6433 - accuracy: 0.8185 - val_loss: 0.6239 - val_accuracy: 0.8433\n",
      "Epoch 12/1000\n",
      "1857/1857 [==============================] - 0s 221us/step - loss: 0.6433 - accuracy: 0.8185 - val_loss: 0.6217 - val_accuracy: 0.8433\n",
      "Epoch 13/1000\n",
      "1857/1857 [==============================] - 0s 224us/step - loss: 0.6432 - accuracy: 0.8185 - val_loss: 0.6214 - val_accuracy: 0.8433\n",
      "Epoch 14/1000\n",
      "1857/1857 [==============================] - 0s 223us/step - loss: 0.6430 - accuracy: 0.8185 - val_loss: 0.6214 - val_accuracy: 0.8433\n",
      "Epoch 15/1000\n",
      "1857/1857 [==============================] - 0s 219us/step - loss: 0.6430 - accuracy: 0.8185 - val_loss: 0.6210 - val_accuracy: 0.8433\n",
      "Epoch 16/1000\n",
      "1857/1857 [==============================] - 0s 218us/step - loss: 0.6430 - accuracy: 0.8185 - val_loss: 0.6213 - val_accuracy: 0.8433\n",
      "Epoch 17/1000\n",
      "1857/1857 [==============================] - 0s 221us/step - loss: 0.6430 - accuracy: 0.8185 - val_loss: 0.6216 - val_accuracy: 0.8433\n",
      "Epoch 18/1000\n",
      "1857/1857 [==============================] - 0s 222us/step - loss: 0.6430 - accuracy: 0.8185 - val_loss: 0.6214 - val_accuracy: 0.8433\n",
      "auc: 0.6053212382558065\n",
      "kappa: 0.0\n",
      "layers: 1, nodes: 16\n",
      "Train on 1854 samples, validate on 618 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 2s 830us/step - loss: 0.6945 - accuracy: 0.8031 - val_loss: 0.6013 - val_accuracy: 0.8479\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 1s 272us/step - loss: 0.6490 - accuracy: 0.8182 - val_loss: 0.6027 - val_accuracy: 0.8479\n",
      "Epoch 3/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1854/1854 [==============================] - 0s 259us/step - loss: 0.6448 - accuracy: 0.8182 - val_loss: 0.6078 - val_accuracy: 0.8479\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 0s 255us/step - loss: 0.6435 - accuracy: 0.8182 - val_loss: 0.6110 - val_accuracy: 0.8479\n",
      "Train on 1854 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 1s 735us/step - loss: 0.8503 - accuracy: 0.7923 - val_loss: 0.7010 - val_accuracy: 0.8352\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 0s 222us/step - loss: 0.7139 - accuracy: 0.8220 - val_loss: 0.6520 - val_accuracy: 0.8352\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 0s 225us/step - loss: 0.6627 - accuracy: 0.8220 - val_loss: 0.6353 - val_accuracy: 0.8352\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 0s 218us/step - loss: 0.6465 - accuracy: 0.8220 - val_loss: 0.6328 - val_accuracy: 0.8352\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 0s 222us/step - loss: 0.6403 - accuracy: 0.8220 - val_loss: 0.6316 - val_accuracy: 0.8352\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - -1s -579us/step - loss: 0.6382 - accuracy: 0.8220 - val_loss: 0.6336 - val_accuracy: 0.8352\n",
      "Epoch 7/1000\n",
      "1854/1854 [==============================] - 0s 224us/step - loss: 0.6366 - accuracy: 0.8220 - val_loss: 0.6358 - val_accuracy: 0.8352\n",
      "Epoch 8/1000\n",
      "1854/1854 [==============================] - 0s 229us/step - loss: 0.6357 - accuracy: 0.8220 - val_loss: 0.6365 - val_accuracy: 0.8352\n",
      "Train on 1856 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1856/1856 [==============================] - 1s 729us/step - loss: 0.6958 - accuracy: 0.8023 - val_loss: 0.5765 - val_accuracy: 0.8562\n",
      "Epoch 2/1000\n",
      "1856/1856 [==============================] - 0s 222us/step - loss: 0.6612 - accuracy: 0.8147 - val_loss: 0.5944 - val_accuracy: 0.8562\n",
      "Epoch 3/1000\n",
      "1856/1856 [==============================] - 0s 221us/step - loss: 0.6544 - accuracy: 0.8147 - val_loss: 0.5966 - val_accuracy: 0.8562\n",
      "Epoch 4/1000\n",
      "1856/1856 [==============================] - 0s 218us/step - loss: 0.6531 - accuracy: 0.8147 - val_loss: 0.5888 - val_accuracy: 0.8562\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 1s 742us/step - loss: 0.7066 - accuracy: 0.8083 - val_loss: 0.6188 - val_accuracy: 0.8384\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 0s 225us/step - loss: 0.6491 - accuracy: 0.8201 - val_loss: 0.6162 - val_accuracy: 0.8384\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 0s 225us/step - loss: 0.6435 - accuracy: 0.8201 - val_loss: 0.6194 - val_accuracy: 0.8384\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 0s 229us/step - loss: 0.6434 - accuracy: 0.8201 - val_loss: 0.6230 - val_accuracy: 0.8384\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 0s 224us/step - loss: 0.6419 - accuracy: 0.8201 - val_loss: 0.6239 - val_accuracy: 0.8384\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 1s 741us/step - loss: 0.6877 - accuracy: 0.8196 - val_loss: 0.6227 - val_accuracy: 0.8401\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 0s 223us/step - loss: 0.6437 - accuracy: 0.8196 - val_loss: 0.6234 - val_accuracy: 0.8401\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 0s 223us/step - loss: 0.6429 - accuracy: 0.8196 - val_loss: 0.6227 - val_accuracy: 0.8401\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 0s 222us/step - loss: 0.6436 - accuracy: 0.8196 - val_loss: 0.6231 - val_accuracy: 0.8401\n",
      "auc: 0.5715178565066106\n",
      "kappa: 0.0\n",
      "layers: 1, nodes: 32\n",
      "Train on 1854 samples, validate on 618 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 2s 920us/step - loss: 0.6829 - accuracy: 0.8085 - val_loss: 0.6563 - val_accuracy: 0.8350\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 0s 233us/step - loss: 0.6345 - accuracy: 0.8225 - val_loss: 0.6466 - val_accuracy: 0.8350\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 0s 228us/step - loss: 0.6338 - accuracy: 0.8225 - val_loss: 0.6440 - val_accuracy: 0.8350\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 0s 230us/step - loss: 0.6339 - accuracy: 0.8225 - val_loss: 0.6429 - val_accuracy: 0.8350\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 0s 232us/step - loss: 0.6340 - accuracy: 0.8225 - val_loss: 0.6444 - val_accuracy: 0.8350\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 0s 226us/step - loss: 0.6339 - accuracy: 0.8225 - val_loss: 0.6444 - val_accuracy: 0.8350\n",
      "Epoch 7/1000\n",
      "1854/1854 [==============================] - 0s 224us/step - loss: 0.6334 - accuracy: 0.8225 - val_loss: 0.6442 - val_accuracy: 0.8350\n",
      "Train on 1854 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 2s 812us/step - loss: 0.6654 - accuracy: 0.8080 - val_loss: 0.6169 - val_accuracy: 0.8465\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 0s 225us/step - loss: 0.6454 - accuracy: 0.8182 - val_loss: 0.6132 - val_accuracy: 0.8465\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 0s 226us/step - loss: 0.6445 - accuracy: 0.8182 - val_loss: 0.6134 - val_accuracy: 0.8465\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 0s 227us/step - loss: 0.6445 - accuracy: 0.8182 - val_loss: 0.6141 - val_accuracy: 0.8465\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 0s 233us/step - loss: 0.6443 - accuracy: 0.8182 - val_loss: 0.6181 - val_accuracy: 0.8465\n",
      "Train on 1856 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1856/1856 [==============================] - 1s 756us/step - loss: 0.7310 - accuracy: 0.8023 - val_loss: 0.5963 - val_accuracy: 0.8546\n",
      "Epoch 2/1000\n",
      "1856/1856 [==============================] - 0s 223us/step - loss: 0.6535 - accuracy: 0.8152 - val_loss: 0.5892 - val_accuracy: 0.8546\n",
      "Epoch 3/1000\n",
      "1856/1856 [==============================] - 0s 228us/step - loss: 0.6522 - accuracy: 0.8152 - val_loss: 0.5917 - val_accuracy: 0.8546\n",
      "Epoch 4/1000\n",
      "1856/1856 [==============================] - 0s 228us/step - loss: 0.6522 - accuracy: 0.8152 - val_loss: 0.5943 - val_accuracy: 0.8546\n",
      "Epoch 5/1000\n",
      "1856/1856 [==============================] - 0s 230us/step - loss: 0.6520 - accuracy: 0.8152 - val_loss: 0.5938 - val_accuracy: 0.8546\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 1s 771us/step - loss: 0.6925 - accuracy: 0.8061 - val_loss: 0.6166 - val_accuracy: 0.8433\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 0s 228us/step - loss: 0.6459 - accuracy: 0.8185 - val_loss: 0.6168 - val_accuracy: 0.8433\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 0s 228us/step - loss: 0.6468 - accuracy: 0.8185 - val_loss: 0.6177 - val_accuracy: 0.8433\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 0s 228us/step - loss: 0.6458 - accuracy: 0.8185 - val_loss: 0.6166 - val_accuracy: 0.8433\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 1s 772us/step - loss: 0.7243 - accuracy: 0.8072 - val_loss: 0.6221 - val_accuracy: 0.8384\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 0s 231us/step - loss: 0.6510 - accuracy: 0.8201 - val_loss: 0.6364 - val_accuracy: 0.8384\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 0s 228us/step - loss: 0.6428 - accuracy: 0.8201 - val_loss: 0.6323 - val_accuracy: 0.8384\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 0s 228us/step - loss: 0.6418 - accuracy: 0.8201 - val_loss: 0.6306 - val_accuracy: 0.8384\n",
      "auc: 0.5437831762860649\n",
      "kappa: 0.0\n",
      "layers: 1, nodes: 64\n",
      "Train on 1854 samples, validate on 618 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 1s 788us/step - loss: 0.7353 - accuracy: 0.8215 - val_loss: 0.6743 - val_accuracy: 0.8382\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 0s 242us/step - loss: 0.6410 - accuracy: 0.8215 - val_loss: 0.6396 - val_accuracy: 0.8382\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 0s 239us/step - loss: 0.6379 - accuracy: 0.8215 - val_loss: 0.6330 - val_accuracy: 0.8382\n",
      "Epoch 4/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1854/1854 [==============================] - 0s 236us/step - loss: 0.6391 - accuracy: 0.8215 - val_loss: 0.6336 - val_accuracy: 0.8382\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 0s 238us/step - loss: 0.6390 - accuracy: 0.8215 - val_loss: 0.6307 - val_accuracy: 0.8382\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 0s 240us/step - loss: 0.6377 - accuracy: 0.8215 - val_loss: 0.6329 - val_accuracy: 0.8382\n",
      "Epoch 7/1000\n",
      "1854/1854 [==============================] - 0s 243us/step - loss: 0.6375 - accuracy: 0.8215 - val_loss: 0.6347 - val_accuracy: 0.8382\n",
      "Epoch 8/1000\n",
      "1854/1854 [==============================] - 0s 238us/step - loss: 0.6392 - accuracy: 0.8215 - val_loss: 0.6367 - val_accuracy: 0.8382\n",
      "Train on 1854 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1854/1854 [==============================] - 1s 799us/step - loss: 0.7037 - accuracy: 0.8074 - val_loss: 0.6253 - val_accuracy: 0.8433\n",
      "Epoch 2/1000\n",
      "1854/1854 [==============================] - 0s 243us/step - loss: 0.6458 - accuracy: 0.8193 - val_loss: 0.6207 - val_accuracy: 0.8433\n",
      "Epoch 3/1000\n",
      "1854/1854 [==============================] - 0s 246us/step - loss: 0.6431 - accuracy: 0.8193 - val_loss: 0.6224 - val_accuracy: 0.8433\n",
      "Epoch 4/1000\n",
      "1854/1854 [==============================] - 0s 242us/step - loss: 0.6435 - accuracy: 0.8193 - val_loss: 0.6188 - val_accuracy: 0.8433\n",
      "Epoch 5/1000\n",
      "1854/1854 [==============================] - 0s 239us/step - loss: 0.6434 - accuracy: 0.8193 - val_loss: 0.6185 - val_accuracy: 0.8433\n",
      "Epoch 6/1000\n",
      "1854/1854 [==============================] - 0s 242us/step - loss: 0.6422 - accuracy: 0.8193 - val_loss: 0.6184 - val_accuracy: 0.8433\n",
      "Epoch 7/1000\n",
      "1854/1854 [==============================] - 0s 242us/step - loss: 0.6435 - accuracy: 0.8193 - val_loss: 0.6201 - val_accuracy: 0.8433\n",
      "Epoch 8/1000\n",
      "1854/1854 [==============================] - 0s 240us/step - loss: 0.6426 - accuracy: 0.8193 - val_loss: 0.6216 - val_accuracy: 0.8433\n",
      "Epoch 9/1000\n",
      "1854/1854 [==============================] - 0s 240us/step - loss: 0.6425 - accuracy: 0.8193 - val_loss: 0.6248 - val_accuracy: 0.8433\n",
      "Train on 1856 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1856/1856 [==============================] - 1s 788us/step - loss: 0.8267 - accuracy: 0.8077 - val_loss: 0.5991 - val_accuracy: 0.8433\n",
      "Epoch 2/1000\n",
      "1856/1856 [==============================] - 0s 243us/step - loss: 0.6495 - accuracy: 0.8190 - val_loss: 0.6237 - val_accuracy: 0.8433\n",
      "Epoch 3/1000\n",
      "1856/1856 [==============================] - 0s 241us/step - loss: 0.6441 - accuracy: 0.8190 - val_loss: 0.6251 - val_accuracy: 0.8433\n",
      "Epoch 4/1000\n",
      "1856/1856 [==============================] - 0s 243us/step - loss: 0.6443 - accuracy: 0.8190 - val_loss: 0.6230 - val_accuracy: 0.8433\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 2s 818us/step - loss: 0.8436 - accuracy: 0.8040 - val_loss: 0.6299 - val_accuracy: 0.8401\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 0s 248us/step - loss: 0.6464 - accuracy: 0.8196 - val_loss: 0.6296 - val_accuracy: 0.8401\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 0s 244us/step - loss: 0.6419 - accuracy: 0.8196 - val_loss: 0.6336 - val_accuracy: 0.8401\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 0s 246us/step - loss: 0.6429 - accuracy: 0.8196 - val_loss: 0.6312 - val_accuracy: 0.8401\n",
      "Epoch 5/1000\n",
      "1857/1857 [==============================] - 0s 247us/step - loss: 0.6420 - accuracy: 0.8196 - val_loss: 0.6304 - val_accuracy: 0.8401\n",
      "Train on 1857 samples, validate on 619 samples\n",
      "Epoch 1/1000\n",
      "1857/1857 [==============================] - 2s 811us/step - loss: 0.8368 - accuracy: 0.7997 - val_loss: 0.5772 - val_accuracy: 0.8530\n",
      "Epoch 2/1000\n",
      "1857/1857 [==============================] - 0s 242us/step - loss: 0.6591 - accuracy: 0.8153 - val_loss: 0.5881 - val_accuracy: 0.8530\n",
      "Epoch 3/1000\n",
      "1857/1857 [==============================] - 0s 247us/step - loss: 0.6575 - accuracy: 0.8153 - val_loss: 0.5888 - val_accuracy: 0.8530\n",
      "Epoch 4/1000\n",
      "1857/1857 [==============================] - 0s 247us/step - loss: 0.6536 - accuracy: 0.8153 - val_loss: 0.5892 - val_accuracy: 0.8530\n",
      "auc: 0.5290653949720266\n",
      "kappa: 0.0\n"
     ]
    }
   ],
   "source": [
    "FOLDS = 5\n",
    "PADDING = 100\n",
    "LAYERS = 1\n",
    "MAX_POWER = 6\n",
    "KERNEL_SIZE = 3\n",
    "POOL_SIZE = 2\n",
    "DROPOUT = 0.25\n",
    "ACTIVATION = 'sigmoid'\n",
    "LAST_ACTIVATION = 'softmax'\n",
    "\n",
    "# Prepare training batches\n",
    "input_data = pk.load(open('input_data2.pkl', 'rb'))\n",
    "target_data = pk.load(open('target_data2.pkl', 'rb'))\n",
    "model_input = []\n",
    "model_target = []\n",
    "for i, t in zip(input_data, target_data):\n",
    "    model_input.append(np.concatenate([np.zeros((PADDING - 1, i.shape[1])), i])[:PADDING,:])\n",
    "    model_target.append(np.argmax(t))\n",
    "model_input = np.array(model_input)\n",
    "model_target = np.array(model_target)\n",
    "\n",
    "#keys, values = np.unique(model_target, return_counts=True)\n",
    "#values = (1 / values) / max((1 / values))\n",
    "#class_weight = dict(zip(keys, values))\n",
    "class_weight = dict(zip(np.arange(target_data[0].size), np.ones((target_data[0].size,))))\n",
    "\n",
    "skf = StratifiedKFold(n_splits=FOLDS, shuffle=True)\n",
    "mms = MinMaxScaler()\n",
    "\n",
    "layers = []\n",
    "dimention = []\n",
    "auc = []\n",
    "kappa = []\n",
    "for lay in range(1,LAYERS+1):\n",
    "    for dim in np.power(2, np.arange(MAX_POWER+1)):\n",
    "        print(f'layers: {lay}, nodes: {dim}')\n",
    "        aucs = []\n",
    "        kappas = []\n",
    "        \n",
    "        # Prepare k-fold training and test sets\n",
    "        for train_index, test_index in skf.split(model_input, model_target):\n",
    "            model_target[train_index.astype(int)]\n",
    "            X_train_raw, X_test_raw = model_input[train_index], model_input[test_index]\n",
    "            y_train_raw, y_test_raw = model_target[train_index], model_target[test_index]\n",
    "            \n",
    "            X_train = np.stack(X_train_raw)\n",
    "            X_test = np.stack(X_test_raw)\n",
    "            \n",
    "            y_train = np.zeros((y_train_raw.size, y_train_raw.max() + 1))\n",
    "            y_train[np.arange(y_train_raw.size),y_train_raw] = 1\n",
    "            y_test = np.zeros((y_test_raw.size, y_test_raw.max() + 1))\n",
    "            y_test[np.arange(y_test_raw.size),y_test_raw] = 1\n",
    "            \n",
    "            # Make the LSTM\n",
    "            model = Sequential()\n",
    "            model.add(Conv1D(filters=dim, kernel_size=KERNEL_SIZE, activation=ACTIVATION, padding='same', input_shape=(PADDING, model_input[0].shape[1])))\n",
    "            for l in range(lay-1):\n",
    "                model.add(Conv1D(filters=dim, kernel_size=KERNEL_SIZE, activation=ACTIVATION, padding='same'))\n",
    "                model.add(Dropout(DROPOUT))\n",
    "                model.add(MaxPooling1D(pool_size=POOL_SIZE))\n",
    "            model.add(Flatten())\n",
    "            model.add(Dense(dim, activation=ACTIVATION))\n",
    "            model.add(Dense(target_data[0].size, activation=LAST_ACTIVATION))\n",
    "            model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "            es = [EarlyStopping(monitor='val_loss', patience=3, min_delta=0, restore_best_weights=True)]\n",
    "            model.fit(X_train, y_train, epochs=1000, validation_split=0.25, callbacks=es, verbose=True)\n",
    "            \n",
    "            # Get the average auc and kappa for all affects and folds\n",
    "            y_pred = model.predict(X_test, batch_size=1)\n",
    "            for y_t, y_p in zip(y_test.T, y_pred.T):\n",
    "                #y_p = mms.fit_transform(y_p.reshape(-1, 1))\n",
    "                aucs.append(roc_auc_score(y_t, y_p))\n",
    "                kappas.append(cohen_kappa_score(y_t, np.around(y_p)))\n",
    "        \n",
    "        layers.append(lay)\n",
    "        dimention.append(dim)\n",
    "        auc.append(np.mean(aucs))\n",
    "        kappa.append(np.mean(kappas))\n",
    "        print(f'auc: {auc[-1]}')\n",
    "        print(f'kappa: {kappa[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "for i in range(LAYERS):\n",
    "    start = int(i*(MAX_POWER+1))\n",
    "    end = int(i*(MAX_POWER+1)+MAX_POWER+1)\n",
    "    plt.plot(dimention[start:end], auc[start:end], marker='.', label=f'{i} Layer LSTM')\n",
    "plt.xlabel('Projected Dimensions')\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.title('1dCNN')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "for i in range(LAYERS):\n",
    "    start = int(i*(MAX_POWER+1))\n",
    "    end = int(i*(MAX_POWER+1)+MAX_POWER+1)\n",
    "    plt.plot(dimention[start:end], kappa[start:end], marker='.', label=f'{i} Layer LSTM')\n",
    "plt.xlabel('1dCNN w/ scaled softmax output')\n",
    "plt.ylabel('Cohen\\'s Kappa')\n",
    "plt.title('1dCNN')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
